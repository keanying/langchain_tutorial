{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5402c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:33:32.410407Z",
     "iopub.status.busy": "2025-04-07T03:33:32.409471Z",
     "iopub.status.idle": "2025-04-07T03:33:56.358150Z",
     "shell.execute_reply": "2025-04-07T03:33:56.357046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功创建LangChain文档结构索引文件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 20:33:49.559 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:33:52.839 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:33:56.121 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from metagpt.tools.libs.web_scraping import view_page_element_to_scrape\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# 创建项目目录结构\n",
    "terminal = Terminal()\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/docs\")\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/code_examples\")\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/images\")\n",
    "\n",
    "# 获取LangChain文档主页内容\n",
    "introduction_url = \"https://python.langchain.com/docs/introduction/\"\n",
    "introduction_html = await view_page_element_to_scrape(\n",
    "    url=introduction_url,\n",
    "    requirement=\"获取页面内部导航结构和主要内容\",\n",
    "    keep_links=True\n",
    ")\n",
    "\n",
    "# 提取文档结构\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(introduction_html, 'html.parser')\n",
    "\n",
    "# 提取主导航菜单\n",
    "nav_items = soup.find_all('nav')\n",
    "sidebar_content = None\n",
    "for nav in nav_items:\n",
    "    if nav.get('class') and 'sidebar' in ' '.join(nav.get('class')):\n",
    "        sidebar_content = nav\n",
    "        break\n",
    "\n",
    "# 创建文档结构索引文件\n",
    "with open('langchain_tutorial/docs/document_structure.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# LangChain 文档结构\\n\\n\")\n",
    "    f.write(\"## 基本架构和核心组件\\n\\n\")\n",
    "    \n",
    "    # 提取主要内容\n",
    "    main_content = soup.find('main')\n",
    "    if main_content:\n",
    "        headers = main_content.find_all(['h1', 'h2', 'h3'])\n",
    "        for header in headers:\n",
    "            header_text = header.get_text(strip=True)\n",
    "            if header.name == 'h1':\n",
    "                f.write(f\"# {header_text}\\n\\n\")\n",
    "            elif header.name == 'h2':\n",
    "                f.write(f\"## {header_text}\\n\\n\")\n",
    "            else:\n",
    "                f.write(f\"### {header_text}\\n\\n\")\n",
    "            \n",
    "            # 获取段落内容\n",
    "            next_elem = header.find_next_sibling()\n",
    "            while next_elem and next_elem.name not in ['h1', 'h2', 'h3']:\n",
    "                if next_elem.name == 'p':\n",
    "                    f.write(f\"{next_elem.get_text(strip=True)}\\n\\n\")\n",
    "                next_elem = next_elem.find_next_sibling()\n",
    "    \n",
    "    # 添加侧边栏导航结构\n",
    "    f.write(\"## 文档导航结构\\n\\n\")\n",
    "    if sidebar_content:\n",
    "        links = sidebar_content.find_all('a')\n",
    "        for link in links:\n",
    "            href = link.get('href')\n",
    "            text = link.get_text(strip=True)\n",
    "            if href and text:\n",
    "                f.write(f\"- [{text}]({href})\\n\")\n",
    "\n",
    "# 获取模块页面的内容\n",
    "modules_url = \"https://python.langchain.com/docs/modules/\"\n",
    "modules_html = await view_page_element_to_scrape(\n",
    "    url=modules_url,\n",
    "    requirement=\"获取LangChain各个模块的信息\",\n",
    "    keep_links=True\n",
    ")\n",
    "\n",
    "# 分析模块内容并保存\n",
    "soup_modules = BeautifulSoup(modules_html, 'html.parser')\n",
    "main_content = soup_modules.find('main')\n",
    "\n",
    "with open('langchain_tutorial/docs/components.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# LangChain 框架组件\\n\\n\")\n",
    "    \n",
    "    if main_content:\n",
    "        headers = main_content.find_all(['h1', 'h2', 'h3'])\n",
    "        for header in headers:\n",
    "            header_text = header.get_text(strip=True)\n",
    "            if header.name == 'h1':\n",
    "                f.write(f\"# {header_text}\\n\\n\")\n",
    "            elif header.name == 'h2':\n",
    "                f.write(f\"## {header_text}\\n\\n\")\n",
    "            else:\n",
    "                f.write(f\"### {header_text}\\n\\n\")\n",
    "            \n",
    "            # 获取段落内容\n",
    "            next_elem = header.find_next_sibling()\n",
    "            while next_elem and next_elem.name not in ['h1', 'h2', 'h3']:\n",
    "                if next_elem.name == 'p':\n",
    "                    f.write(f\"{next_elem.get_text(strip=True)}\\n\\n\")\n",
    "                next_elem = next_elem.find_next_sibling()\n",
    "\n",
    "# 检查LangChain的agents部分\n",
    "agents_url = \"https://python.langchain.com/docs/modules/agents/\"\n",
    "agents_html = await view_page_element_to_scrape(\n",
    "    url=agents_url,\n",
    "    requirement=\"获取LangChain智能体相关信息\",\n",
    "    keep_links=True\n",
    ")\n",
    "\n",
    "# 保存agents文档\n",
    "with open('langchain_tutorial/docs/agents.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# LangChain 智能体 (Agents)\\n\\n\")\n",
    "    soup_agents = BeautifulSoup(agents_html, 'html.parser')\n",
    "    main_content = soup_agents.find('main')\n",
    "    \n",
    "    if main_content:\n",
    "        content_text = main_content.get_text(strip=True)\n",
    "        paragraphs = re.split(r'\\n\\s*\\n', content_text)\n",
    "        for paragraph in paragraphs:\n",
    "            f.write(f\"{paragraph.strip()}\\n\\n\")\n",
    "\n",
    "# 显示项目结构\n",
    "await terminal.run(\"find langchain_tutorial -type f | sort\")\n",
    "print(\"成功创建LangChain文档结构索引文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd5c3e80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:35:35.935825Z",
     "iopub.status.busy": "2025-04-07T03:35:35.935048Z",
     "iopub.status.idle": "2025-04-07T03:36:43.457155Z",
     "shell.execute_reply": "2025-04-07T03:36:43.456359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在获取 model_io 组件文档...\n",
      "正在获取 memory 组件文档...\n",
      "正在获取 prompt_templates 组件文档...\n",
      "正在获取 output_parsers 组件文档...\n",
      "正在获取 chains 组件文档...\n",
      "正在获取 retrieval 组件文档...\n",
      "正在获取 agent_overview 文档...\n",
      "正在获取 agent_types 文档...\n",
      "正在获取 agent_executors 文档...\n",
      "正在获取 tools 文档...\n",
      "正在获取 toolkits 文档...\n",
      "正在获取 retrieval 文档...\n",
      "正在获取 rag_overview 文档...\n",
      "正在获取 rag_retrieval 文档...\n",
      "正在获取 agent_supervision 文档...\n",
      "正在获取 executor 文档...\n",
      "正在获取 tools 文档...\n",
      "正在获取 lcel_intro 文档...\n",
      "正在获取 lcel_interface 文档...\n",
      "正在获取 lcel_cookbook 文档...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 20:35:39.406 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:35:42.743 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:35:45.903 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:35:49.067 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:35:52.407 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:35:55.796 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:35:59.002 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:02.339 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:05.799 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:08.949 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:11.938 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:15.111 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:18.253 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:21.266 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:24.356 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:27.727 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:30.867 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:34.981 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:39.332 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 20:36:42.664 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nlangchain_tutorial/docs/agents.md\\nlangchain_tutorial/docs/agents/agent_executors.md\\nlangchain_tutorial/docs/agents/agent_overview.md\\nlangchain_tutorial/docs/agents/agent_supervision_multi.md\\nlangchain_tutorial/docs/agents/agent_types.md\\nlangchain_tutorial/docs/agents/executor_multi.md\\nlangchain_tutorial/docs/agents/toolkits.md\\nlangchain_tutorial/docs/agents/tools.md\\nlangchain_tutorial/docs/agents/tools_multi.md\\nlangchain_tutorial/docs/components.md\\nlangchain_tutorial/docs/components/chains.md\\nlangchain_tutorial/docs/components/memory.md\\nlangchain_tutorial/docs/components/model_io.md\\nlangchain_tutorial/docs/components/output_parsers.md\\nlangchain_tutorial/docs/components/prompt_templates.md\\nlangchain_tutorial/docs/components/retrieval.md\\nlangchain_tutorial/docs/document_structure.md\\nlangchain_tutorial/docs/lcel_cookbook.md\\nlangchain_tutorial/docs/lcel_interface.md\\nlangchain_tutorial/docs/lcel_intro.md\\nlangchain_tutorial/docs/overview.md\\nlangchain_tutorial/docs/search/rag_overview.md\\nlangchain_tutorial/docs/search/rag_retrieval.md\\nlangchain_tutorial/docs/search/retrieval.md\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from metagpt.tools.libs.web_scraping import view_page_element_to_scrape\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# 创建目录用于保存不同模块的文档\n",
    "terminal = Terminal()\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/docs/components\")\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/docs/agents\")\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/docs/search\")\n",
    "\n",
    "# 核心组件页面URL列表\n",
    "component_urls = [\n",
    "    (\"model_io\", \"https://python.langchain.com/docs/modules/model_io/\"),\n",
    "    (\"memory\", \"https://python.langchain.com/docs/modules/memory/\"),\n",
    "    (\"prompt_templates\", \"https://python.langchain.com/docs/modules/prompts/\"),\n",
    "    (\"output_parsers\", \"https://python.langchain.com/docs/modules/model_io/output_parsers\"),\n",
    "    (\"chains\", \"https://python.langchain.com/docs/modules/chains/\"),\n",
    "    (\"retrieval\", \"https://python.langchain.com/docs/modules/data_connection/\"),\n",
    "]\n",
    "\n",
    "# 获取每个核心组件的文档并保存\n",
    "for component_name, url in component_urls:\n",
    "    print(f\"正在获取 {component_name} 组件文档...\")\n",
    "    html_content = await view_page_element_to_scrape(\n",
    "        url=url,\n",
    "        requirement=f\"获取 {component_name} 组件的详细信息和示例代码\",\n",
    "        keep_links=True\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.find('main')\n",
    "    \n",
    "    if main_content:\n",
    "        with open(f\"langchain_tutorial/docs/components/{component_name}.md\", 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"# LangChain {component_name} 组件\\n\\n\")\n",
    "            f.write(f\"来源: {url}\\n\\n\")\n",
    "            \n",
    "            # 提取标题和内容\n",
    "            headers = main_content.find_all(['h1', 'h2', 'h3'])\n",
    "            for header in headers:\n",
    "                header_text = header.get_text(strip=True)\n",
    "                if header.name == 'h1':\n",
    "                    f.write(f\"# {header_text}\\n\\n\")\n",
    "                elif header.name == 'h2':\n",
    "                    f.write(f\"## {header_text}\\n\\n\")\n",
    "                else:\n",
    "                    f.write(f\"### {header_text}\\n\\n\")\n",
    "                \n",
    "                # 获取段落内容\n",
    "                next_elem = header.find_next_sibling()\n",
    "                while next_elem and next_elem.name not in ['h1', 'h2', 'h3']:\n",
    "                    if next_elem.name == 'p':\n",
    "                        f.write(f\"{next_elem.get_text(strip=True)}\\n\\n\")\n",
    "                    elif next_elem.name == 'pre':\n",
    "                        # 获取代码示例\n",
    "                        code = next_elem.get_text()\n",
    "                        f.write(\"```python\\n\")\n",
    "                        f.write(code)\n",
    "                        f.write(\"\\n```\\n\\n\")\n",
    "                    elif next_elem.name in ['ul', 'ol']:\n",
    "                        # 处理列表\n",
    "                        items = next_elem.find_all('li')\n",
    "                        for item in items:\n",
    "                            f.write(f\"- {item.get_text(strip=True)}\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    next_elem = next_elem.find_next_sibling()\n",
    "\n",
    "# 获取智能体相关文档\n",
    "agent_urls = [\n",
    "    (\"agent_overview\", \"https://python.langchain.com/docs/modules/agents/\"),\n",
    "    (\"agent_types\", \"https://python.langchain.com/docs/modules/agents/agent_types/\"),\n",
    "    (\"agent_executors\", \"https://python.langchain.com/docs/modules/agents/executor/\"),\n",
    "    (\"tools\", \"https://python.langchain.com/docs/modules/tools/\"),\n",
    "    (\"toolkits\", \"https://python.langchain.com/docs/modules/agents/toolkits/\")\n",
    "]\n",
    "\n",
    "for agent_name, url in agent_urls:\n",
    "    print(f\"正在获取 {agent_name} 文档...\")\n",
    "    html_content = await view_page_element_to_scrape(\n",
    "        url=url,\n",
    "        requirement=f\"获取 {agent_name} 的详细信息和示例代码\",\n",
    "        keep_links=True\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.find('main')\n",
    "    \n",
    "    if main_content:\n",
    "        with open(f\"langchain_tutorial/docs/agents/{agent_name}.md\", 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"# LangChain {agent_name}\\n\\n\")\n",
    "            f.write(f\"来源: {url}\\n\\n\")\n",
    "            \n",
    "            # 提取标题和内容\n",
    "            headers = main_content.find_all(['h1', 'h2', 'h3'])\n",
    "            for header in headers:\n",
    "                header_text = header.get_text(strip=True)\n",
    "                if header.name == 'h1':\n",
    "                    f.write(f\"# {header_text}\\n\\n\")\n",
    "                elif header.name == 'h2':\n",
    "                    f.write(f\"## {header_text}\\n\\n\")\n",
    "                else:\n",
    "                    f.write(f\"### {header_text}\\n\\n\")\n",
    "                \n",
    "                # 获取段落内容和代码示例\n",
    "                next_elem = header.find_next_sibling()\n",
    "                while next_elem and next_elem.name not in ['h1', 'h2', 'h3']:\n",
    "                    if next_elem.name == 'p':\n",
    "                        f.write(f\"{next_elem.get_text(strip=True)}\\n\\n\")\n",
    "                    elif next_elem.name == 'pre':\n",
    "                        code = next_elem.get_text()\n",
    "                        f.write(\"```python\\n\")\n",
    "                        f.write(code)\n",
    "                        f.write(\"\\n```\\n\\n\")\n",
    "                    elif next_elem.name in ['ul', 'ol']:\n",
    "                        items = next_elem.find_all('li')\n",
    "                        for item in items:\n",
    "                            f.write(f\"- {item.get_text(strip=True)}\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    next_elem = next_elem.find_next_sibling()\n",
    "\n",
    "# 获取搜索结合智能体相关文档\n",
    "search_urls = [\n",
    "    (\"retrieval\", \"https://python.langchain.com/docs/modules/data_connection/retrievers/\"),\n",
    "    (\"rag_overview\", \"https://python.langchain.com/docs/use_cases/question_answering/\"),\n",
    "    (\"rag_retrieval\", \"https://python.langchain.com/docs/use_cases/question_answering/retrieval\")\n",
    "]\n",
    "\n",
    "for search_name, url in search_urls:\n",
    "    print(f\"正在获取 {search_name} 文档...\")\n",
    "    html_content = await view_page_element_to_scrape(\n",
    "        url=url,\n",
    "        requirement=f\"获取 {search_name} 的详细信息和示例代码\",\n",
    "        keep_links=True\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.find('main')\n",
    "    \n",
    "    if main_content:\n",
    "        with open(f\"langchain_tutorial/docs/search/{search_name}.md\", 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"# LangChain {search_name}\\n\\n\")\n",
    "            f.write(f\"来源: {url}\\n\\n\")\n",
    "            \n",
    "            # 提取标题和内容\n",
    "            headers = main_content.find_all(['h1', 'h2', 'h3'])\n",
    "            for header in headers:\n",
    "                header_text = header.get_text(strip=True)\n",
    "                if header.name == 'h1':\n",
    "                    f.write(f\"# {header_text}\\n\\n\")\n",
    "                elif header.name == 'h2':\n",
    "                    f.write(f\"## {header_text}\\n\\n\")\n",
    "                else:\n",
    "                    f.write(f\"### {header_text}\\n\\n\")\n",
    "                \n",
    "                # 获取段落内容和代码示例\n",
    "                next_elem = header.find_next_sibling()\n",
    "                while next_elem and next_elem.name not in ['h1', 'h2', 'h3']:\n",
    "                    if next_elem.name == 'p':\n",
    "                        f.write(f\"{next_elem.get_text(strip=True)}\\n\\n\")\n",
    "                    elif next_elem.name == 'pre':\n",
    "                        code = next_elem.get_text()\n",
    "                        f.write(\"```python\\n\")\n",
    "                        f.write(code)\n",
    "                        f.write(\"\\n```\\n\\n\")\n",
    "                    elif next_elem.name in ['ul', 'ol']:\n",
    "                        items = next_elem.find_all('li')\n",
    "                        for item in items:\n",
    "                            f.write(f\"- {item.get_text(strip=True)}\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    next_elem = next_elem.find_next_sibling()\n",
    "\n",
    "# 获取多智能体编排相关文档\n",
    "multi_agent_urls = [\n",
    "    (\"agent_supervision\", \"https://python.langchain.com/docs/modules/agents/agent_supervision/\"),\n",
    "    (\"executor\", \"https://python.langchain.com/docs/modules/agents/executor/\"),\n",
    "    (\"tools\", \"https://python.langchain.com/docs/modules/tools/\")\n",
    "]\n",
    "\n",
    "for agent_name, url in multi_agent_urls:\n",
    "    print(f\"正在获取 {agent_name} 文档...\")\n",
    "    html_content = await view_page_element_to_scrape(\n",
    "        url=url,\n",
    "        requirement=f\"获取 {agent_name} 的详细信息和示例代码\",\n",
    "        keep_links=True\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.find('main')\n",
    "    \n",
    "    if main_content:\n",
    "        with open(f\"langchain_tutorial/docs/agents/{agent_name}_multi.md\", 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"# LangChain 多智能体 {agent_name}\\n\\n\")\n",
    "            f.write(f\"来源: {url}\\n\\n\")\n",
    "            \n",
    "            # 提取标题和内容\n",
    "            headers = main_content.find_all(['h1', 'h2', 'h3'])\n",
    "            for header in headers:\n",
    "                header_text = header.get_text(strip=True)\n",
    "                if header.name == 'h1':\n",
    "                    f.write(f\"# {header_text}\\n\\n\")\n",
    "                elif header.name == 'h2':\n",
    "                    f.write(f\"## {header_text}\\n\\n\")\n",
    "                else:\n",
    "                    f.write(f\"### {header_text}\\n\\n\")\n",
    "                \n",
    "                # 获取段落内容和代码示例\n",
    "                next_elem = header.find_next_sibling()\n",
    "                while next_elem and next_elem.name not in ['h1', 'h2', 'h3']:\n",
    "                    if next_elem.name == 'p':\n",
    "                        f.write(f\"{next_elem.get_text(strip=True)}\\n\\n\")\n",
    "                    elif next_elem.name == 'pre':\n",
    "                        code = next_elem.get_text()\n",
    "                        f.write(\"```python\\n\")\n",
    "                        f.write(code)\n",
    "                        f.write(\"\\n```\\n\\n\")\n",
    "                    elif next_elem.name in ['ul', 'ol']:\n",
    "                        items = next_elem.find_all('li')\n",
    "                        for item in items:\n",
    "                            f.write(f\"- {item.get_text(strip=True)}\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    next_elem = next_elem.find_next_sibling()\n",
    "\n",
    "# 获取表达式语言(LCEL)相关文档，这对多智能体编排很重要\n",
    "lcel_urls = [\n",
    "    (\"lcel_intro\", \"https://python.langchain.com/docs/expression_language/\"),\n",
    "    (\"lcel_interface\", \"https://python.langchain.com/docs/expression_language/interface\"),\n",
    "    (\"lcel_cookbook\", \"https://python.langchain.com/docs/expression_language/cookbook\")\n",
    "]\n",
    "\n",
    "for lcel_name, url in lcel_urls:\n",
    "    print(f\"正在获取 {lcel_name} 文档...\")\n",
    "    html_content = await view_page_element_to_scrape(\n",
    "        url=url,\n",
    "        requirement=f\"获取 {lcel_name} 的详细信息和示例代码\",\n",
    "        keep_links=True\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.find('main')\n",
    "    \n",
    "    if main_content:\n",
    "        with open(f\"langchain_tutorial/docs/{lcel_name}.md\", 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"# LangChain 表达式语言 {lcel_name}\\n\\n\")\n",
    "            f.write(f\"来源: {url}\\n\\n\")\n",
    "            \n",
    "            # 提取标题和内容\n",
    "            headers = main_content.find_all(['h1', 'h2', 'h3'])\n",
    "            for header in headers:\n",
    "                header_text = header.get_text(strip=True)\n",
    "                if header.name == 'h1':\n",
    "                    f.write(f\"# {header_text}\\n\\n\")\n",
    "                elif header.name == 'h2':\n",
    "                    f.write(f\"## {header_text}\\n\\n\")\n",
    "                else:\n",
    "                    f.write(f\"### {header_text}\\n\\n\")\n",
    "                \n",
    "                # 获取段落内容和代码示例\n",
    "                next_elem = header.find_next_sibling()\n",
    "                while next_elem and next_elem.name not in ['h1', 'h2', 'h3']:\n",
    "                    if next_elem.name == 'p':\n",
    "                        f.write(f\"{next_elem.get_text(strip=True)}\\n\\n\")\n",
    "                    elif next_elem.name == 'pre':\n",
    "                        code = next_elem.get_text()\n",
    "                        f.write(\"```python\\n\")\n",
    "                        f.write(code)\n",
    "                        f.write(\"\\n```\\n\\n\")\n",
    "                    elif next_elem.name in ['ul', 'ol']:\n",
    "                        items = next_elem.find_all('li')\n",
    "                        for item in items:\n",
    "                            f.write(f\"- {item.get_text(strip=True)}\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    next_elem = next_elem.find_next_sibling()\n",
    "\n",
    "# 创建框架总览文档\n",
    "with open('langchain_tutorial/docs/overview.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# LangChain 框架总览\\n\\n\")\n",
    "    f.write(\"## 基本组件\\n\\n\")\n",
    "    f.write(\"LangChain 框架由以下核心组件构成：\\n\\n\")\n",
    "    f.write(\"1. **模型 I/O (Model I/O)** - 处理与语言模型的交互\\n\")\n",
    "    f.write(\"2. **提示模板 (Prompt Templates)** - 管理和优化发送给模型的提示\\n\")\n",
    "    f.write(\"3. **输出解析器 (Output Parsers)** - 处理模型响应转换为结构化格式\\n\")\n",
    "    f.write(\"4. **链 (Chains)** - 组合模型调用与其他组件\\n\")\n",
    "    f.write(\"5. **记忆 (Memory)** - 维护对话状态\\n\")\n",
    "    f.write(\"6. **检索 (Retrieval)** - 与外部数据源交互\\n\")\n",
    "    f.write(\"7. **智能体 (Agents)** - 允许模型确定执行的操作\\n\\n\")\n",
    "    \n",
    "    f.write(\"## 表达式语言 (LCEL)\\n\\n\")\n",
    "    f.write(\"LangChain 表达式语言 (LCEL) 是一种声明式方式，用于组合链和智能体。它通过简洁的操作符实现组件间的连接，并支持异步操作。\\n\\n\")\n",
    "    \n",
    "    f.write(\"## 智能体类型\\n\\n\")\n",
    "    f.write(\"LangChain 支持多种智能体类型：\\n\\n\")\n",
    "    f.write(\"1. **ReAct 智能体** - 结合推理和行动的智能体\\n\")\n",
    "    f.write(\"2. **工具调用智能体** - 专门设计用于工具调用的智能体\\n\")\n",
    "    f.write(\"3. **计划与执行智能体** - 先规划后执行的智能体\\n\")\n",
    "    f.write(\"4. **OpenAI 助手智能体** - 基于 OpenAI 助手 API 的智能体\\n\")\n",
    "    f.write(\"5. **自定义智能体** - 根据特定需求创建的智能体\\n\\n\")\n",
    "    \n",
    "    f.write(\"## 多智能体编排\\n\\n\")\n",
    "    f.write(\"LangChain 支持多智能体系统的编排，包括：\\n\\n\")\n",
    "    f.write(\"1. **智能体监督** - 管理多个智能体的协作\\n\")\n",
    "    f.write(\"2. **智能体执行器** - 控制智能体执行流程\\n\")\n",
    "    f.write(\"3. **工具共享** - 在多个智能体间共享工具\\n\\n\")\n",
    "    \n",
    "    f.write(\"## 搜索与检索增强生成 (RAG)\\n\\n\")\n",
    "    f.write(\"LangChain 提供了强大的检索功能，支持：\\n\\n\")\n",
    "    f.write(\"1. **多种检索器** - 向量存储、关键词搜索等\\n\")\n",
    "    f.write(\"2. **RAG 管道** - 结合检索与生成的端到端系统\\n\")\n",
    "    f.write(\"3. **上下文增强** - 使用外部知识增强模型响应\\n\\n\")\n",
    "\n",
    "# 显示创建的文档结构\n",
    "await terminal.run(\"find langchain_tutorial -type f | grep -v __pycache__ | sort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d44224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:39:31.317644Z",
     "iopub.status.busy": "2025-04-07T03:39:31.317231Z",
     "iopub.status.idle": "2025-04-07T03:39:31.324708Z",
     "shell.execute_reply": "2025-04-07T03:39:31.323771Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2285967862.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[3], line 31\u001B[0;36m\u001B[0m\n\u001B[0;31m    readme_content = \"\"\"# LangChain 多智能体工作流示例\u001B[0m\n\u001B[0m                     ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive code example showcasing LangChain's components and multi-agent workflow\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain.tools.playwright.utils import create_async_playwright_browser\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# 创建项目目录\n",
    "terminal = Terminal()\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/code_examples/multi_agent_demo\")\n",
    "\n",
    "# Create a README file to explain the example\n",
    "readme_content = \"\"\"# LangChain 多智能体工作流示例\n",
    "\n",
    "本示例展示了 LangChain 框架的核心组件和多智能体工作流程。示例包括：\n",
    "\n",
    "1. 基本组件演示：提示模板、语言模型、链、记忆组件\n",
    "2. RAG (检索增强生成) 示例：向量数据库、文档加载与分割、查询\n",
    "3. 单智能体工作流：使用工具增强智能体能力\n",
    "4. 多智能体协作系统：执行复杂任务的多智能体编排\n",
    "\n",
    "## 环境设置\n",
    "\n",
    "需要以下环境变量：\n",
    "- OPENAI_API_KEY：OpenAI API 密钥\n",
    "\n",
    "## 文件结构\n",
    "\n",
    "- `multi_agent_workflow.py`：主要示例代码\n",
    "- `data/`：示例数据文件\n",
    "- `agents/`：定义的智能体\n",
    "- `tools/`：可用工具\n",
    "\n",
    "## 运行方式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad05c42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:41:48.452095Z",
     "iopub.status.busy": "2025-04-07T03:41:48.451542Z",
     "iopub.status.idle": "2025-04-07T03:41:49.298119Z",
     "shell.execute_reply": "2025-04-07T03:41:49.297616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建的示例文件结构:\n",
      "\n",
      "langchain_tutorial/code_examples/multi_agent_demo/README.md\n",
      "langchain_tutorial/code_examples/multi_agent_demo/agents/specialist_agents.py\n",
      "langchain_tutorial/code_examples/multi_agent_demo/lcel_example.py\n",
      "langchain_tutorial/code_examples/multi_agent_demo/multi_agent_workflow.py\n",
      "langchain_tutorial/code_examples/multi_agent_demo/tools/custom_tools.py\n",
      "\n",
      "\n",
      "已创建LangChain多智能体工作流程示例代码，包含以下内容:\n",
      "1. 基础组件示例: 提示模板、语言模型、链、记忆组件\n",
      "2. RAG系统实现: 文档加载、分块、向量存储和检索问答\n",
      "3. 单智能体工作流: 使用工具增强的智能体\n",
      "4. 多智能体协作系统: 研究、规划、编码和测试的专家智能体组合\n",
      "5. LangChain表达式语言(LCEL)示例: 声明式链组合\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# 创建项目目录\n",
    "terminal = Terminal()\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/code_examples/multi_agent_demo\")\n",
    "\n",
    "# Create a README file to explain the example\n",
    "readme_content = \"\"\"# LangChain 多智能体工作流示例\n",
    "\n",
    "本示例展示了 LangChain 框架的核心组件和多智能体工作流程。示例包括：\n",
    "\n",
    "1. 基本组件演示：提示模板、语言模型、链、记忆组件\n",
    "2. RAG (检索增强生成) 示例：向量数据库、文档加载与分割、查询\n",
    "3. 单智能体工作流：使用工具增强智能体能力\n",
    "4. 多智能体协作系统：执行复杂任务的多智能体编排\n",
    "\n",
    "## 环境设置\n",
    "\n",
    "需要以下环境变量：\n",
    "- OPENAI_API_KEY：OpenAI API 密钥\n",
    "\n",
    "## 文件结构\n",
    "\n",
    "- `multi_agent_workflow.py`：主要示例代码\n",
    "- `data/`：示例数据文件\n",
    "- `agents/`：定义的智能体\n",
    "- `tools/`：可用工具\n",
    "\n",
    "## 运行方式\n",
    "python multi_agent_workflow.py\n",
    "\"\"\"\n",
    "\n",
    "# 将README写入到项目目录\n",
    "editor = Editor()\n",
    "editor.write(\"langchain_tutorial/code_examples/multi_agent_demo/README.md\", readme_content)\n",
    "\n",
    "# 创建示例代码文件\n",
    "multi_agent_code = \"\"\"# LangChain 多智能体工作流示例代码\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# 请先设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "# 1. 基础组件演示\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "def demonstrate_basic_components():\n",
    "    print(\"\\\\n1. 演示 LangChain 基础组件\")\n",
    "    \n",
    "    # 创建一个提示模板\n",
    "    template = \"你是一个{role}。用户问题: {question}\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"role\", \"question\"],\n",
    "        template=template,\n",
    "    )\n",
    "    \n",
    "    # 初始化LLM\n",
    "    llm = ChatOpenAI(temperature=0.7)\n",
    "    \n",
    "    # 创建一个带有记忆的链\n",
    "    memory = ConversationBufferMemory()\n",
    "    chain = LLMChain(\n",
    "        llm=llm, \n",
    "        prompt=prompt, \n",
    "        memory=memory,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 执行链\n",
    "    response = chain.run(role=\"友好的AI助手\", question=\"什么是LangChain框架?\")\n",
    "    print(f\"\\\\n回答: {response}\\\\n\")\n",
    "    \n",
    "    # 展示记忆功能\n",
    "    response = chain.run(role=\"友好的AI助手\", question=\"它的主要组件有哪些?\")\n",
    "    print(f\"\\\\n回答: {response}\\\\n\")\n",
    "    \n",
    "    return chain\n",
    "\n",
    "# 2. 检索增强生成 (RAG) 示例\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "def create_rag_system():\n",
    "    print(\"\\\\n2. 创建检索增强生成 (RAG) 系统\")\n",
    "    \n",
    "    # 创建示例文档\n",
    "    Path(\"data\").mkdir(exist_ok=True)\n",
    "    with open(\"data/langchain_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write('''\n",
    "LangChain 是一个用于开发由语言模型驱动的应用程序的框架。它有以下核心组件：\n",
    "\n",
    "1. 模型 I/O: 处理与语言模型的交互，包括提示模板和输出解析。\n",
    "2. 数据连接: 连接语言模型与各种数据源。\n",
    "3. 链: 将多个组件组合成一个应用程序。\n",
    "4. 记忆: 在链的运行之间持久化状态。\n",
    "5. 智能体: 允许语言模型根据目标选择要使用的工具。\n",
    "6. 回调: 在链执行期间钩入中间步骤。\n",
    "\n",
    "LangChain 表达式语言 (LCEL) 是一种声明式语言，用于组合这些组件。它支持同步和异步操作，可以实现复杂的工作流程，如检索增强生成 (RAG)。\n",
    "\n",
    "LangChain 还支持多种类型的智能体，如 ReAct、工具使用、规划与执行等。多智能体系统可以通过智能体监督功能进行协作。\n",
    "        ''')\n",
    "    \n",
    "    # 加载并处理文档\n",
    "    loader = TextLoader(\"data/langchain_info.txt\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 文本分块\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # 创建向量存储\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectordb = FAISS.from_documents(docs, embeddings)\n",
    "    \n",
    "    # 创建一个检索链\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    retriever = vectordb.as_retriever()\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(),\n",
    "        retriever=retriever,\n",
    "        memory=memory,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 执行检索问答\n",
    "    result = qa_chain({\"question\": \"LangChain有哪些核心组件?\"})\n",
    "    print(f\"\\\\nRAG回答: {result['answer']}\\\\n\")\n",
    "    \n",
    "    return qa_chain\n",
    "\n",
    "# 3. 单智能体工作流\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "\n",
    "def create_single_agent():\n",
    "    print(\"\\\\n3. 创建带工具的单智能体系统\")\n",
    "    \n",
    "    # 定义工具\n",
    "    wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "    python_repl = PythonREPLTool()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Wikipedia\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"查询维基百科以获取信息\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Python REPL\",\n",
    "            func=python_repl.run,\n",
    "            description=\"执行Python代码\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 初始化智能体\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    agent = initialize_agent(\n",
    "        tools=tools,\n",
    "        llm=llm,\n",
    "        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    \n",
    "    # 运行智能体\n",
    "    response = agent.run(\"LangChain框架是什么时候发布的? 然后计算从发布到现在经过了多少天。\")\n",
    "    print(f\"\\\\n智能体回答: {response}\\\\n\")\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 4. 多智能体系统\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "import re\n",
    "\n",
    "# 定义自定义智能体\n",
    "class MultiAgentSystem:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.research_agent = self._create_research_agent()\n",
    "        self.planning_agent = self._create_planning_agent()\n",
    "        self.execution_agent = self._create_execution_agent()\n",
    "    \n",
    "    def _create_research_agent(self):\n",
    "        # 创建研究智能体\n",
    "        wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "        \n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"Wikipedia\",\n",
    "                func=wikipedia.run,\n",
    "                description=\"查询维基百科以获取信息\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        agent = initialize_agent(\n",
    "            tools=tools,\n",
    "            llm=self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def _create_planning_agent(self):\n",
    "        # 创建规划智能体\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一个规划专家。根据下面的任务描述创建一个分步计划:\\\\n{task}\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        planning_chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        return planning_chain\n",
    "    \n",
    "    def _create_execution_agent(self):\n",
    "        # 创建执行智能体\n",
    "        python_repl = PythonREPLTool()\n",
    "        \n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"Python REPL\",\n",
    "                func=python_repl.run,\n",
    "                description=\"执行Python代码\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        agent = initialize_agent(\n",
    "            tools=tools,\n",
    "            llm=self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def run(self, task):\n",
    "        print(f\"\\\\n4. 执行多智能体工作流 - 任务: {task}\")\n",
    "        \n",
    "        # 1. 研究阶段\n",
    "        print(\"\\\\n步骤1: 研究阶段\")\n",
    "        research_result = self.research_agent.run(f\"研究关于: {task}\")\n",
    "        print(f\"研究结果: {research_result}\")\n",
    "        \n",
    "        # 2. 规划阶段\n",
    "        print(\"\\\\n步骤2: 规划阶段\")\n",
    "        plan = self.planning_chain.run(task=f\"{task}\\\\n背景信息: {research_result}\")\n",
    "        print(f\"执行计划: {plan}\")\n",
    "        \n",
    "        # 3. 执行阶段\n",
    "        print(\"\\\\n步骤3: 执行阶段\")\n",
    "        final_result = self.execution_agent.run(\n",
    "            f\"根据以下计划执行任务: {plan}\\\\n任务: {task}\"\n",
    "        )\n",
    "        print(f\"最终结果: {final_result}\")\n",
    "        \n",
    "        return {\n",
    "            \"research\": research_result,\n",
    "            \"plan\": plan,\n",
    "            \"result\": final_result\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    print(\"LangChain 多智能体工作流示例\")\n",
    "    \n",
    "    # 运行基础组件演示\n",
    "    basic_chain = demonstrate_basic_components()\n",
    "    \n",
    "    # 创建RAG系统\n",
    "    rag_chain = create_rag_system()\n",
    "    \n",
    "    # 创建单智能体系统\n",
    "    agent = create_single_agent()\n",
    "    \n",
    "    # 创建多智能体系统\n",
    "    multi_agent_system = MultiAgentSystem()\n",
    "    result = multi_agent_system.run(\"创建一个简单的网站访问量分析程序\")\n",
    "    \n",
    "    print(\"\\\\n演示完成!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# 写入主代码文件\n",
    "editor.write(\"langchain_tutorial/code_examples/multi_agent_demo/multi_agent_workflow.py\", multi_agent_code)\n",
    "\n",
    "# 创建一个简单的工具库，用于多智能体系统\n",
    "tools_code = \"\"\"# 自定义工具库\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import Tool\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class WebSearchTool(BaseTool):\n",
    "    name = \"web_search\"\n",
    "    description = \"在网络上搜索信息\"\n",
    "    \n",
    "    def _run(self, query: str) -> str:\n",
    "        # 模拟网络搜索\n",
    "        return f\"关于'{query}'的搜索结果: 这里是一些相关信息...\"\n",
    "    \n",
    "    async def _arun(self, query: str) -> str:\n",
    "        return self._run(query)\n",
    "\n",
    "class DataAnalysisTool(BaseTool):\n",
    "    name = \"data_analysis\"\n",
    "    description = \"分析数据集并提供洞察\"\n",
    "    \n",
    "    def _run(self, data_description: str) -> str:\n",
    "        # 模拟数据分析\n",
    "        return f\"对'{data_description}'的分析结果: 数据显示以下模式...\"\n",
    "    \n",
    "    async def _arun(self, data_description: str) -> str:\n",
    "        return self._run(data_description)\n",
    "\n",
    "class CodeGenerationTool(BaseTool):\n",
    "    name = \"code_generation\"\n",
    "    description = \"生成Python代码来解决特定问题\"\n",
    "    \n",
    "    def _run(self, task: str) -> str:\n",
    "        # 模拟代码生成\n",
    "        return f\"为'{task}'生成的代码:\\\\n```python\\\\ndef solution():\\\\n    # 实现代码\\\\n    print('解决方案')\\\\n```\"\n",
    "    \n",
    "    async def _arun(self, task: str) -> str:\n",
    "        return self._run(task)\n",
    "\n",
    "def get_all_tools() -> List[Tool]:\n",
    "    \\\"\\\"\\\"获取所有可用工具\\\"\\\"\\\"\n",
    "    return [\n",
    "        Tool(\n",
    "            name=\"Web搜索\",\n",
    "            func=WebSearchTool()._run,\n",
    "            description=\"在网络上搜索信息\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"数据分析\",\n",
    "            func=DataAnalysisTool()._run,\n",
    "            description=\"分析数据集并提供洞察\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"代码生成\",\n",
    "            func=CodeGenerationTool()._run,\n",
    "            description=\"生成Python代码来解决特定问题\"\n",
    "        )\n",
    "    ]\n",
    "\"\"\"\n",
    "\n",
    "# 写入工具库文件\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/code_examples/multi_agent_demo/tools\")\n",
    "editor.write(\"langchain_tutorial/code_examples/multi_agent_demo/tools/custom_tools.py\", tools_code)\n",
    "\n",
    "# 创建多智能体定义文件\n",
    "agents_code = \"\"\"# 定义多智能体系统中的各类智能体\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from typing import List, Union, Dict, Any\n",
    "import re\n",
    "\n",
    "# 基础智能体定义\n",
    "class BaseSpecialistAgent:\n",
    "    def __init__(self, name, role_description, tools=None):\n",
    "        self.name = name\n",
    "        self.role_description = role_description\n",
    "        self.tools = tools or []\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.agent_executor = self._create_agent_executor()\n",
    "    \n",
    "    def _create_agent_executor(self):\n",
    "        # 这里实现具体的智能体执行器\n",
    "        # 简化示例，实际中需根据不同智能体类型定制\n",
    "        pass\n",
    "        \n",
    "    def run(self, task):\n",
    "        return f\"{self.name} 处理任务: {task}\"\n",
    "\n",
    "# 研究员智能体\n",
    "class ResearcherAgent(BaseSpecialistAgent):\n",
    "    def __init__(self, tools=None):\n",
    "        super().__init__(\n",
    "            name=\"Researcher\",\n",
    "            role_description=\"你是一名研究专家，擅长收集和分析信息\",\n",
    "            tools=tools\n",
    "        )\n",
    "    \n",
    "    def run(self, query):\n",
    "        # 简化的研究流程\n",
    "        return f\"研究结果: 关于'{query}'的详细信息和分析\"\n",
    "\n",
    "# 规划师智能体\n",
    "class PlannerAgent(BaseSpecialistAgent):\n",
    "    def __init__(self, tools=None):\n",
    "        super().__init__(\n",
    "            name=\"Planner\",\n",
    "            role_description=\"你是一名规划专家，擅长制定详细的执行计划\",\n",
    "            tools=tools\n",
    "        )\n",
    "    \n",
    "    def run(self, task, context=None):\n",
    "        context_str = f\"\\\\n背景信息: {context}\" if context else \"\"\n",
    "        return f\"执行计划:\\\\n1. 分析问题\\\\n2. 设计解决方案\\\\n3. 实施方案\\\\n4. 测试结果\"\n",
    "\n",
    "# 编码员智能体\n",
    "class CoderAgent(BaseSpecialistAgent):\n",
    "    def __init__(self, tools=None):\n",
    "        super().__init__(\n",
    "            name=\"Coder\",\n",
    "            role_description=\"你是一名编程专家，擅长编写和调试代码\",\n",
    "            tools=tools\n",
    "        )\n",
    "    \n",
    "    def run(self, task, plan=None):\n",
    "        plan_str = f\"\\\\n按照计划: {plan}\" if plan else \"\"\n",
    "        return f\"代码实现:\\\\n```python\\\\n# {task}的代码实现\\\\nprint('Hello world!')\\\\n```\"\n",
    "\n",
    "# 测试员智能体\n",
    "class TesterAgent(BaseSpecialistAgent):\n",
    "    def __init__(self, tools=None):\n",
    "        super().__init__(\n",
    "            name=\"Tester\",\n",
    "            role_description=\"你是一名测试专家，擅长验证解决方案和提供反馈\",\n",
    "            tools=tools\n",
    "        )\n",
    "    \n",
    "    def run(self, solution):\n",
    "        return f\"测试结果: 解决方案已验证，运行正常\"\n",
    "\n",
    "# 多智能体协调器\n",
    "class AgentCoordinator:\n",
    "    def __init__(self):\n",
    "        self.researcher = ResearcherAgent()\n",
    "        self.planner = PlannerAgent()\n",
    "        self.coder = CoderAgent()\n",
    "        self.tester = TesterAgent()\n",
    "    \n",
    "    def run_workflow(self, task):\n",
    "        results = {}\n",
    "        \n",
    "        # 1. 研究阶段\n",
    "        research_result = self.researcher.run(task)\n",
    "        results[\"research\"] = research_result\n",
    "        \n",
    "        # 2. 规划阶段\n",
    "        plan = self.planner.run(task, context=research_result)\n",
    "        results[\"plan\"] = plan\n",
    "        \n",
    "        # 3. 编码阶段\n",
    "        code = self.coder.run(task, plan=plan)\n",
    "        results[\"code\"] = code\n",
    "        \n",
    "        # 4. 测试阶段\n",
    "        test_result = self.tester.run(code)\n",
    "        results[\"test\"] = test_result\n",
    "        \n",
    "        return results\n",
    "\"\"\"\n",
    "\n",
    "# 写入智能体文件\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/code_examples/multi_agent_demo/agents\")\n",
    "editor.write(\"langchain_tutorial/code_examples/multi_agent_demo/agents/specialist_agents.py\", agents_code)\n",
    "\n",
    "# 创建一个使用LCEL的示例\n",
    "lcel_example = \"\"\"# LangChain 表达式语言 (LCEL) 示例\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# 基础链\n",
    "def simple_chain_example():\n",
    "    # 1. 定义提示模板\n",
    "    prompt = PromptTemplate.from_template(\"向我介绍{topic}\")\n",
    "    \n",
    "    # 2. 定义语言模型\n",
    "    model = ChatOpenAI()\n",
    "    \n",
    "    # 3. 定义解析器\n",
    "    output_parser = StrOutputParser()\n",
    "    \n",
    "    # 4. 使用LCEL组合成一个链\n",
    "    chain = prompt | model | output_parser\n",
    "    \n",
    "    # 5. 执行链\n",
    "    response = chain.invoke({\"topic\": \"LangChain表达式语言\"})\n",
    "    print(\"\\\\n简单链示例:\")\n",
    "    print(response)\n",
    "    \n",
    "    return chain\n",
    "\n",
    "# RAG 链\n",
    "def rag_chain_example():\n",
    "    # 1. 准备文档\n",
    "    with open(\"data/rag_example.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write('''\n",
    "LangChain 表达式语言 (LCEL) 是一种声明式语言，设计用于组合链和其他组件。\n",
    "LCEL 的主要优势包括：\n",
    "1. 简洁的接口: 使用 | 操作符连接组件\n",
    "2. 异步支持: 提供同步和异步执行选项\n",
    "3. 流媒体支持: 支持流式响应\n",
    "4. 批处理支持: 可以高效处理多个输入\n",
    "5. 可重试性: 内置的重试机制\n",
    "\n",
    "LCEL 支持多种组件，包括 Runnable, Chain, PromptTemplate, ChatModel 等。\n",
    "        ''')\n",
    "    \n",
    "    # 2. 加载和分割文档\n",
    "    loader = TextLoader(\"data/rag_example.txt\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # 3. 创建向量存储\n",
    "    vectorstore = FAISS.from_documents(splits, OpenAIEmbeddings())\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    # 4. 定义RAG提示模板\n",
    "    template = \\\"\\\"\\\"使用以下上下文回答问题。如果你不知道答案，就说你不知道。\n",
    "\n",
    "上下文:\n",
    "{context}\n",
    "\n",
    "问题: {question}\n",
    "\\\"\\\"\\\"\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    # 5. 使用LCEL组合成RAG链\n",
    "    model = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    def format_docs(docs):\n",
    "        return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # 6. 执行RAG链\n",
    "    response = rag_chain.invoke(\"什么是LCEL的主要优势?\")\n",
    "    print(\"\\\\nRAG链示例:\")\n",
    "    print(response)\n",
    "    \n",
    "    return rag_chain\n",
    "\n",
    "def main():\n",
    "    # 执行简单链示例\n",
    "    simple_chain = simple_chain_example()\n",
    "    \n",
    "    # 执行RAG链示例\n",
    "    rag_chain = rag_chain_example()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# 写入LCEL示例文件\n",
    "editor.write(\"langchain_tutorial/code_examples/multi_agent_demo/lcel_example.py\", lcel_example)\n",
    "\n",
    "# 列出创建的文件\n",
    "file_structure = await terminal.run(\"find langchain_tutorial/code_examples/multi_agent_demo -type f | sort\")\n",
    "print(f\"创建的示例文件结构:\\n{file_structure}\")\n",
    "\n",
    "# 总结创建的内容\n",
    "print(\"\\n已创建LangChain多智能体工作流程示例代码，包含以下内容:\")\n",
    "print(\"1. 基础组件示例: 提示模板、语言模型、链、记忆组件\")\n",
    "print(\"2. RAG系统实现: 文档加载、分块、向量存储和检索问答\")\n",
    "print(\"3. 单智能体工作流: 使用工具增强的智能体\")\n",
    "print(\"4. 多智能体协作系统: 研究、规划、编码和测试的专家智能体组合\")\n",
    "print(\"5. LangChain表达式语言(LCEL)示例: 声明式链组合\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0d8029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:45:06.056533Z",
     "iopub.status.busy": "2025-04-07T03:45:06.056130Z",
     "iopub.status.idle": "2025-04-07T03:45:06.064209Z",
     "shell.execute_reply": "2025-04-07T03:45:06.063598Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (387482405.py, line 233)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[5], line 233\u001B[0;36m\u001B[0m\n\u001B[0;31m    code_examples = \"\"\"# LangChain 实用代码示例集\u001B[0m\n\u001B[0m                    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for the comprehensive documentation\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "\n",
    "# Create the comprehensive summary document\n",
    "summary_content = \"\"\"# LangChain 框架综合指南\n",
    "\n",
    "## 1. 框架概述\n",
    "\n",
    "LangChain 是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架，其设计目标是让开发者能够轻松构建结合外部数据、上下文感知和推理能力的智能应用。\n",
    "\n",
    "### 1.1 核心理念\n",
    "\n",
    "LangChain 的核心理念是将语言模型与其他计算资源和知识来源相结合，使 AI 应用不仅能够生成文本，还能够：\n",
    "- 访问和处理特定领域的知识\n",
    "- 与数据库和 API 交互\n",
    "- 链接多个推理步骤\n",
    "- 根据实际情况做出决策\n",
    "\n",
    "### 1.2 应用场景\n",
    "\n",
    "LangChain 框架适用于各种应用场景，包括但不限于：\n",
    "- 聊天机器人和对话系统\n",
    "- 问答系统（基于文档的问答）\n",
    "- 文本摘要与分析\n",
    "- 智能助手和代理\n",
    "- 内容生成与创意写作\n",
    "- 数据分析与解释\n",
    "\n",
    "## 2. 架构与核心组件\n",
    "\n",
    "LangChain 框架的架构由以下核心组件构成：\n",
    "\n",
    "### 2.1 模型 I/O (Model I/O)\n",
    "\n",
    "负责处理与语言模型的交互，包括：\n",
    "- **语言模型 (LLMs/Chat Models)**: 与各种 LLM 提供商（如 OpenAI, Anthropic, Hugging Face 等）的集成\n",
    "- **提示模板 (Prompt Templates)**: 创建和管理提示\n",
    "- **输出解析器 (Output Parsers)**: 将模型输出转换为结构化格式\n",
    "\n",
    "### 2.2 数据连接 (Data Connection)\n",
    "\n",
    "用于连接语言模型与各种数据源：\n",
    "- **文档加载器 (Document Loaders)**: 从各种源加载文档\n",
    "- **文档转换器 (Document Transformers)**: 分割和转换文档\n",
    "- **文本嵌入模型 (Text Embedding Models)**: 将文本转换为向量表示\n",
    "- **向量存储 (Vector Stores)**: 存储和检索向量嵌入\n",
    "- **检索器 (Retrievers)**: 检索相关信息\n",
    "\n",
    "### 2.3 链 (Chains)\n",
    "\n",
    "将多个组件组合成应用程序的序列：\n",
    "- **基础链 (Basic Chains)**: 简单的串行操作\n",
    "- **顺序链 (Sequential Chains)**: 多个链按顺序执行\n",
    "- **转换链 (Transform Chains)**: 在链之间转换输入/输出\n",
    "- **用例特定链 (Use-case Specific Chains)**: 针对特定场景优化的链\n",
    "\n",
    "### 2.4 记忆 (Memory)\n",
    "\n",
    "在链的执行之间维护状态：\n",
    "- **对话记忆 (Conversation Memory)**: 记录对话历史\n",
    "- **实体记忆 (Entity Memory)**: 记录特定实体的信息\n",
    "- **长期记忆 (Long-term Memory)**: 跨会话持久化信息\n",
    "- **总结记忆 (Summary Memory)**: 维护对话摘要\n",
    "\n",
    "### 2.5 智能体 (Agents)\n",
    "\n",
    "允许语言模型决定采取的行动：\n",
    "- **智能体类型 (Agent Types)**: 如 ReAct, 工具使用, 规划与执行\n",
    "- **智能体工具 (Agent Tools)**: 智能体可以使用的功能\n",
    "- **智能体执行器 (Agent Executors)**: 控制智能体执行流程\n",
    "- **智能体工具包 (Agent Toolkits)**: 预定义的工具集合\n",
    "\n",
    "### 2.6 回调 (Callbacks)\n",
    "\n",
    "允许在链执行期间钩入中间步骤：\n",
    "- **记录 (Logging)**: 跟踪执行过程\n",
    "- **流式处理 (Streaming)**: 实时处理输出\n",
    "- **监控 (Monitoring)**: 监控执行状态\n",
    "\n",
    "## 3. LangChain 表达式语言 (LCEL)\n",
    "\n",
    "LangChain 表达式语言是一种声明式方法，用于组合链和智能体。\n",
    "\n",
    "### 3.1 基本概念\n",
    "\n",
    "- **Runnable 接口**: 所有组件统一接口\n",
    "- **管道操作符**: 使用 `|` 连接组件\n",
    "- **异步支持**: 提供同步和异步执行选项\n",
    "- **流式传输**: 支持流式响应\n",
    "- **批处理**: 高效处理多个输入\n",
    "\n",
    "### 3.2 优势\n",
    "\n",
    "- **简洁的接口**: 更清晰的组件连接方式\n",
    "- **一致的调用模式**: invoke, batch, stream 等统一方法\n",
    "- **内置错误处理**: 包含重试和回退机制\n",
    "- **扩展性**: 易于添加新组件\n",
    "\n",
    "## 4. 单智能体实现\n",
    "\n",
    "### 4.1 智能体类型\n",
    "\n",
    "1. **ReAct 智能体**: 结合推理（Reasoning）和行动（Acting）的智能体\n",
    "2. **工具调用智能体**: 专为工具调用优化的智能体\n",
    "3. **规划与执行智能体**: 先制定计划再执行的智能体\n",
    "4. **OpenAI 助手智能体**: 基于 OpenAI 助手 API 的智能体\n",
    "5. **自定义智能体**: 根据特定需求定制的智能体\n",
    "\n",
    "### 4.2 实现步骤\n",
    "\n",
    "1. **定义工具**: 创建智能体可以使用的工具\n",
    "2. **选择智能体类型**: 根据需求选择适当的智能体类型\n",
    "3. **配置智能体**: 设置提示模板和响应格式\n",
    "4. **创建执行器**: 配置智能体执行环境\n",
    "5. **运行智能体**: 处理用户查询并执行操作\n",
    "\n",
    "## 5. 多智能体编排\n",
    "\n",
    "### 5.1 多智能体架构\n",
    "\n",
    "- **协作模式**: 多个智能体协同工作的方式\n",
    "- **通信机制**: 智能体之间的信息交换\n",
    "- **角色分配**: 不同专业领域的智能体\n",
    "\n",
    "### 5.2 智能体监督\n",
    "\n",
    "- **主管智能体**: 协调其他智能体工作\n",
    "- **任务分配**: 将复杂任务分解为子任务\n",
    "- **结果整合**: 汇总各个智能体的输出\n",
    "\n",
    "### 5.3 实现方法\n",
    "\n",
    "1. **定义专家智能体**: 创建具有特定专长的智能体\n",
    "2. **设置监督机制**: 配置主管智能体\n",
    "3. **建立通信渠道**: 实现智能体之间的信息交换\n",
    "4. **制定协作流程**: 定义工作流和决策机制\n",
    "5. **执行与监控**: 启动系统并监控运行情况\n",
    "\n",
    "## 6. 搜索与检索增强生成 (RAG)\n",
    "\n",
    "### 6.1 基本概念\n",
    "\n",
    "检索增强生成 (Retrieval-Augmented Generation, RAG) 通过结合检索系统和生成模型，使语言模型能够访问外部知识。\n",
    "\n",
    "### 6.2 组件\n",
    "\n",
    "- **文档处理**: 加载、分割和处理文档\n",
    "- **嵌入生成**: 创建文本的向量表示\n",
    "- **向量存储**: 存储和索引嵌入\n",
    "- **检索系统**: 根据查询获取相关内容\n",
    "- **上下文增强**: 将检索到的内容与查询结合\n",
    "- **生成系统**: 基于增强上下文生成回答\n",
    "\n",
    "### 6.3 实现步骤\n",
    "\n",
    "1. **准备数据**: 加载和预处理文档\n",
    "2. **创建向量存储**: 生成嵌入并存储\n",
    "3. **构建检索器**: 配置检索策略\n",
    "4. **设计提示模板**: 将检索结果融入提示\n",
    "5. **配置生成模型**: 设置语言模型参数\n",
    "6. **组装 RAG 链**: 使用 LCEL 连接各组件\n",
    "7. **优化与评估**: 测试和改进系统性能\n",
    "\n",
    "## 7. 多智能体工作流设计\n",
    "\n",
    "### 7.1 工作流组件\n",
    "\n",
    "- **专家智能体**: 具有特定领域知识的智能体\n",
    "- **工具集成**: 与外部系统和数据源的连接\n",
    "- **协作机制**: 智能体之间的互动规则\n",
    "- **决策流程**: 如何做出和执行决策\n",
    "- **监控系统**: 追踪工作流执行情况\n",
    "\n",
    "### 7.2 常见模式\n",
    "\n",
    "1. **研究-规划-执行**: 先研究问题，制定计划，再执行\n",
    "2. **分解-征询-整合**: 将问题分解，征求专家意见，整合结果\n",
    "3. **反馈循环**: 执行-评估-调整的迭代过程\n",
    "4. **层级决策**: 不同层级的智能体负责不同抽象级别的决策\n",
    "\n",
    "### 7.3 实现案例\n",
    "\n",
    "多智能体系统可以包含如下角色：\n",
    "- **研究员智能体**: 收集和分析信息\n",
    "- **规划师智能体**: 制定执行计划\n",
    "- **编码员智能体**: 编写和调试代码\n",
    "- **测试员智能体**: 验证解决方案\n",
    "- **协调器**: 管理整个工作流程\n",
    "\n",
    "## 8. 最佳实践与优化\n",
    "\n",
    "### 8.1 性能优化\n",
    "\n",
    "- **批量处理**: 使用批处理减少 API 调用\n",
    "- **缓存机制**: 缓存常用查询和结果\n",
    "- **并行执行**: 并行化独立任务\n",
    "- **模型选择**: 针对不同任务使用适当的模型\n",
    "\n",
    "### 8.2 提示工程\n",
    "\n",
    "- **任务分解**: 将复杂任务分解为简单步骤\n",
    "- **上下文增强**: 提供充分的背景信息\n",
    "- **指令明确性**: 给出清晰的指令\n",
    "- **示例驱动**: 使用少样本学习\n",
    "\n",
    "### 8.3 错误处理\n",
    "\n",
    "- **异常捕获**: 处理可能的错误情况\n",
    "- **重试机制**: 为不稳定操作实现重试\n",
    "- **回退策略**: 当首选方法失败时的替代方案\n",
    "- **用户反馈**: 适当时寻求用户输入\n",
    "\n",
    "## 9. 资源与参考\n",
    "\n",
    "- **官方文档**: https://python.langchain.com/docs/introduction/\n",
    "- **GitHub 仓库**: https://github.com/langchain-ai/langchain\n",
    "- **示例集**: https://python.langchain.com/docs/use_cases/\n",
    "\"\"\"\n",
    "\n",
    "# Write the comprehensive guide\n",
    "editor.write(\"langchain_tutorial/documentation/langchain_comprehensive_guide.md\", summary_content)\n",
    "\n",
    "# Create a practical code examples library document\n",
    "code_examples = \"\"\"# LangChain 实用代码示例集\n",
    "\n",
    "## 1. 基础组件示例\n",
    "\n",
    "### 1.1 语言模型和提示模板\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5242cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:48:39.801989Z",
     "iopub.status.busy": "2025-04-07T03:48:39.801623Z",
     "iopub.status.idle": "2025-04-07T03:48:39.810295Z",
     "shell.execute_reply": "2025-04-07T03:48:39.809549Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (387482405.py, line 233)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[6], line 233\u001B[0;36m\u001B[0m\n\u001B[0;31m    code_examples = \"\"\"# LangChain 实用代码示例集\u001B[0m\n\u001B[0m                    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for the comprehensive documentation\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "\n",
    "# Create the comprehensive summary document\n",
    "summary_content = \"\"\"# LangChain 框架综合指南\n",
    "\n",
    "## 1. 框架概述\n",
    "\n",
    "LangChain 是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架，其设计目标是让开发者能够轻松构建结合外部数据、上下文感知和推理能力的智能应用。\n",
    "\n",
    "### 1.1 核心理念\n",
    "\n",
    "LangChain 的核心理念是将语言模型与其他计算资源和知识来源相结合，使 AI 应用不仅能够生成文本，还能够：\n",
    "- 访问和处理特定领域的知识\n",
    "- 与数据库和 API 交互\n",
    "- 链接多个推理步骤\n",
    "- 根据实际情况做出决策\n",
    "\n",
    "### 1.2 应用场景\n",
    "\n",
    "LangChain 框架适用于各种应用场景，包括但不限于：\n",
    "- 聊天机器人和对话系统\n",
    "- 问答系统（基于文档的问答）\n",
    "- 文本摘要与分析\n",
    "- 智能助手和代理\n",
    "- 内容生成与创意写作\n",
    "- 数据分析与解释\n",
    "\n",
    "## 2. 架构与核心组件\n",
    "\n",
    "LangChain 框架的架构由以下核心组件构成：\n",
    "\n",
    "### 2.1 模型 I/O (Model I/O)\n",
    "\n",
    "负责处理与语言模型的交互，包括：\n",
    "- **语言模型 (LLMs/Chat Models)**: 与各种 LLM 提供商（如 OpenAI, Anthropic, Hugging Face 等）的集成\n",
    "- **提示模板 (Prompt Templates)**: 创建和管理提示\n",
    "- **输出解析器 (Output Parsers)**: 将模型输出转换为结构化格式\n",
    "\n",
    "### 2.2 数据连接 (Data Connection)\n",
    "\n",
    "用于连接语言模型与各种数据源：\n",
    "- **文档加载器 (Document Loaders)**: 从各种源加载文档\n",
    "- **文档转换器 (Document Transformers)**: 分割和转换文档\n",
    "- **文本嵌入模型 (Text Embedding Models)**: 将文本转换为向量表示\n",
    "- **向量存储 (Vector Stores)**: 存储和检索向量嵌入\n",
    "- **检索器 (Retrievers)**: 检索相关信息\n",
    "\n",
    "### 2.3 链 (Chains)\n",
    "\n",
    "将多个组件组合成应用程序的序列：\n",
    "- **基础链 (Basic Chains)**: 简单的串行操作\n",
    "- **顺序链 (Sequential Chains)**: 多个链按顺序执行\n",
    "- **转换链 (Transform Chains)**: 在链之间转换输入/输出\n",
    "- **用例特定链 (Use-case Specific Chains)**: 针对特定场景优化的链\n",
    "\n",
    "### 2.4 记忆 (Memory)\n",
    "\n",
    "在链的执行之间维护状态：\n",
    "- **对话记忆 (Conversation Memory)**: 记录对话历史\n",
    "- **实体记忆 (Entity Memory)**: 记录特定实体的信息\n",
    "- **长期记忆 (Long-term Memory)**: 跨会话持久化信息\n",
    "- **总结记忆 (Summary Memory)**: 维护对话摘要\n",
    "\n",
    "### 2.5 智能体 (Agents)\n",
    "\n",
    "允许语言模型决定采取的行动：\n",
    "- **智能体类型 (Agent Types)**: 如 ReAct, 工具使用, 规划与执行\n",
    "- **智能体工具 (Agent Tools)**: 智能体可以使用的功能\n",
    "- **智能体执行器 (Agent Executors)**: 控制智能体执行流程\n",
    "- **智能体工具包 (Agent Toolkits)**: 预定义的工具集合\n",
    "\n",
    "### 2.6 回调 (Callbacks)\n",
    "\n",
    "允许在链执行期间钩入中间步骤：\n",
    "- **记录 (Logging)**: 跟踪执行过程\n",
    "- **流式处理 (Streaming)**: 实时处理输出\n",
    "- **监控 (Monitoring)**: 监控执行状态\n",
    "\n",
    "## 3. LangChain 表达式语言 (LCEL)\n",
    "\n",
    "LangChain 表达式语言是一种声明式方法，用于组合链和智能体。\n",
    "\n",
    "### 3.1 基本概念\n",
    "\n",
    "- **Runnable 接口**: 所有组件统一接口\n",
    "- **管道操作符**: 使用 `|` 连接组件\n",
    "- **异步支持**: 提供同步和异步执行选项\n",
    "- **流式传输**: 支持流式响应\n",
    "- **批处理**: 高效处理多个输入\n",
    "\n",
    "### 3.2 优势\n",
    "\n",
    "- **简洁的接口**: 更清晰的组件连接方式\n",
    "- **一致的调用模式**: invoke, batch, stream 等统一方法\n",
    "- **内置错误处理**: 包含重试和回退机制\n",
    "- **扩展性**: 易于添加新组件\n",
    "\n",
    "## 4. 单智能体实现\n",
    "\n",
    "### 4.1 智能体类型\n",
    "\n",
    "1. **ReAct 智能体**: 结合推理（Reasoning）和行动（Acting）的智能体\n",
    "2. **工具调用智能体**: 专为工具调用优化的智能体\n",
    "3. **规划与执行智能体**: 先制定计划再执行的智能体\n",
    "4. **OpenAI 助手智能体**: 基于 OpenAI 助手 API 的智能体\n",
    "5. **自定义智能体**: 根据特定需求定制的智能体\n",
    "\n",
    "### 4.2 实现步骤\n",
    "\n",
    "1. **定义工具**: 创建智能体可以使用的工具\n",
    "2. **选择智能体类型**: 根据需求选择适当的智能体类型\n",
    "3. **配置智能体**: 设置提示模板和响应格式\n",
    "4. **创建执行器**: 配置智能体执行环境\n",
    "5. **运行智能体**: 处理用户查询并执行操作\n",
    "\n",
    "## 5. 多智能体编排\n",
    "\n",
    "### 5.1 多智能体架构\n",
    "\n",
    "- **协作模式**: 多个智能体协同工作的方式\n",
    "- **通信机制**: 智能体之间的信息交换\n",
    "- **角色分配**: 不同专业领域的智能体\n",
    "\n",
    "### 5.2 智能体监督\n",
    "\n",
    "- **主管智能体**: 协调其他智能体工作\n",
    "- **任务分配**: 将复杂任务分解为子任务\n",
    "- **结果整合**: 汇总各个智能体的输出\n",
    "\n",
    "### 5.3 实现方法\n",
    "\n",
    "1. **定义专家智能体**: 创建具有特定专长的智能体\n",
    "2. **设置监督机制**: 配置主管智能体\n",
    "3. **建立通信渠道**: 实现智能体之间的信息交换\n",
    "4. **制定协作流程**: 定义工作流和决策机制\n",
    "5. **执行与监控**: 启动系统并监控运行情况\n",
    "\n",
    "## 6. 搜索与检索增强生成 (RAG)\n",
    "\n",
    "### 6.1 基本概念\n",
    "\n",
    "检索增强生成 (Retrieval-Augmented Generation, RAG) 通过结合检索系统和生成模型，使语言模型能够访问外部知识。\n",
    "\n",
    "### 6.2 组件\n",
    "\n",
    "- **文档处理**: 加载、分割和处理文档\n",
    "- **嵌入生成**: 创建文本的向量表示\n",
    "- **向量存储**: 存储和索引嵌入\n",
    "- **检索系统**: 根据查询获取相关内容\n",
    "- **上下文增强**: 将检索到的内容与查询结合\n",
    "- **生成系统**: 基于增强上下文生成回答\n",
    "\n",
    "### 6.3 实现步骤\n",
    "\n",
    "1. **准备数据**: 加载和预处理文档\n",
    "2. **创建向量存储**: 生成嵌入并存储\n",
    "3. **构建检索器**: 配置检索策略\n",
    "4. **设计提示模板**: 将检索结果融入提示\n",
    "5. **配置生成模型**: 设置语言模型参数\n",
    "6. **组装 RAG 链**: 使用 LCEL 连接各组件\n",
    "7. **优化与评估**: 测试和改进系统性能\n",
    "\n",
    "## 7. 多智能体工作流设计\n",
    "\n",
    "### 7.1 工作流组件\n",
    "\n",
    "- **专家智能体**: 具有特定领域知识的智能体\n",
    "- **工具集成**: 与外部系统和数据源的连接\n",
    "- **协作机制**: 智能体之间的互动规则\n",
    "- **决策流程**: 如何做出和执行决策\n",
    "- **监控系统**: 追踪工作流执行情况\n",
    "\n",
    "### 7.2 常见模式\n",
    "\n",
    "1. **研究-规划-执行**: 先研究问题，制定计划，再执行\n",
    "2. **分解-征询-整合**: 将问题分解，征求专家意见，整合结果\n",
    "3. **反馈循环**: 执行-评估-调整的迭代过程\n",
    "4. **层级决策**: 不同层级的智能体负责不同抽象级别的决策\n",
    "\n",
    "### 7.3 实现案例\n",
    "\n",
    "多智能体系统可以包含如下角色：\n",
    "- **研究员智能体**: 收集和分析信息\n",
    "- **规划师智能体**: 制定执行计划\n",
    "- **编码员智能体**: 编写和调试代码\n",
    "- **测试员智能体**: 验证解决方案\n",
    "- **协调器**: 管理整个工作流程\n",
    "\n",
    "## 8. 最佳实践与优化\n",
    "\n",
    "### 8.1 性能优化\n",
    "\n",
    "- **批量处理**: 使用批处理减少 API 调用\n",
    "- **缓存机制**: 缓存常用查询和结果\n",
    "- **并行执行**: 并行化独立任务\n",
    "- **模型选择**: 针对不同任务使用适当的模型\n",
    "\n",
    "### 8.2 提示工程\n",
    "\n",
    "- **任务分解**: 将复杂任务分解为简单步骤\n",
    "- **上下文增强**: 提供充分的背景信息\n",
    "- **指令明确性**: 给出清晰的指令\n",
    "- **示例驱动**: 使用少样本学习\n",
    "\n",
    "### 8.3 错误处理\n",
    "\n",
    "- **异常捕获**: 处理可能的错误情况\n",
    "- **重试机制**: 为不稳定操作实现重试\n",
    "- **回退策略**: 当首选方法失败时的替代方案\n",
    "- **用户反馈**: 适当时寻求用户输入\n",
    "\n",
    "## 9. 资源与参考\n",
    "\n",
    "- **官方文档**: https://python.langchain.com/docs/introduction/\n",
    "- **GitHub 仓库**: https://github.com/langchain-ai/langchain\n",
    "- **示例集**: https://python.langchain.com/docs/use_cases/\n",
    "\"\"\"\n",
    "\n",
    "# Write the comprehensive guide\n",
    "editor.write(\"langchain_tutorial/documentation/langchain_comprehensive_guide.md\", summary_content)\n",
    "\n",
    "# Create a practical code examples library document\n",
    "code_examples = \"\"\"# LangChain 实用代码示例集\n",
    "\n",
    "## 1. 基础组件示例\n",
    "\n",
    "### 1.1 语言模型和提示模板\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a7a80a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:52:02.134630Z",
     "iopub.status.busy": "2025-04-07T03:52:02.134355Z",
     "iopub.status.idle": "2025-04-07T03:52:02.142717Z",
     "shell.execute_reply": "2025-04-07T03:52:02.141715Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (387482405.py, line 233)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[7], line 233\u001B[0;36m\u001B[0m\n\u001B[0;31m    code_examples = \"\"\"# LangChain 实用代码示例集\u001B[0m\n\u001B[0m                    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for the comprehensive documentation\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "\n",
    "# Create the comprehensive summary document\n",
    "summary_content = \"\"\"# LangChain 框架综合指南\n",
    "\n",
    "## 1. 框架概述\n",
    "\n",
    "LangChain 是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架，其设计目标是让开发者能够轻松构建结合外部数据、上下文感知和推理能力的智能应用。\n",
    "\n",
    "### 1.1 核心理念\n",
    "\n",
    "LangChain 的核心理念是将语言模型与其他计算资源和知识来源相结合，使 AI 应用不仅能够生成文本，还能够：\n",
    "- 访问和处理特定领域的知识\n",
    "- 与数据库和 API 交互\n",
    "- 链接多个推理步骤\n",
    "- 根据实际情况做出决策\n",
    "\n",
    "### 1.2 应用场景\n",
    "\n",
    "LangChain 框架适用于各种应用场景，包括但不限于：\n",
    "- 聊天机器人和对话系统\n",
    "- 问答系统（基于文档的问答）\n",
    "- 文本摘要与分析\n",
    "- 智能助手和代理\n",
    "- 内容生成与创意写作\n",
    "- 数据分析与解释\n",
    "\n",
    "## 2. 架构与核心组件\n",
    "\n",
    "LangChain 框架的架构由以下核心组件构成：\n",
    "\n",
    "### 2.1 模型 I/O (Model I/O)\n",
    "\n",
    "负责处理与语言模型的交互，包括：\n",
    "- **语言模型 (LLMs/Chat Models)**: 与各种 LLM 提供商（如 OpenAI, Anthropic, Hugging Face 等）的集成\n",
    "- **提示模板 (Prompt Templates)**: 创建和管理提示\n",
    "- **输出解析器 (Output Parsers)**: 将模型输出转换为结构化格式\n",
    "\n",
    "### 2.2 数据连接 (Data Connection)\n",
    "\n",
    "用于连接语言模型与各种数据源：\n",
    "- **文档加载器 (Document Loaders)**: 从各种源加载文档\n",
    "- **文档转换器 (Document Transformers)**: 分割和转换文档\n",
    "- **文本嵌入模型 (Text Embedding Models)**: 将文本转换为向量表示\n",
    "- **向量存储 (Vector Stores)**: 存储和检索向量嵌入\n",
    "- **检索器 (Retrievers)**: 检索相关信息\n",
    "\n",
    "### 2.3 链 (Chains)\n",
    "\n",
    "将多个组件组合成应用程序的序列：\n",
    "- **基础链 (Basic Chains)**: 简单的串行操作\n",
    "- **顺序链 (Sequential Chains)**: 多个链按顺序执行\n",
    "- **转换链 (Transform Chains)**: 在链之间转换输入/输出\n",
    "- **用例特定链 (Use-case Specific Chains)**: 针对特定场景优化的链\n",
    "\n",
    "### 2.4 记忆 (Memory)\n",
    "\n",
    "在链的执行之间维护状态：\n",
    "- **对话记忆 (Conversation Memory)**: 记录对话历史\n",
    "- **实体记忆 (Entity Memory)**: 记录特定实体的信息\n",
    "- **长期记忆 (Long-term Memory)**: 跨会话持久化信息\n",
    "- **总结记忆 (Summary Memory)**: 维护对话摘要\n",
    "\n",
    "### 2.5 智能体 (Agents)\n",
    "\n",
    "允许语言模型决定采取的行动：\n",
    "- **智能体类型 (Agent Types)**: 如 ReAct, 工具使用, 规划与执行\n",
    "- **智能体工具 (Agent Tools)**: 智能体可以使用的功能\n",
    "- **智能体执行器 (Agent Executors)**: 控制智能体执行流程\n",
    "- **智能体工具包 (Agent Toolkits)**: 预定义的工具集合\n",
    "\n",
    "### 2.6 回调 (Callbacks)\n",
    "\n",
    "允许在链执行期间钩入中间步骤：\n",
    "- **记录 (Logging)**: 跟踪执行过程\n",
    "- **流式处理 (Streaming)**: 实时处理输出\n",
    "- **监控 (Monitoring)**: 监控执行状态\n",
    "\n",
    "## 3. LangChain 表达式语言 (LCEL)\n",
    "\n",
    "LangChain 表达式语言是一种声明式方法，用于组合链和智能体。\n",
    "\n",
    "### 3.1 基本概念\n",
    "\n",
    "- **Runnable 接口**: 所有组件统一接口\n",
    "- **管道操作符**: 使用 `|` 连接组件\n",
    "- **异步支持**: 提供同步和异步执行选项\n",
    "- **流式传输**: 支持流式响应\n",
    "- **批处理**: 高效处理多个输入\n",
    "\n",
    "### 3.2 优势\n",
    "\n",
    "- **简洁的接口**: 更清晰的组件连接方式\n",
    "- **一致的调用模式**: invoke, batch, stream 等统一方法\n",
    "- **内置错误处理**: 包含重试和回退机制\n",
    "- **扩展性**: 易于添加新组件\n",
    "\n",
    "## 4. 单智能体实现\n",
    "\n",
    "### 4.1 智能体类型\n",
    "\n",
    "1. **ReAct 智能体**: 结合推理（Reasoning）和行动（Acting）的智能体\n",
    "2. **工具调用智能体**: 专为工具调用优化的智能体\n",
    "3. **规划与执行智能体**: 先制定计划再执行的智能体\n",
    "4. **OpenAI 助手智能体**: 基于 OpenAI 助手 API 的智能体\n",
    "5. **自定义智能体**: 根据特定需求定制的智能体\n",
    "\n",
    "### 4.2 实现步骤\n",
    "\n",
    "1. **定义工具**: 创建智能体可以使用的工具\n",
    "2. **选择智能体类型**: 根据需求选择适当的智能体类型\n",
    "3. **配置智能体**: 设置提示模板和响应格式\n",
    "4. **创建执行器**: 配置智能体执行环境\n",
    "5. **运行智能体**: 处理用户查询并执行操作\n",
    "\n",
    "## 5. 多智能体编排\n",
    "\n",
    "### 5.1 多智能体架构\n",
    "\n",
    "- **协作模式**: 多个智能体协同工作的方式\n",
    "- **通信机制**: 智能体之间的信息交换\n",
    "- **角色分配**: 不同专业领域的智能体\n",
    "\n",
    "### 5.2 智能体监督\n",
    "\n",
    "- **主管智能体**: 协调其他智能体工作\n",
    "- **任务分配**: 将复杂任务分解为子任务\n",
    "- **结果整合**: 汇总各个智能体的输出\n",
    "\n",
    "### 5.3 实现方法\n",
    "\n",
    "1. **定义专家智能体**: 创建具有特定专长的智能体\n",
    "2. **设置监督机制**: 配置主管智能体\n",
    "3. **建立通信渠道**: 实现智能体之间的信息交换\n",
    "4. **制定协作流程**: 定义工作流和决策机制\n",
    "5. **执行与监控**: 启动系统并监控运行情况\n",
    "\n",
    "## 6. 搜索与检索增强生成 (RAG)\n",
    "\n",
    "### 6.1 基本概念\n",
    "\n",
    "检索增强生成 (Retrieval-Augmented Generation, RAG) 通过结合检索系统和生成模型，使语言模型能够访问外部知识。\n",
    "\n",
    "### 6.2 组件\n",
    "\n",
    "- **文档处理**: 加载、分割和处理文档\n",
    "- **嵌入生成**: 创建文本的向量表示\n",
    "- **向量存储**: 存储和索引嵌入\n",
    "- **检索系统**: 根据查询获取相关内容\n",
    "- **上下文增强**: 将检索到的内容与查询结合\n",
    "- **生成系统**: 基于增强上下文生成回答\n",
    "\n",
    "### 6.3 实现步骤\n",
    "\n",
    "1. **准备数据**: 加载和预处理文档\n",
    "2. **创建向量存储**: 生成嵌入并存储\n",
    "3. **构建检索器**: 配置检索策略\n",
    "4. **设计提示模板**: 将检索结果融入提示\n",
    "5. **配置生成模型**: 设置语言模型参数\n",
    "6. **组装 RAG 链**: 使用 LCEL 连接各组件\n",
    "7. **优化与评估**: 测试和改进系统性能\n",
    "\n",
    "## 7. 多智能体工作流设计\n",
    "\n",
    "### 7.1 工作流组件\n",
    "\n",
    "- **专家智能体**: 具有特定领域知识的智能体\n",
    "- **工具集成**: 与外部系统和数据源的连接\n",
    "- **协作机制**: 智能体之间的互动规则\n",
    "- **决策流程**: 如何做出和执行决策\n",
    "- **监控系统**: 追踪工作流执行情况\n",
    "\n",
    "### 7.2 常见模式\n",
    "\n",
    "1. **研究-规划-执行**: 先研究问题，制定计划，再执行\n",
    "2. **分解-征询-整合**: 将问题分解，征求专家意见，整合结果\n",
    "3. **反馈循环**: 执行-评估-调整的迭代过程\n",
    "4. **层级决策**: 不同层级的智能体负责不同抽象级别的决策\n",
    "\n",
    "### 7.3 实现案例\n",
    "\n",
    "多智能体系统可以包含如下角色：\n",
    "- **研究员智能体**: 收集和分析信息\n",
    "- **规划师智能体**: 制定执行计划\n",
    "- **编码员智能体**: 编写和调试代码\n",
    "- **测试员智能体**: 验证解决方案\n",
    "- **协调器**: 管理整个工作流程\n",
    "\n",
    "## 8. 最佳实践与优化\n",
    "\n",
    "### 8.1 性能优化\n",
    "\n",
    "- **批量处理**: 使用批处理减少 API 调用\n",
    "- **缓存机制**: 缓存常用查询和结果\n",
    "- **并行执行**: 并行化独立任务\n",
    "- **模型选择**: 针对不同任务使用适当的模型\n",
    "\n",
    "### 8.2 提示工程\n",
    "\n",
    "- **任务分解**: 将复杂任务分解为简单步骤\n",
    "- **上下文增强**: 提供充分的背景信息\n",
    "- **指令明确性**: 给出清晰的指令\n",
    "- **示例驱动**: 使用少样本学习\n",
    "\n",
    "### 8.3 错误处理\n",
    "\n",
    "- **异常捕获**: 处理可能的错误情况\n",
    "- **重试机制**: 为不稳定操作实现重试\n",
    "- **回退策略**: 当首选方法失败时的替代方案\n",
    "- **用户反馈**: 适当时寻求用户输入\n",
    "\n",
    "## 9. 资源与参考\n",
    "\n",
    "- **官方文档**: https://python.langchain.com/docs/introduction/\n",
    "- **GitHub 仓库**: https://github.com/langchain-ai/langchain\n",
    "- **示例集**: https://python.langchain.com/docs/use_cases/\n",
    "\"\"\"\n",
    "\n",
    "# Write the comprehensive guide\n",
    "editor.write(\"langchain_tutorial/documentation/langchain_comprehensive_guide.md\", summary_content)\n",
    "\n",
    "# Create a practical code examples library document\n",
    "code_examples = \"\"\"# LangChain 实用代码示例集\n",
    "\n",
    "## 1. 基础组件示例\n",
    "\n",
    "### 1.1 语言模型和提示模板\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde02c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:55:13.809323Z",
     "iopub.status.busy": "2025-04-07T03:55:13.809060Z",
     "iopub.status.idle": "2025-04-07T03:55:13.813343Z",
     "shell.execute_reply": "2025-04-07T03:55:13.812800Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1008979211.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[8], line 14\u001B[0;36m\u001B[0m\n\u001B[0;31m    code_examples_md = \"\"\"# LangChain 实用代码示例集\u001B[0m\n\u001B[0m                       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for the code examples document\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "\n",
    "# Create the comprehensive code examples document focusing on agents\n",
    "code_examples_md = \"\"\"# LangChain 实用代码示例集\n",
    "\n",
    "## 1. 单智能体实现模式\n",
    "\n",
    "### 1.1 基础 ReAct 智能体\n",
    "\n",
    "ReAct (Reasoning + Acting) 智能体结合了推理和行动的能力，是最常用的智能体类型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209233be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:57:53.041365Z",
     "iopub.status.busy": "2025-04-07T03:57:53.040677Z",
     "iopub.status.idle": "2025-04-07T03:57:53.046638Z",
     "shell.execute_reply": "2025-04-07T03:57:53.045804Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (4277677237.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[9], line 13\u001B[0;36m\u001B[0m\n\u001B[0;31m    code_examples_md = \"\"\"# LangChain 实用代码示例集\u001B[0m\n\u001B[0m                       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for the code examples document\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "\n",
    "# Create the comprehensive code examples document focusing on agents\n",
    "code_examples_md = \"\"\"# LangChain 实用代码示例集\n",
    "\n",
    "## 1. 单智能体实现模式\n",
    "\n",
    "### 1.1 基础 ReAct 智能体\n",
    "\n",
    "ReAct (Reasoning + Acting) 智能体结合了推理和行动的能力，是最常用的智能体类型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb66d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:00:49.740630Z",
     "iopub.status.busy": "2025-04-07T04:00:49.740172Z",
     "iopub.status.idle": "2025-04-07T04:00:49.745848Z",
     "shell.execute_reply": "2025-04-07T04:00:49.744577Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (4277677237.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[10], line 13\u001B[0;36m\u001B[0m\n\u001B[0;31m    code_examples_md = \"\"\"# LangChain 实用代码示例集\u001B[0m\n\u001B[0m                       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for the code examples document\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "\n",
    "# Create the comprehensive code examples document focusing on agents\n",
    "code_examples_md = \"\"\"# LangChain 实用代码示例集\n",
    "\n",
    "## 1. 单智能体实现模式\n",
    "\n",
    "### 1.1 基础 ReAct 智能体\n",
    "\n",
    "ReAct (Reasoning + Acting) 智能体结合了推理和行动的能力，是最常用的智能体类型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55327f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:02:01.710454Z",
     "iopub.status.busy": "2025-04-07T04:02:01.709623Z",
     "iopub.status.idle": "2025-04-07T04:02:35.310016Z",
     "shell.execute_reply": "2025-04-07T04:02:35.309003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching single agent (agent_executor) documentation from: https://python.langchain.com/docs/modules/agents/executor/\n",
      "Fetching single agent (react_agent) documentation from: https://python.langchain.com/docs/modules/agents/agent_types/react/\n",
      "Fetching single agent (openai_functions) documentation from: https://python.langchain.com/docs/modules/agents/agent_types/openai_functions/\n",
      "Fetching single agent (structured_chat) documentation from: https://python.langchain.com/docs/modules/agents/agent_types/structured_chat/\n",
      "Fetching single agent (plan_execute) documentation from: https://python.langchain.com/docs/modules/agents/agent_types/plan_and_execute/\n",
      "Fetching multi-agent orchestration (agent_supervision) documentation from: https://python.langchain.com/docs/modules/agents/agent_supervision/\n",
      "Fetching multi-agent orchestration (team_supervisor) documentation from: https://python.langchain.com/docs/modules/agents/agent_supervision/team_supervisor/\n",
      "Fetching multi-agent orchestration (manager_worker) documentation from: https://python.langchain.com/docs/modules/agents/agent_supervision/manager_worker/\n",
      "Fetching multi-agent orchestration (plan_executor) documentation from: https://python.langchain.com/docs/modules/agents/agent_supervision/planexecutor/\n",
      "Fetching multi-agent orchestration (crewai_integration) documentation from: https://python.langchain.com/docs/integrations/platforms/crewai/\n",
      "\n",
      "Created documentation files:\n",
      "\n",
      "langchain_tutorial/docs/agent_orchestration_guide.md\n",
      "langchain_tutorial/docs/agents.md\n",
      "langchain_tutorial/docs/agents/agent_executors.md\n",
      "langchain_tutorial/docs/agents/agent_overview.md\n",
      "langchain_tutorial/docs/agents/agent_supervision_multi.md\n",
      "langchain_tutorial/docs/agents/agent_types.md\n",
      "langchain_tutorial/docs/agents/executor_multi.md\n",
      "langchain_tutorial/docs/agents/toolkits.md\n",
      "langchain_tutorial/docs/agents/tools.md\n",
      "langchain_tutorial/docs/agents/tools_multi.md\n",
      "langchain_tutorial/docs/components.md\n",
      "langchain_tutorial/docs/components/chains.md\n",
      "langchain_tutorial/docs/components/memory.md\n",
      "langchain_tutorial/docs/components/model_io.md\n",
      "langchain_tutorial/docs/components/output_parsers.md\n",
      "langchain_tutorial/docs/components/prompt_templates.md\n",
      "langchain_tutorial/docs/components/retrieval.md\n",
      "langchain_tutorial/docs/document_structure.md\n",
      "langchain_tutorial/docs/lcel_cookbook.md\n",
      "langchain_tutorial/docs/lcel_interface.md\n",
      "langchain_tutorial/docs/lcel_intro.md\n",
      "langchain_tutorial/docs/multi_agent/agent_supervision.md\n",
      "langchain_tutorial/docs/multi_agent/crewai_integration.md\n",
      "langchain_tutorial/docs/multi_agent/manager_worker.md\n",
      "langchain_tutorial/docs/multi_agent/plan_executor.md\n",
      "langchain_tutorial/docs/multi_agent/team_supervisor.md\n",
      "langchain_tutorial/docs/overview.md\n",
      "langchain_tutorial/docs/search/rag_overview.md\n",
      "langchain_tutorial/docs/search/rag_retrieval.md\n",
      "langchain_tutorial/docs/search/retrieval.md\n",
      "langchain_tutorial/docs/single_agent/agent_executor.md\n",
      "langchain_tutorial/docs/single_agent/openai_functions.md\n",
      "langchain_tutorial/docs/single_agent/plan_execute.md\n",
      "langchain_tutorial/docs/single_agent/react_agent.md\n",
      "langchain_tutorial/docs/single_agent/structured_chat.md\n",
      "\n",
      "\n",
      "====== Documentation Collection Complete ======\n",
      "Collected information about:\n",
      "1. Single agent implementations - various agent types\n",
      "2. Multi-agent orchestration - supervision patterns\n",
      "3. Created a comprehensive guide on agent orchestration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 21:02:05.222 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 21:02:08.434 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 21:02:11.678 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 21:02:15.022 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 21:02:18.408 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 21:02:21.477 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 21:02:24.816 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 21:02:27.609 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 21:02:30.937 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n",
      "2025-04-06 21:02:34.091 | INFO     | metagpt.configs.supabase_config:initialize:36 - Supabase is not enabled.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from metagpt.tools.libs.web_scraping import view_page_element_to_scrape\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create dedicated directories for agent documentation\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/docs/single_agent\")\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/docs/multi_agent\")\n",
    "\n",
    "# Target URLs focused on agent orchestration\n",
    "single_agent_urls = [\n",
    "    (\"agent_executor\", \"https://python.langchain.com/docs/modules/agents/executor/\"),\n",
    "    (\"react_agent\", \"https://python.langchain.com/docs/modules/agents/agent_types/react/\"),\n",
    "    (\"openai_functions\", \"https://python.langchain.com/docs/modules/agents/agent_types/openai_functions/\"),\n",
    "    (\"structured_chat\", \"https://python.langchain.com/docs/modules/agents/agent_types/structured_chat/\"),\n",
    "    (\"plan_execute\", \"https://python.langchain.com/docs/modules/agents/agent_types/plan_and_execute/\")\n",
    "]\n",
    "\n",
    "multi_agent_urls = [\n",
    "    (\"agent_supervision\", \"https://python.langchain.com/docs/modules/agents/agent_supervision/\"),\n",
    "    (\"team_supervisor\", \"https://python.langchain.com/docs/modules/agents/agent_supervision/team_supervisor/\"),\n",
    "    (\"manager_worker\", \"https://python.langchain.com/docs/modules/agents/agent_supervision/manager_worker/\"), \n",
    "    (\"plan_executor\", \"https://python.langchain.com/docs/modules/agents/agent_supervision/planexecutor/\"),\n",
    "    (\"crewai_integration\", \"https://python.langchain.com/docs/integrations/platforms/crewai/\")\n",
    "]\n",
    "\n",
    "# Function to extract content with better handling of code examples and structure\n",
    "async def extract_doc_content(url, doc_type):\n",
    "    print(f\"Fetching {doc_type} documentation from: {url}\")\n",
    "    html_content = await view_page_element_to_scrape(\n",
    "        url=url,\n",
    "        requirement=f\"Extract all information about {doc_type} implementation, including examples and explanations\",\n",
    "        keep_links=True\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.find('main')\n",
    "    \n",
    "    content = \"\"\n",
    "    if main_content:\n",
    "        # Extract title\n",
    "        title = main_content.find('h1')\n",
    "        if title:\n",
    "            content += f\"# {title.get_text(strip=True)}\\n\\n\"\n",
    "        \n",
    "        # Process all elements sequentially to maintain structure and code examples\n",
    "        for element in main_content.find_all(['h2', 'h3', 'h4', 'p', 'pre', 'ul', 'ol', 'li', 'div']):\n",
    "            if element.name in ['h2', 'h3', 'h4']:\n",
    "                level = int(element.name[1])\n",
    "                content += f\"{'#' * level} {element.get_text(strip=True)}\\n\\n\"\n",
    "            elif element.name == 'p':\n",
    "                content += f\"{element.get_text(strip=True)}\\n\\n\"\n",
    "            elif element.name == 'pre':\n",
    "                # Check if it contains code\n",
    "                code = element.find('code')\n",
    "                if code:\n",
    "                    language = \"python\" if \"python\" in code.get('class', [''])[0] else \"\"\n",
    "                    content += f\"```{language}\\n{code.get_text()}\\n```\\n\\n\"\n",
    "                else:\n",
    "                    content += f\"```\\n{element.get_text()}\\n```\\n\\n\"\n",
    "            elif element.name in ['ul', 'ol']:\n",
    "                for li in element.find_all('li', recursive=False):\n",
    "                    content += f\"- {li.get_text(strip=True)}\\n\"\n",
    "                content += \"\\n\"\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Process single agent documentation\n",
    "for agent_type, url in single_agent_urls:\n",
    "    content = await extract_doc_content(url, f\"single agent ({agent_type})\")\n",
    "    with open(f\"langchain_tutorial/docs/single_agent/{agent_type}.md\", 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "        f.write(f\"\\n\\nSource: {url}\\n\")\n",
    "\n",
    "# Process multi-agent documentation\n",
    "for agent_type, url in multi_agent_urls:\n",
    "    content = await extract_doc_content(url, f\"multi-agent orchestration ({agent_type})\")\n",
    "    with open(f\"langchain_tutorial/docs/multi_agent/{agent_type}.md\", 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "        f.write(f\"\\n\\nSource: {url}\\n\")\n",
    "\n",
    "# Create a comprehensive guide document specifically about agent orchestration\n",
    "comprehensive_guide = \"\"\"# LangChain 智能体编排指南\n",
    "\n",
    "## 1. 单一智能体架构\n",
    "\n",
    "单一智能体架构通过将语言模型与工具和执行逻辑结合，使模型能够通过工具与外部环境交互，以解决复杂任务。\n",
    "\n",
    "### 1.1 智能体执行器 (Agent Executor)\n",
    "\n",
    "智能体执行器是实现智能体架构的核心组件，负责：\n",
    "- 管理智能体与工具之间的交互\n",
    "- 解析智能体输出\n",
    "- 执行工具调用\n",
    "- 将结果返回给智能体\n",
    "- 循环直到任务完成\n",
    "\n",
    "### 1.2 常见智能体类型\n",
    "\n",
    "LangChain提供多种智能体类型，根据不同场景选择适当的智能体类型：\n",
    "\n",
    "1. **ReAct 智能体**\n",
    "   - 结合推理和行动的智能体\n",
    "   - 适用于需要复杂推理的任务\n",
    "   - 支持链式思考过程\n",
    "\n",
    "2. **OpenAI 函数智能体**\n",
    "   - 基于 OpenAI 函数调用能力\n",
    "   - 更易于解析工具调用\n",
    "   - 更高的可靠性和更低的幻觉\n",
    "\n",
    "3. **结构化聊天智能体**\n",
    "   - 处理复杂的人类指令\n",
    "   - 增强了聊天功能\n",
    "   - 可以使用多种工具\n",
    "\n",
    "4. **计划与执行智能体**\n",
    "   - 先制定计划再执行\n",
    "   - 将任务分解为步骤\n",
    "   - 适用于复杂任务的分解\n",
    "\n",
    "## 2. 多智能体编排\n",
    "\n",
    "多智能体编排通过结合多个智能体的专业知识和能力，以协作方式解决复杂问题。\n",
    "\n",
    "### 2.1 多智能体架构模式\n",
    "\n",
    "1. **团队监督模式 (Team Supervisor)**\n",
    "   - 一个监督者智能体协调多个专家智能体\n",
    "   - 专家智能体各自解决子问题\n",
    "   - 监督者合并和整理结果\n",
    "\n",
    "2. **经理-员工模式 (Manager-Worker)**\n",
    "   - 经理智能体分配任务\n",
    "   - 员工智能体执行具体工作\n",
    "   - 层级结构的工作分配\n",
    "\n",
    "3. **计划执行模式 (Plan Executor)**\n",
    "   - 一个智能体制定详细计划\n",
    "   - 另一个智能体执行计划中的步骤\n",
    "   - 适用于需要规划的复杂任务\n",
    "\n",
    "### 2.2 智能体监督 (Agent Supervision)\n",
    "\n",
    "智能体监督是实现多智能体协作的核心机制，包括：\n",
    "- 任务分配与跟踪\n",
    "- 结果整合\n",
    "- 冲突解决\n",
    "- 错误处理和恢复\n",
    "\n",
    "### 2.3 工具共享与通信\n",
    "\n",
    "多智能体系统中工具共享和通信的关键考虑因素：\n",
    "- 工具访问权限管理\n",
    "- 智能体间通信协议\n",
    "- 中间结果共享机制\n",
    "- 知识库与上下文管理\n",
    "\n",
    "## 3. 智能体与搜索集成\n",
    "\n",
    "将搜索和检索功能集成到智能体架构中，增强智能体访问和处理信息的能力。\n",
    "\n",
    "### 3.1 智能体与RAG结合\n",
    "\n",
    "检索增强生成（RAG）与智能体结合可以：\n",
    "- 让智能体主动检索相关信息\n",
    "- 增加回答的准确性和相关性\n",
    "- 减少幻觉和错误信息\n",
    "\n",
    "### 3.2 实现模式\n",
    "\n",
    "1. **检索作为工具**\n",
    "   - 将检索器封装为智能体可用的工具\n",
    "   - 智能体主动决定何时检索信息\n",
    "\n",
    "2. **检索增强上下文**\n",
    "   - 在智能体处理前先进行检索\n",
    "   - 将检索结果作为上下文提供给智能体\n",
    "\n",
    "3. **混合方法**\n",
    "   - 结合以上两种方法\n",
    "   - 提供基础上下文并允许主动检索\n",
    "\n",
    "## 4. 多智能体工作流设计\n",
    "\n",
    "### 4.1 工作流设计原则\n",
    "\n",
    "设计多智能体工作流时应考虑：\n",
    "- 任务分解粒度\n",
    "- 智能体角色和专长定义\n",
    "- 通信频率和方式\n",
    "- 决策机制\n",
    "- 错误处理策略\n",
    "\n",
    "### 4.2 常见工作流模式\n",
    "\n",
    "1. **研究-规划-执行模式**\n",
    "   - 研究智能体收集信息\n",
    "   - 规划智能体制定计划\n",
    "   - 执行智能体实施计划\n",
    "\n",
    "2. **分析-创建-评估模式**\n",
    "   - 分析智能体理解问题\n",
    "   - 创建智能体生成解决方案\n",
    "   - 评估智能体验证解决方案\n",
    "\n",
    "3. **协作迭代模式**\n",
    "   - 多个智能体并行工作\n",
    "   - 定期同步和更新\n",
    "   - 迭代改进解决方案\n",
    "\n",
    "### 4.3 外部工具集成\n",
    "\n",
    "多智能体系统可以集成的外部工具类型：\n",
    "- 代码执行环境\n",
    "- 数据分析工具\n",
    "- 网络搜索工具\n",
    "- 文档处理工具\n",
    "- API 调用工具\n",
    "\"\"\"\n",
    "\n",
    "# Write the comprehensive guide\n",
    "editor.write(\"langchain_tutorial/docs/agent_orchestration_guide.md\", comprehensive_guide)\n",
    "\n",
    "# Check the files created\n",
    "files = await terminal.run(\"find langchain_tutorial/docs -name '*.md' | sort\")\n",
    "print(\"\\nCreated documentation files:\")\n",
    "print(files)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n====== Documentation Collection Complete ======\")\n",
    "print(\"Collected information about:\")\n",
    "print(\"1. Single agent implementations - various agent types\")\n",
    "print(\"2. Multi-agent orchestration - supervision patterns\")\n",
    "print(\"3. Created a comprehensive guide on agent orchestration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c62a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:05:54.017725Z",
     "iopub.status.busy": "2025-04-07T04:05:54.016843Z",
     "iopub.status.idle": "2025-04-07T04:05:54.040286Z",
     "shell.execute_reply": "2025-04-07T04:05:54.038418Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (1350562727.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[12], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    I'll create practical code examples that demonstrate both single agent and multi-agent orchestration patterns in LangChain. Let me focus on creating clear examples that showcase different orchestration patterns.\u001B[0m\n\u001B[0m     ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "I'll create practical code examples that demonstrate both single agent and multi-agent orchestration patterns in LangChain. Let me focus on creating clear examples that showcase different orchestration patterns.\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Create directory for code examples focusing on agent orchestration\n",
    "terminal = Terminal()\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/code_examples/agent_examples\")\n",
    "\n",
    "# First, let's create a comprehensive single agent example that demonstrates different agent types\n",
    "single_agent_example = \"\"\"# LangChain 单智能体模式示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import SerpAPIWrapper, WikipediaAPIWrapper\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\" \n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"your-serpapi-key\"  # 如果使用搜索功能\n",
    "\n",
    "# 1. ReAct 智能体示例 - 结合推理和行动的智能体\n",
    "def create_react_agent():\n",
    "    \"\"\"创建基本的ReAct智能体\"\"\"\n",
    "    # 定义工具集\n",
    "    search = SerpAPIWrapper()\n",
    "    wikipedia = WikipediaAPIWrapper()\n",
    "    python_repl = PythonREPLTool()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"搜索\",\n",
    "            func=search.run,\n",
    "            description=\"用于在网络上搜索最新信息的工具\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"维基百科\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"用于查询维基百科文章的工具\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Python解释器\",\n",
    "            func=python_repl.run,\n",
    "            description=\"用于执行Python代码的工具，可以进行计算或数据分析\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 创建LLM\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "    \n",
    "    # 创建记忆组件\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    \n",
    "    # 初始化ReAct智能体\n",
    "    agent = initialize_agent(\n",
    "        tools, \n",
    "        llm, \n",
    "        agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 2. OpenAI函数智能体示例 - 专为函数调用设计的智能体\n",
    "def create_openai_functions_agent():\n",
    "    \"\"\"创建基于OpenAI函数调用的智能体\"\"\"\n",
    "    # 定义工具集\n",
    "    python_repl = PythonAstREPLTool()\n",
    "    wikipedia = WikipediaAPIWrapper()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Python执行器\",\n",
    "            func=python_repl.run,\n",
    "            description=\"执行Python代码的安全工具，适合进行计算、数据处理\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"维基百科\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"搜索维基百科文章的工具，适合查询事实性信息\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 创建LLM\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "    \n",
    "    # 初始化OpenAI函数智能体\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.OPENAI_FUNCTIONS,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 3. 计划与执行智能体 - 先规划后执行的智能体\n",
    "from langchain.agents import create_plan_and_execute_agent\n",
    "from langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain.tools.playwright.utils import create_async_playwright_browser\n",
    "\n",
    "def create_planner_agent():\n",
    "    \"\"\"创建计划与执行智能体\"\"\"\n",
    "    # 创建LLM\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "    \n",
    "    # 定义简单工具集\n",
    "    wikipedia = WikipediaAPIWrapper()\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"维基百科\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"搜索维基百科文章的工具\"\n",
    "        ),\n",
    "        PythonREPLTool()\n",
    "    ]\n",
    "    \n",
    "    # 创建计划与执行智能体\n",
    "    agent = create_plan_and_execute_agent(\n",
    "        llm=llm,\n",
    "        tools=tools,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 4. 自定义智能体工具示例\n",
    "class WeatherTool(BaseTool):\n",
    "    name = \"天气查询\"\n",
    "    description = \"查询指定城市的天气情况\"\n",
    "    \n",
    "    def _run(self, city: str) -> str:\n",
    "        # 模拟天气API调用\n",
    "        return f\"{city}的天气: 晴朗, 25°C, 湿度50%\"\n",
    "        \n",
    "    async def _arun(self, city: str) -> str:\n",
    "        return self._run(city)\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    name = \"计算器\"\n",
    "    description = \"进行数学计算，输入应为数学表达式\"\n",
    "    \n",
    "    def _run(self, expression: str) -> str:\n",
    "        try:\n",
    "            result = eval(expression)\n",
    "            return f\"计算结果: {result}\"\n",
    "        except Exception as e:\n",
    "            return f\"计算错误: {str(e)}\"\n",
    "            \n",
    "    async def _arun(self, expression: str) -> str:\n",
    "        return self._run(expression)\n",
    "\n",
    "def create_custom_tool_agent():\n",
    "    \"\"\"创建带有自定义工具的智能体\"\"\"\n",
    "    tools = [\n",
    "        WeatherTool(),\n",
    "        CalculatorTool(),\n",
    "        PythonREPLTool()\n",
    "    ]\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain 单智能体模式示例 ===\")\n",
    "    \n",
    "    # 选择要演示的智能体类型 \n",
    "    agent_type = \"react\"  # 可选: \"react\", \"openai_functions\", \"planner\", \"custom\"\n",
    "    \n",
    "    if agent_type == \"react\":\n",
    "        agent = create_react_agent()\n",
    "        response = agent.run(\n",
    "            \"谁是阿尔伯特·爱因斯坦? 他出生于哪一年? 计算从他出生到现在过了多少年。\"\n",
    "        )\n",
    "    elif agent_type == \"openai_functions\":\n",
    "        agent = create_openai_functions_agent() \n",
    "        response = agent.run(\n",
    "            \"计算 2345 + 5678 的结果，并解释这两个数字的数学特性。\"\n",
    "        )\n",
    "    elif agent_type == \"planner\":\n",
    "        agent = create_planner_agent()\n",
    "        response = agent.run(\n",
    "            \"查找关于人工智能的信息，然后编写一个Python函数来总结这些信息的关键点。\"\n",
    "        )\n",
    "    elif agent_type == \"custom\":\n",
    "        agent = create_custom_tool_agent()\n",
    "        response = agent.run(\n",
    "            \"北京的天气如何？然后计算25乘以4的结果。\"\n",
    "        )\n",
    "        \n",
    "    print(f\"\\\\n最终回答: {response}\")\n",
    "\"\"\"\n",
    "\n",
    "# Now, let's create a multi-agent orchestration example showing different patterns\n",
    "multi_agent_example = \"\"\"# LangChain 多智能体编排模式示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "# 1. 团队监督者模式 (Team Supervisor)\n",
    "class TeamSupervisorSystem:\n",
    "    \"\"\"\n",
    "    团队监督者模式 - 一个监督者智能体协调多个专家智能体\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "        \n",
    "        # 创建专家智能体\n",
    "        self.researcher = self._create_researcher_agent()\n",
    "        self.coder = self._create_coder_agent()\n",
    "        self.critic = self._create_critic_agent()\n",
    "        \n",
    "        # 创建监督者\n",
    "        self.supervisor = self._create_supervisor_agent()\n",
    "    \n",
    "    def _create_researcher_agent(self):\n",
    "        \"\"\"创建研究员智能体\"\"\"\n",
    "        wikipedia = WikipediaAPIWrapper()\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"维基百科\",\n",
    "                func=wikipedia.run,\n",
    "                description=\"用于查询事实性信息的维基百科工具\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def _create_coder_agent(self):\n",
    "        \"\"\"创建编码员智能体\"\"\"\n",
    "        tools = [PythonREPLTool()]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def _create_critic_agent(self):\n",
    "        \"\"\"创建评论员智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一位严格的评论家。请评估以下解决方案的质量、正确性和效率：\\\\n{solution}\\\\n请提供详细的改进建议。\",\n",
    "            input_variables=[\"solution\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt, verbose=True)\n",
    "    \n",
    "    def _create_supervisor_agent(self):\n",
    "        \"\"\"创建监督者智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一个团队领导，负责协调其他专家完成任务。你需要将复杂问题分解成子任务，分配给适当的专家，并整合他们的工作。\\\\n\\\\n任务描述: {task}\\\\n\\\\n请制定一个计划，说明如何将这个任务分解并分配给团队成员（研究员、编码员、评论员）。\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def run(self, task: str) -> Dict[str, Any]:\n",
    "        \"\"\"运行团队监督者系统\"\"\"\n",
    "        print(\"\\\\n===== 团队监督者模式 =====\")\n",
    "        print(f\"任务: {task}\")\n",
    "        \n",
    "        # 1. 监督者分配任务\n",
    "        print(\"\\\\n1. 监督者制定计划\")\n",
    "        plan = self.supervisor.run(task=task)\n",
    "        print(f\"\\\\n计划:\\\\n{plan}\")\n",
    "        \n",
    "        # 2. 研究员收集信息\n",
    "        print(\"\\\\n2. 研究员收集信息\")\n",
    "        research_query = f\"请查询关于以下内容的事实性信息: {task}\"\n",
    "        research_result = self.researcher.run(research_query)\n",
    "        print(f\"\\\\n研究结果:\\\\n{research_result}\")\n",
    "        \n",
    "        # 3. 编码员根据研究结果实现解决方案\n",
    "        print(\"\\\\n3. 编码员实现解决方案\")\n",
    "        coding_task = f\"根据以下研究结果，编写Python代码解决问题: {task}\\\\n\\\\n研究信息: {research_result}\"\n",
    "        code_solution = self.coder.run(coding_task)\n",
    "        print(f\"\\\\n代码解决方案:\\\\n{code_solution}\")\n",
    "        \n",
    "        # 4. 评论员评估解决方案\n",
    "        print(\"\\\\n4. 评论员评估解决方案\")\n",
    "        critique = self.critic.run(solution=code_solution)\n",
    "        print(f\"\\\\n评估意见:\\\\n{critique}\")\n",
    "        \n",
    "        # 5. 监督者整合结果\n",
    "        print(\"\\\\n5. 监督者整合最终结果\")\n",
    "        final_prompt = f\"请整合以下信息，提供最终的解决方案和总结：\\\\n\\\\n原始任务: {task}\\\\n\\\\n研究结果: {research_result}\\\\n\\\\n代码解决方案: {code_solution}\\\\n\\\\n评估意见: {critique}\"\n",
    "        final_solution = self.llm.predict(final_prompt)\n",
    "        print(f\"\\\\n最终解决方案:\\\\n{final_solution}\")\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"plan\": plan,\n",
    "            \"research\": research_result,\n",
    "            \"code\": code_solution,\n",
    "            \"critique\": critique,\n",
    "            \"final_solution\": final_solution\n",
    "        }\n",
    "\n",
    "# 2. 经理-员工模式 (Manager-Worker)\n",
    "class ManagerWorkerSystem:\n",
    "    \"\"\"\n",
    "    经理-员工模式 - 经理智能体分配任务给员工智能体\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        \n",
    "        # 创建经理智能体\n",
    "        self.manager = self._create_manager_agent()\n",
    "        \n",
    "        # 创建员工智能体\n",
    "        self.workers = {\n",
    "            \"researcher\": self._create_worker(\"researcher\", \"执行研究任务，查找和分析信息\"),\n",
    "            \"analyst\": self._create_worker(\"analyst\", \"分析数据并提供洞察\"),\n",
    "            \"coder\": self._create_worker(\"coder\", \"编写和调试代码\"),\n",
    "            \"writer\": self._create_worker(\"writer\", \"撰写报告和文档\")\n",
    "        }\n",
    "    \n",
    "    def _create_manager_agent(self):\n",
    "        \"\"\"创建经理智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一位项目经理，负责将大型任务分解为子任务并分配给适当的员工。\\\\n\\\\n可用员工: researcher(研究员), analyst(分析师), coder(程序员), writer(作家)\\\\n\\\\n任务: {task}\\\\n\\\\n请将此任务分解成1-4个子任务，每个子任务分配给一个员工，并提供清晰的指示。格式为JSON:\\\\n{{\\\\n  \\\"assignments\\\": [\\\\n    {{\\\\n      \\\"worker\\\": \\\"worker_name\\\",\\\\n      \\\"task\\\": \\\"task_description\\\"\\\\n    }}\\\\n  ]\\\\n}}\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def _create_worker(self, role: str, description: str):\n",
    "        \"\"\"创建员工智能体\"\"\"\n",
    "        tools = []\n",
    "        \n",
    "        # 根据角色分配不同的工具\n",
    "        if role == \"researcher\":\n",
    "            tools.append(\n",
    "                Tool(\n",
    "                    name=\"维基百科\",\n",
    "                    func=WikipediaAPIWrapper().run,\n",
    "                    description=\"查询事实性信息的工具\"\n",
    "                )\n",
    "            )\n",
    "        elif role == \"coder\":\n",
    "            tools.append(PythonREPLTool())\n",
    "        \n",
    "        # 创建员工智能体\n",
    "        worker_prompt = f\"你是一名{role}({description})。你需要完成分配给你的任务并提供详细的结果。\"\n",
    "        \n",
    "        if tools:\n",
    "            return initialize_agent(\n",
    "                tools,\n",
    "                self.llm,\n",
    "                agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "                verbose=True,\n",
    "                agent_kwargs={\"system_message\": worker_prompt}\n",
    "            )\n",
    "        else:\n",
    "            # 对于不需要特殊工具的角色，使用简单链\n",
    "            prompt = PromptTemplate(\n",
    "                template=f\"{worker_prompt}\\\\n\\\\n任务: {{task}}\\\\n\\\\n请提供你的解决方案:\",\n",
    "                input_variables=[\"task\"]\n",
    "            )\n",
    "            return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def run(self, task: str) -> Dict[str, Any]:\n",
    "        \"\"\"运行经理-员工系统\"\"\"\n",
    "        print(\"\\\\n===== 经理-员工模式 =====\")\n",
    "        print(f\"任务: {task}\")\n",
    "        \n",
    "        # 1. 经理分配任务\n",
    "        print(\"\\\\n1. 经理分配任务\")\n",
    "        assignments_text = self.manager.run(task=task)\n",
    "        print(f\"任务分配:\\\\n{assignments_text}\")\n",
    "        \n",
    "        # 简单解析JSON (实际应用中应使用更健壮的方法)\n",
    "        import json\n",
    "        try:\n",
    "            assignments = json.loads(assignments_text)[\"assignments\"]\n",
    "        except:\n",
    "            # 如果解析失败，使用备用方案\n",
    "            print(\"无法解析任务分配，使用备用方案\")\n",
    "            assignments = [\n",
    "                {\"worker\": \"researcher\", \"task\": f\"研究关于: {task}\"},\n",
    "                {\"worker\": \"coder\", \"task\": f\"编写代码解决: {task}\"},\n",
    "                {\"worker\": \"writer\", \"task\": f\"撰写关于{task}的报告\"}\n",
    "            ]\n",
    "        \n",
    "        # 2. 员工执行任务\n",
    "        results = {}\n",
    "        for idx, assignment in enumerate(assignments):\n",
    "            worker_name = assignment[\"worker\"]\n",
    "            worker_task = assignment[\"task\"]\n",
    "            \n",
    "            if worker_name in self.workers:\n",
    "                print(f\"\\\\n{idx+2}. {worker_name}执行任务: {worker_task}\")\n",
    "                worker = self.workers[worker_name]\n",
    "                result = worker.run(task=worker_task)\n",
    "                results[worker_name] = result\n",
    "                print(f\"\\\\n{worker_name}的结果:\\\\n{result}\")\n",
    "            else:\n",
    "                print(f\"未找到{worker_name}角色的员工\")\n",
    "        \n",
    "        # 3. 经理整合结果\n",
    "        print(\"\\\\n最后. 经理整合结果\")\n",
    "        summary_prompt = f\"以下是各员工完成的工作成果，请整合这些结果并提供最终的总结和解决方案：\\\\n\\\\n原始任务: {task}\\\\n\\\\n\"\n",
    "        \n",
    "        for worker_name, result in results.items():\n",
    "            summary_prompt += f\"{worker_name}的工作成果: {result}\\\\n\\\\n\"\n",
    "        \n",
    "        final_summary = self.llm.predict(summary_prompt)\n",
    "        print(f\"\\\\n最终总结:\\\\n{final_summary}\")\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"assignments\": assignments,\n",
    "            \"results\": results,\n",
    "            \"summary\": final_summary\n",
    "        }\n",
    "\n",
    "# 3. 计划执行模式 (Plan Executor)\n",
    "class PlanExecutorSystem:\n",
    "    \"\"\"\n",
    "    计划执行模式 - 一个智能体制定计划，另一个智能体执行计划\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        \n",
    "        # 创建规划者智能体\n",
    "        self.planner = self._create_planner()\n",
    "        \n",
    "        # 创建执行者智能体\n",
    "        self.executor = self._create_executor()\n",
    "    \n",
    "    def _create_planner(self):\n",
    "        \"\"\"创建规划者智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一位专业的规划者。请为以下任务制定一个详细的、分步骤的计划：\\\\n\\\\n任务: {task}\\\\n\\\\n请提供一个清晰的、有序的计划，每个步骤应该具体且可执行。确保计划涵盖任务的所有方面，并考虑可能的障碍和解决方案。\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def _create_executor(self):\n",
    "        \"\"\"创建执行者智能体\"\"\"\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"维基百科\",\n",
    "                func=WikipediaAPIWrapper().run,\n",
    "                description=\"用于查询信息的工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def run(self, task: str) -> Dict[str, Any]:\n",
    "        \"\"\"运行计划执行系统\"\"\"\n",
    "        print(\"\\\\n===== 计划执行模式 =====\")\n",
    "        print(f\"任务: {task}\")\n",
    "        \n",
    "        # 1. 制定计划\n",
    "        print(\"\\\\n1. 规划者制定计划\")\n",
    "        plan = self.planner.run(task=task)\n",
    "        print(f\"\\\\n计划:\\\\n{plan}\")\n",
    "        \n",
    "        # 2. 执行计划\n",
    "        print(\"\\\\n2. 执行者执行计划\")\n",
    "        execution_task = f\"根据以下计划执行任务：\\\\n\\\\n任务: {task}\\\\n\\\\n计划:\\\\n{plan}\\\\n\\\\n执行每个步骤并报告结果。\"\n",
    "        execution_result = self.executor.run(execution_task)\n",
    "        print(f\"\\\\n执行结果:\\\\n{execution_result}\")\n",
    "        \n",
    "        # 3. 总结结果\n",
    "        summary = f\"任务: {task}\\\\n\\\\n计划: {plan}\\\\n\\\\n执行结果: {execution_result}\"\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"plan\": plan,\n",
    "            \"execution_result\": execution_result,\n",
    "            \"summary\": summary\n",
    "        }\n",
    "\n",
    "# 4. RAG与智能体结合示例\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "class RAGAgentSystem:\n",
    "    \"\"\"\n",
    "    将RAG（检索增强生成）与智能体结合的系统\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.retriever = None\n",
    "        self.rag_chain = None\n",
    "        self.agent = None\n",
    "        \n",
    "    def setup_knowledge_base(self, texts: List[str]):\n",
    "        \"\"\"设置知识库\"\"\"\n",
    "        print(\"\\\\n设置RAG知识库...\")\n",
    "        \n",
    "        # 创建临时文本文件\n",
    "        import tempfile\n",
    "        import os\n",
    "        \n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        file_paths = []\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            file_path = os.path.join(temp_dir, f\"document_{i}.txt\")\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "            file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        documents = []\n",
    "        for file_path in file_paths:\n",
    "            loader = TextLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "        \n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # 创建检索器\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectordb = FAISS.from_documents(chunks, embeddings)\n",
    "        self.retriever = self.vectordb.as_retriever(\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "        \n",
    "        # 创建RAG链\n",
    "        self._create_rag_chain()\n",
    "        \n",
    "        # 创建智能体工具\n",
    "        self._create_agent_with_rag_tool()\n",
    "        \n",
    "        print(\"知识库设置完成!\")\n",
    "        \n",
    "    def _create_rag_chain(self):\n",
    "        \"\"\"创建RAG链\"\"\"\n",
    "        # 创建RAG提示模板\n",
    "        template = \"\"\"使用以下检索的上下文来回答问题。如果你无法从上下文中找到答案，请说明你不知道。\n",
    "        \n",
    "上下文:\n",
    "{context}\n",
    "\n",
    "问题: {question}\n",
    "\"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        \n",
    "        # 定义文档格式化函数\n",
    "        def format_docs(docs):\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建RAG链\n",
    "        self.rag_chain = (\n",
    "            {\"context\": self.retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | self.llm\n",
    "        )\n",
    "    \n",
    "    def _create_agent_with_rag_tool(self):\n",
    "        \"\"\"创建带有RAG工具的智能体\"\"\"\n",
    "        # 定义RAG工具\n",
    "        def rag_tool(query):\n",
    "            \"\"\"使用RAG系统查询知识库\"\"\"\n",
    "            result = self.rag_chain.invoke(query)\n",
    "            return result.content if hasattr(result, 'content') else str(result)\n",
    "        \n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"知识库查询\",\n",
    "                func=rag_tool,\n",
    "                description=\"当你需要查询特定领域知识时使用此工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        self.agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"运行RAG智能体系统\"\"\"\n",
    "        print(\"\\\\n===== RAG智能体系统 =====\")\n",
    "        print(f\"查询: {query}\")\n",
    "        \n",
    "        if not self.agent:\n",
    "            raise ValueError(\"请先通过setup_knowledge_base方法设置知识库\")\n",
    "        \n",
    "        result = self.agent.run(query)\n",
    "        return result\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain 多智能体编排模式示例 ===\")\n",
    "    \n",
    "    # 选择要演示的编排模式\n",
    "    orchestration_type = \"team_supervisor\"  # 可选: \"team_supervisor\", \"manager_worker\", \"plan_executor\", \"rag_agent\"\n",
    "    \n",
    "    if orchestration_type == \"team_supervisor\":\n",
    "        system = TeamSupervisorSystem()\n",
    "        result = system.run(\"创建一个简单的网站访问计数器应用\")\n",
    "        \n",
    "    elif orchestration_type == \"manager_worker\":\n",
    "        system = ManagerWorkerSystem()\n",
    "        result = system.run(\"分析2022年全球气候变化的主要趋势并创建数据可视化\")\n",
    "        \n",
    "    elif orchestration_type == \"plan_executor\":\n",
    "        system = PlanExecutorSystem()\n",
    "        result = system.run(\"研究机器学习中的过拟合问题并提供3种解决方法\")\n",
    "        \n",
    "    elif orchestration_type == \"rag_agent\":\n",
    "        system = RAGAgentSystem()\n",
    "        \n",
    "        # 设置示例知识库\n",
    "        knowledge = [\n",
    "            \\\"\\\"\\\"\n",
    "            LangChain是一个用于开发由语言模型驱动的应用程序的框架。它的主要组件包括:\n",
    "            \n",
    "            1. 模型I/O: 处理与语言模型的交互，包括提示模板和输出解析。\n",
    "            2. 检索: 从外部数据源检索数据。\n",
    "            3. 记忆: 在链的运行之间持久化状态。\n",
    "            4. 链: 将多个组件组合成一个应用程序。\n",
    "            5. 智能体: 允许LLM根据用户输入选择执行操作。\n",
    "            \n",
    "            LangChain表达式语言(LCEL)是一种声明式语言，用于组合这些组件。它使用管道操作符(|)连接组件，支持同步和异步操作，并提供错误处理和批处理功能。\n",
    "            \\\"\\\"\\\",\n",
    "            \\\"\\\"\\\"\n",
    "            多智能体系统是一种由多个智能体组成的系统，这些智能体相互协作以解决复杂问题。在LangChain中，多智能体编排可以通过以下模式实现:\n",
    "            \n",
    "            1. 团队监督模式: 一个监督者智能体协调多个专家智能体的工作。\n",
    "            2. 经理-员工模式: 一个经理智能体将任务分配给多个员工智能体。\n",
    "            3. 计划执行模式: 一个规划者智能体制定计划，执行者智能体执行计划。\n",
    "            \n",
    "            这些模式可以根据任务的复杂性和需求进行选择和组合。\n",
    "            \\\"\\\"\\\",\n",
    "            \\\"\\\"\\\"\n",
    "            检索增强生成(RAG)是将大型语言模型与外部知识库结合的技术。它的工作流程包括:\n",
    "            \n",
    "            1. 索引: 将文档分割成块并创建向量索引。\n",
    "            2. 检索: 根据查询检索相关文档片段。\n",
    "            3. 生成: 使用检索到的上下文增强LLM的回答。\n",
    "            \n",
    "            RAG可以与智能体结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac6cedad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:09:13.122480Z",
     "iopub.status.busy": "2025-04-07T04:09:13.121527Z",
     "iopub.status.idle": "2025-04-07T04:09:13.142229Z",
     "shell.execute_reply": "2025-04-07T04:09:13.141588Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (1670564751.py, line 304)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[13], line 304\u001B[0;36m\u001B[0m\n\u001B[0;31m    \"\"\"计划执行模式 - 一个智能体制定计划，另一个智能体执行计划\"\"\"\u001B[0m\n\u001B[0m                         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "source": [
    "[reflection on previous impl]\n",
    "In the previous implementation, I tried to create comprehensive code examples for both single agent and multi-agent orchestration patterns in LangChain. However, the code ended with a syntax error: \"unterminated string literal\". \n",
    "\n",
    "Looking closely at the error, I notice that I used triple quotes (`\"\"\"`) for the multi-line strings within the knowledge list but didn't properly close the RAG knowledge example. The last text block was cut off at \"RAG可以与智能体结\" without closing the triple quotes, which caused the syntax error.\n",
    "\n",
    "Additionally, there appears to be an issue with how I'm escaping special characters in the embedded strings. In Python, when using triple-quoted strings inside a triple-quoted string, we need to ensure proper escaping to avoid syntax errors.\n",
    "\n",
    "[improved impl]:\n",
    "```python\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directories for code examples\n",
    "async def create_agent_examples():\n",
    "    # Create directories\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/code_examples/agent_examples\")\n",
    "    \n",
    "    # Create single agent examples file\n",
    "    single_agent_code = '''# LangChain 单智能体模式示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\" \n",
    "\n",
    "# 1. ReAct 智能体示例 - 结合推理和行动的智能体\n",
    "def create_react_agent():\n",
    "    \"\"\"创建基本的ReAct智能体\"\"\"\n",
    "    # 定义工具集\n",
    "    wikipedia = WikipediaAPIWrapper()\n",
    "    python_repl = PythonREPLTool()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"维基百科\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"用于查询维基百科文章的工具\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Python解释器\",\n",
    "            func=python_repl.run,\n",
    "            description=\"用于执行Python代码的工具，可以进行计算或数据分析\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 创建LLM\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    # 创建记忆组件\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    \n",
    "    # 初始化ReAct智能体\n",
    "    agent = initialize_agent(\n",
    "        tools, \n",
    "        llm, \n",
    "        agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 2. OpenAI函数智能体示例 - 专为函数调用设计的智能体\n",
    "def create_openai_functions_agent():\n",
    "    \"\"\"创建基于OpenAI函数调用的智能体\"\"\"\n",
    "    # 定义工具集\n",
    "    wikipedia = WikipediaAPIWrapper()\n",
    "    python_repl = PythonREPLTool()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Python执行器\",\n",
    "            func=python_repl.run,\n",
    "            description=\"执行Python代码的工具，适合进行计算、数据处理\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"维基百科\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"搜索维基百科文章的工具，适合查询事实性信息\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 创建LLM\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    # 初始化OpenAI函数智能体\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.OPENAI_FUNCTIONS,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 3. 自定义智能体工具示例\n",
    "class WeatherTool(BaseTool):\n",
    "    name = \"天气查询\"\n",
    "    description = \"查询指定城市的天气情况\"\n",
    "    \n",
    "    def _run(self, city: str) -> str:\n",
    "        # 模拟天气API调用\n",
    "        return f\"{city}的天气: 晴朗, 25°C, 湿度50%\"\n",
    "        \n",
    "    async def _arun(self, city: str) -> str:\n",
    "        return self._run(city)\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    name = \"计算器\"\n",
    "    description = \"进行数学计算，输入应为数学表达式\"\n",
    "    \n",
    "    def _run(self, expression: str) -> str:\n",
    "        try:\n",
    "            result = eval(expression)\n",
    "            return f\"计算结果: {result}\"\n",
    "        except Exception as e:\n",
    "            return f\"计算错误: {str(e)}\"\n",
    "            \n",
    "    async def _arun(self, expression: str) -> str:\n",
    "        return self._run(expression)\n",
    "\n",
    "def create_custom_tool_agent():\n",
    "    \"\"\"创建带有自定义工具的智能体\"\"\"\n",
    "    tools = [\n",
    "        WeatherTool(),\n",
    "        CalculatorTool(),\n",
    "        PythonREPLTool()\n",
    "    ]\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain 单智能体模式示例 ===\")\n",
    "    \n",
    "    # 选择要演示的智能体类型 \n",
    "    agent_type = \"react\"  # 可选: \"react\", \"openai_functions\", \"custom\"\n",
    "    \n",
    "    if agent_type == \"react\":\n",
    "        agent = create_react_agent()\n",
    "        response = agent.run(\n",
    "            \"谁是阿尔伯特·爱因斯坦? 他出生于哪一年? 计算从他出生到现在过了多少年。\"\n",
    "        )\n",
    "    elif agent_type == \"openai_functions\":\n",
    "        agent = create_openai_functions_agent() \n",
    "        response = agent.run(\n",
    "            \"计算 2345 + 5678 的结果，并解释这两个数字的数学特性。\"\n",
    "        )\n",
    "    elif agent_type == \"custom\":\n",
    "        agent = create_custom_tool_agent()\n",
    "        response = agent.run(\n",
    "            \"北京的天气如何？然后计算25乘以4的结果。\"\n",
    "        )\n",
    "        \n",
    "    print(f\"\\\\n最终回答: {response}\")\n",
    "'''\n",
    "\n",
    "    # Create multi-agent examples file\n",
    "    multi_agent_code = '''# LangChain 多智能体编排模式示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "# 1. 团队监督者模式 (Team Supervisor)\n",
    "class TeamSupervisorSystem:\n",
    "    \"\"\"团队监督者模式 - 一个监督者智能体协调多个专家智能体\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        \n",
    "        # 创建专家智能体\n",
    "        self.researcher = self._create_researcher_agent()\n",
    "        self.coder = self._create_coder_agent()\n",
    "        self.critic = self._create_critic_agent()\n",
    "        \n",
    "        # 创建监督者\n",
    "        self.supervisor = self._create_supervisor_agent()\n",
    "    \n",
    "    def _create_researcher_agent(self):\n",
    "        \"\"\"创建研究员智能体\"\"\"\n",
    "        wikipedia = WikipediaAPIWrapper()\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"维基百科\",\n",
    "                func=wikipedia.run,\n",
    "                description=\"用于查询事实性信息的维基百科工具\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def _create_coder_agent(self):\n",
    "        \"\"\"创建编码员智能体\"\"\"\n",
    "        tools = [PythonREPLTool()]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def _create_critic_agent(self):\n",
    "        \"\"\"创建评论员智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一位严格的评论家。请评估以下解决方案的质量、正确性和效率：\\\\n{solution}\\\\n请提供详细的改进建议。\",\n",
    "            input_variables=[\"solution\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt, verbose=True)\n",
    "    \n",
    "    def _create_supervisor_agent(self):\n",
    "        \"\"\"创建监督者智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一个团队领导，负责协调其他专家完成任务。你需要将复杂问题分解成子任务，分配给适当的专家，并整合他们的工作。\\\\n\\\\n任务描述: {task}\\\\n\\\\n请制定一个计划，说明如何将这个任务分解并分配给团队成员（研究员、编码员、评论员）。\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def run(self, task: str) -> Dict[str, Any]:\n",
    "        \"\"\"运行团队监督者系统\"\"\"\n",
    "        print(\"\\\\n===== 团队监督者模式 =====\")\n",
    "        print(f\"任务: {task}\")\n",
    "        \n",
    "        # 1. 监督者分配任务\n",
    "        print(\"\\\\n1. 监督者制定计划\")\n",
    "        plan = self.supervisor.run(task=task)\n",
    "        print(f\"\\\\n计划:\\\\n{plan}\")\n",
    "        \n",
    "        # 2. 研究员收集信息\n",
    "        print(\"\\\\n2. 研究员收集信息\")\n",
    "        research_query = f\"请查询关于以下内容的事实性信息: {task}\"\n",
    "        research_result = self.researcher.run(research_query)\n",
    "        print(f\"\\\\n研究结果:\\\\n{research_result}\")\n",
    "        \n",
    "        # 3. 编码员根据研究结果实现解决方案\n",
    "        print(\"\\\\n3. 编码员实现解决方案\")\n",
    "        coding_task = f\"根据以下研究结果，编写Python代码解决问题: {task}\\\\n\\\\n研究信息: {research_result}\"\n",
    "        code_solution = self.coder.run(coding_task)\n",
    "        print(f\"\\\\n代码解决方案:\\\\n{code_solution}\")\n",
    "        \n",
    "        # 4. 评论员评估解决方案\n",
    "        print(\"\\\\n4. 评论员评估解决方案\")\n",
    "        critique = self.critic.run(solution=code_solution)\n",
    "        print(f\"\\\\n评估意见:\\\\n{critique}\")\n",
    "        \n",
    "        # 5. 监督者整合结果\n",
    "        print(\"\\\\n5. 监督者整合最终结果\")\n",
    "        final_prompt = f\"请整合以下信息，提供最终的解决方案和总结：\\\\n\\\\n原始任务: {task}\\\\n\\\\n研究结果: {research_result}\\\\n\\\\n代码解决方案: {code_solution}\\\\n\\\\n评估意见: {critique}\"\n",
    "        final_solution = self.llm.predict(final_prompt)\n",
    "        print(f\"\\\\n最终解决方案:\\\\n{final_solution}\")\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"plan\": plan,\n",
    "            \"research\": research_result,\n",
    "            \"code\": code_solution,\n",
    "            \"critique\": critique,\n",
    "            \"final_solution\": final_solution\n",
    "        }\n",
    "\n",
    "# 2. 计划执行模式 (Plan Executor)\n",
    "class PlanExecutorSystem:\n",
    "    \"\"\"计划执行模式 - 一个智能体制定计划，另一个智能体执行计划\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        \n",
    "        # 创建规划者智能体\n",
    "        self.planner = self._create_planner()\n",
    "        \n",
    "        # 创建执行者智能体\n",
    "        self.executor = self._create_executor()\n",
    "    \n",
    "    def _create_planner(self):\n",
    "        \"\"\"创建规划者智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一位专业的规划者。请为以下任务制定一个详细的、分步骤的计划：\\\\n\\\\n任务: {task}\\\\n\\\\n请提供一个清晰的、有序的计划，每个步骤应该具体且可执行。确保计划涵盖任务的所有方面，并考虑可能的障碍和解决方案。\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def _create_executor(self):\n",
    "        \"\"\"创建执行者智能体\"\"\"\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"维基百科\",\n",
    "                func=WikipediaAPIWrapper().run,\n",
    "                description=\"用于查询信息的工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def run(self, task: str) -> Dict[str, Any]:\n",
    "        \"\"\"运行计划执行系统\"\"\"\n",
    "        print(\"\\\\n===== 计划执行模式 =====\")\n",
    "        print(f\"任务: {task}\")\n",
    "        \n",
    "        # 1. 制定计划\n",
    "        print(\"\\\\n1. 规划者制定计划\")\n",
    "        plan = self.planner.run(task=task)\n",
    "        print(f\"\\\\n计划:\\\\n{plan}\")\n",
    "        \n",
    "        # 2. 执行计划\n",
    "        print(\"\\\\n2. 执行者执行计划\")\n",
    "        execution_task = f\"根据以下计划执行任务：\\\\n\\\\n任务: {task}\\\\n\\\\n计划:\\\\n{plan}\\\\n\\\\n执行每个步骤并报告结果。\"\n",
    "        execution_result = self.executor.run(execution_task)\n",
    "        print(f\"\\\\n执行结果:\\\\n{execution_result}\")\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"plan\": plan,\n",
    "            \"execution_result\": execution_result\n",
    "        }\n",
    "\n",
    "# 3. RAG与智能体结合示例\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "class RAGAgentSystem:\n",
    "    \"\"\"将RAG（检索增强生成）与智能体结合的系统\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.retriever = None\n",
    "        self.rag_chain = None\n",
    "        self.agent = None\n",
    "        \n",
    "    def setup_knowledge_base(self, texts):\n",
    "        \"\"\"设置知识库\"\"\"\n",
    "        print(\"\\\\n设置RAG知识库...\")\n",
    "        \n",
    "        # 创建临时文本文件\n",
    "        import tempfile\n",
    "        import os\n",
    "        \n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        file_paths = []\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            file_path = os.path.join(temp_dir, f\"document_{i}.txt\")\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "            file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        documents = []\n",
    "        for file_path in file_paths:\n",
    "            loader = TextLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "        \n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # 创建检索器\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectordb = FAISS.from_documents(chunks, embeddings)\n",
    "        self.retriever = self.vectordb.as_retriever(\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "        \n",
    "        # 创建RAG链\n",
    "        self._create_rag_chain()\n",
    "        \n",
    "        # 创建智能体工具\n",
    "        self._create_agent_with_rag_tool()\n",
    "        \n",
    "        print(\"知识库设置完成!\")\n",
    "        \n",
    "    def _create_rag_chain(self):\n",
    "        \"\"\"创建RAG链\"\"\"\n",
    "        # 创建RAG提示模板\n",
    "        template = \"\"\"使用以下检索的上下文来回答问题。如果你无法从上下文中找到答案，请说明你不知道。\n",
    "        \n",
    "上下文:\n",
    "{context}\n",
    "\n",
    "问题: {question}\n",
    "\"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        \n",
    "        # 定义文档格式化函数\n",
    "        def format_docs(docs):\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建RAG链\n",
    "        self.rag_chain = (\n",
    "            {\"context\": self.retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | self.llm\n",
    "        )\n",
    "    \n",
    "    def _create_agent_with_rag_tool(self):\n",
    "        \"\"\"创建带有RAG工具的智能体\"\"\"\n",
    "        # 定义RAG工具\n",
    "        def rag_tool(query):\n",
    "            \"\"\"使用RAG系统查询知识库\"\"\"\n",
    "            result = self.rag_chain.invoke(query)\n",
    "            return result.content if hasattr(result, 'content') else str(result)\n",
    "        \n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"知识库查询\",\n",
    "                func=rag_tool,\n",
    "                description=\"当你需要查询特定领域知识时使用此工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        self.agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        \"\"\"运行RAG智能体系统\"\"\"\n",
    "        print(\"\\\\n===== RAG智能体系统 =====\")\n",
    "        print(f\"查询: {query}\")\n",
    "        \n",
    "        if not self.agent:\n",
    "            raise ValueError(\"请先通过setup_knowledge_base方法设置知识库\")\n",
    "        \n",
    "        result = self.agent.run(query)\n",
    "        return result\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain 多智能体编排模式示例 ===\")\n",
    "    \n",
    "    # 选择要演示的编排模式\n",
    "    orchestration_type = \"team_supervisor\"  # 可选: \"team_supervisor\", \"plan_executor\", \"rag_agent\"\n",
    "    \n",
    "    if orchestration_type == \"team_supervisor\":\n",
    "        system = TeamSupervisorSystem()\n",
    "        result = system.run(\"创建一个简单的网站访问计数器应用\")\n",
    "        \n",
    "    elif orchestration_type == \"plan_executor\":\n",
    "        system = PlanExecutorSystem()\n",
    "        result = system.run(\"研究机器学习中的过拟合问题并提供3种解决方法\")\n",
    "        \n",
    "    elif orchestration_type == \"rag_agent\":\n",
    "        system = RAGAgentSystem()\n",
    "        \n",
    "        # 设置示例知识库\n",
    "        knowledge = [\n",
    "            \"\"\"\n",
    "            LangChain是一个用于开发由语言模型驱动的应用程序的框架。它的主要组件包括:\n",
    "            \n",
    "            1. 模型I/O: 处理与语言模型的交互，包括提示模板和输出解析。\n",
    "            2. 检索: 从外部数据源检索数据。\n",
    "            3. 记忆: 在链的运行之间持久化状态。\n",
    "            4. 链: 将多个组件组合成一个应用程序。\n",
    "            5. 智能体: 允许LLM根据用户输入选择执行操作。\n",
    "            \n",
    "            LangChain表达式语言(LCEL)是一种声明式语言，用于组合这些组件。\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            多智能体系统是一种由多个智能体组成的系统，这些智能体相互协作以解决复杂问题。在LangChain中，多智能体编排可以通过以下模式实现:\n",
    "            \n",
    "            1. 团队监督模式: 一个监督者智能体协调多个专家智能体的工作。\n",
    "            2. 经理-员工模式: 一个经理智能体将任务分配给多个员工智能体。\n",
    "            3. 计划执行模式: 一个规划者智能体制定计划，执行者智能体执行计划。\n",
    "            \"\"\"\n",
    "        ]\n",
    "        \n",
    "        system.setup_knowledge_base(knowledge)\n",
    "        result = system.run(\"解释LangChain中的多智能体编排模式有哪些\")\n",
    "'''\n",
    "\n",
    "    # Create a RAG+Agent integration example\n",
    "    rag_agent_code = '''# LangChain RAG与智能体结合示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "import tempfile\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class RAGAgentExample:\n",
    "    \"\"\"\n",
    "    检索增强生成(RAG)与智能体结合示例\n",
    "    展示如何将RAG系统集成到智能体工作流中\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.documents = []\n",
    "        self.vector_store = None\n",
    "        self.retriever = None\n",
    "    \n",
    "    def load_documents(self, texts: List[str]):\n",
    "        \"\"\"加载文档到系统中\"\"\"\n",
    "        print(\"加载文档...\")\n",
    "        \n",
    "        # 创建临时文件\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        file_paths = []\n",
    "        \n",
    "        # 将文本写入临时文件\n",
    "        for i, text in enumerate(texts):\n",
    "            file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        for file_path in file_paths:\n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个文档\")\n",
    "    \n",
    "    def process_documents(self):\n",
    "        \"\"\"处理文档：分块和创建向量存储\"\"\"\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"请先加载文档\")\n",
    "        \n",
    "        print(\"处理文档：分块和向量化...\")\n",
    "        \n",
    "        # 分块\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "        self.retriever = self.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        print(f\"文档处理完成，共创建 {len(chunks)} 个文本块\")\n",
    "        \n",
    "        return self.retriever\n",
    "    \n",
    "    def create_standalone_rag_chain(self):\n",
    "        \"\"\"创建独立的RAG链\"\"\"\n",
    "        if not self.retriever:\n",
    "            raise ValueError(\"请先处理文档\")\n",
    "        \n",
    "        # 创建RAG提示模板\n",
    "        rag_prompt = PromptTemplate.from_template(\"\"\"\n",
    "        请使用以下检索的信息回答问题。如果检索的信息中没有答案，请说明你不知道。\n",
    "\n",
    "        检索的信息:\n",
    "        {context}\n",
    "\n",
    "        问题: {question}\n",
    "        \"\"\")\n",
    "        \n",
    "        # 定义文档格式化函数\n",
    "        def format_docs(docs):\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建RAG链\n",
    "        rag_chain = (\n",
    "            {\"context\": self.retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | rag_prompt\n",
    "            | self.llm\n",
    "        )\n",
    "        \n",
    "        return rag_chain\n",
    "    \n",
    "    def create_rag_tool(self):\n",
    "        \"\"\"将RAG系统封装为智能体工具\"\"\"\n",
    "        rag_chain = self.create_standalone_rag_chain()\n",
    "        \n",
    "        def query_knowledge_base(query: str) -> str:\n",
    "            \"\"\"查询知识库获取信息\"\"\"\n",
    "            result = rag_chain.invoke(query)\n",
    "            return result.content if hasattr(result, \"content\") else str(result)\n",
    "        \n",
    "        # 创建RAG工具\n",
    "        rag_tool = Tool(\n",
    "            name=\"知识库查询\",\n",
    "            func=query_knowledge_base,\n",
    "            description=\"当你需要查询特定领域知识时使用此工具\"\n",
    "        )\n",
    "        \n",
    "        return rag_tool\n",
    "    \n",
    "    def create_agent_with_rag(self):\n",
    "        \"\"\"创建集成RAG的智能体\"\"\"\n",
    "        # 获取RAG工具\n",
    "        rag_tool = self.create_rag_tool()\n",
    "        \n",
    "        # 添加其他工具\n",
    "        python_tool = PythonREPLTool()\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools=[rag_tool, python_tool],\n",
    "            llm=self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "        \n",
    "        return agent\n",
    "\n",
    "# 1. 直接RAG问答示例\n",
    "def run_rag_qa_example():\n",
    "    \"\"\"运行直接RAG问答示例\"\"\"\n",
    "    print(\"\\\\n===== 直接RAG问答示例 =====\")\n",
    "    \n",
    "    # 创建RAG系统\n",
    "    rag_system = RAGAgentExample()\n",
    "    \n",
    "    # 加载文档\n",
    "    documents = [\n",
    "        \"\"\"\n",
    "        LangChain是一个用于开发由语言模型驱动的应用程序的框架。它的核心组件包括:\n",
    "        \n",
    "        1. 模型I/O (Models): 与各种语言模型提供商的集成接口。\n",
    "        2. 提示管理 (Prompts): 优化和管理提示模板。 \n",
    "        3. 记忆系统 (Memory): 维护对话状态和历史。\n",
    "        4. 索引和检索 (Indexes): 使用向量存储等技术组织和检索信息。\n",
    "        5. 链 (Chains): 将多个组件串联成管道。\n",
    "        6. 智能体 (Agents): 允许LLM决定使用哪些工具来完成任务。\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        LangChain表达式语言(LCEL)是一种声明式语言，用于组合LangChain的组件。它具有以下特性:\n",
    "        \n",
    "        1. 链式API: 使用管道操作符(|)连接组件。\n",
    "        2. 并行执行: 可以同时执行多个操作并合并结果。\n",
    "        3. 错误处理: 内置重试和异常处理机制。\n",
    "        4. 批处理: 一次处理多个输入以提高效率。\n",
    "        5. 流式传输: 支持逐步生成和处理响应。\n",
    "        \n",
    "        示例: chain = prompt | llm | output_parser\n",
    "        \"\"\"\n",
    "    ]\n",
    "    rag_system.load_documents(documents)\n",
    "    rag_system.process_documents()\n",
    "    \n",
    "    # 创建RAG链\n",
    "    rag_chain = rag_system.create_standalone_rag_chain()\n",
    "    \n",
    "    # 查询\n",
    "    queries = [\n",
    "        \"LangChain的核心组件有哪些?\",\n",
    "        \"什么是LCEL，它有什么特点?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\\\n问题: {query}\")\n",
    "        response = rag_chain.invoke(query)\n",
    "        print(f\"回答: {response.content if hasattr(response, 'content') else response}\")\n",
    "\n",
    "# 2. 智能体与RAG集成示例\n",
    "def run_agent_with_rag_example():\n",
    "    \"\"\"运行智能体与RAG集成示例\"\"\"\n",
    "    print(\"\\\\n===== 智能体与RAG集成示例 =====\")\n",
    "    \n",
    "    # 创建RAG系统\n",
    "    rag_system = RAGAgentExample()\n",
    "    \n",
    "    # 加载文档\n",
    "    documents = [\n",
    "        \"\"\"\n",
    "        LangChain中的智能体系统允许语言模型使用工具来解决复杂问题。主要智能体类型包括:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "769f317c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:12:18.640375Z",
     "iopub.status.busy": "2025-04-07T04:12:18.639944Z",
     "iopub.status.idle": "2025-04-07T04:12:18.658020Z",
     "shell.execute_reply": "2025-04-07T04:12:18.656870Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (4002838069.py, line 320)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[14], line 320\u001B[0;36m\u001B[0m\n\u001B[0;31m    \"\"\"计划执行模式 - 一个智能体制定计划，另一个智能体执行计划\"\"\"\u001B[0m\n\u001B[0m                         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directories for code examples\n",
    "async def main():\n",
    "    # Create directories\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/code_examples/agent_examples\")\n",
    "    \n",
    "    # Create single agent example file\n",
    "    await create_single_agent_file()\n",
    "    \n",
    "    # Create multi-agent example file\n",
    "    await create_multi_agent_file()\n",
    "    \n",
    "    # Create RAG agent example file\n",
    "    await create_rag_agent_file()\n",
    "    \n",
    "    # List created files\n",
    "    files = await terminal.run(\"find langchain_tutorial/code_examples/agent_examples -type f | sort\")\n",
    "    print(f\"Created example files:\\n{files}\")\n",
    "    \n",
    "    print(\"\\n========== Completed ==========\")\n",
    "    print(\"Created comprehensive examples for:\")\n",
    "    print(\"1. Single agent implementation patterns\")\n",
    "    print(\"2. Multi-agent orchestration patterns\")\n",
    "    print(\"3. RAG integration with agents\")\n",
    "\n",
    "async def create_single_agent_file():\n",
    "    \"\"\"Create the single agent examples file\"\"\"\n",
    "    single_agent_content = \"\"\"# LangChain 单智能体模式示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\" \n",
    "\n",
    "# 1. ReAct 智能体示例 - 结合推理和行动的智能体\n",
    "def create_react_agent():\n",
    "    \"\"\"创建基本的ReAct智能体\"\"\"\n",
    "    # 定义工具集\n",
    "    wikipedia = WikipediaAPIWrapper()\n",
    "    python_repl = PythonREPLTool()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"维基百科\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"用于查询维基百科文章的工具\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Python解释器\",\n",
    "            func=python_repl.run,\n",
    "            description=\"用于执行Python代码的工具，可以进行计算或数据分析\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 创建LLM\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    # 创建记忆组件\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    \n",
    "    # 初始化ReAct智能体\n",
    "    agent = initialize_agent(\n",
    "        tools, \n",
    "        llm, \n",
    "        agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 2. OpenAI函数智能体示例 - 专为函数调用设计的智能体\n",
    "def create_openai_functions_agent():\n",
    "    \"\"\"创建基于OpenAI函数调用的智能体\"\"\"\n",
    "    # 定义工具集\n",
    "    wikipedia = WikipediaAPIWrapper()\n",
    "    python_repl = PythonREPLTool()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Python执行器\",\n",
    "            func=python_repl.run,\n",
    "            description=\"执行Python代码的工具，适合进行计算、数据处理\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"维基百科\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"搜索维基百科文章的工具，适合查询事实性信息\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 创建LLM\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    # 初始化OpenAI函数智能体\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.OPENAI_FUNCTIONS,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 3. 自定义智能体工具示例\n",
    "class WeatherTool(BaseTool):\n",
    "    name = \"天气查询\"\n",
    "    description = \"查询指定城市的天气情况\"\n",
    "    \n",
    "    def _run(self, city: str) -> str:\n",
    "        # 模拟天气API调用\n",
    "        return f\"{city}的天气: 晴朗, 25°C, 湿度50%\"\n",
    "        \n",
    "    async def _arun(self, city: str) -> str:\n",
    "        return self._run(city)\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    name = \"计算器\"\n",
    "    description = \"进行数学计算，输入应为数学表达式\"\n",
    "    \n",
    "    def _run(self, expression: str) -> str:\n",
    "        try:\n",
    "            result = eval(expression)\n",
    "            return f\"计算结果: {result}\"\n",
    "        except Exception as e:\n",
    "            return f\"计算错误: {str(e)}\"\n",
    "            \n",
    "    async def _arun(self, expression: str) -> str:\n",
    "        return self._run(expression)\n",
    "\n",
    "def create_custom_tool_agent():\n",
    "    \"\"\"创建带有自定义工具的智能体\"\"\"\n",
    "    tools = [\n",
    "        WeatherTool(),\n",
    "        CalculatorTool(),\n",
    "        PythonREPLTool()\n",
    "    ]\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain 单智能体模式示例 ===\")\n",
    "    \n",
    "    # 选择要演示的智能体类型 \n",
    "    agent_type = \"react\"  # 可选: \"react\", \"openai_functions\", \"custom\"\n",
    "    \n",
    "    if agent_type == \"react\":\n",
    "        agent = create_react_agent()\n",
    "        response = agent.run(\n",
    "            \"谁是阿尔伯特·爱因斯坦? 他出生于哪一年? 计算从他出生到现在过了多少年。\"\n",
    "        )\n",
    "    elif agent_type == \"openai_functions\":\n",
    "        agent = create_openai_functions_agent() \n",
    "        response = agent.run(\n",
    "            \"计算 2345 + 5678 的结果，并解释这两个数字的数学特性。\"\n",
    "        )\n",
    "    elif agent_type == \"custom\":\n",
    "        agent = create_custom_tool_agent()\n",
    "        response = agent.run(\n",
    "            \"北京的天气如何？然后计算25乘以4的结果。\"\n",
    "        )\n",
    "        \n",
    "    print(f\"\\\\n最终回答: {response}\")\n",
    "\"\"\"\n",
    "    \n",
    "    # Write the file\n",
    "    editor.write(\"langchain_tutorial/code_examples/agent_examples/single_agent_example.py\", single_agent_content)\n",
    "    print(\"Created single agent examples file\")\n",
    "\n",
    "async def create_multi_agent_file():\n",
    "    \"\"\"Create the multi-agent examples file\"\"\"\n",
    "    multi_agent_content = \"\"\"# LangChain 多智能体编排模式示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "# 1. 团队监督者模式 (Team Supervisor)\n",
    "class TeamSupervisorSystem:\n",
    "    \"\"\"团队监督者模式 - 一个监督者智能体协调多个专家智能体\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        \n",
    "        # 创建专家智能体\n",
    "        self.researcher = self._create_researcher_agent()\n",
    "        self.coder = self._create_coder_agent()\n",
    "        self.critic = self._create_critic_agent()\n",
    "        \n",
    "        # 创建监督者\n",
    "        self.supervisor = self._create_supervisor_agent()\n",
    "    \n",
    "    def _create_researcher_agent(self):\n",
    "        \"\"\"创建研究员智能体\"\"\"\n",
    "        wikipedia = WikipediaAPIWrapper()\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"维基百科\",\n",
    "                func=wikipedia.run,\n",
    "                description=\"用于查询事实性信息的维基百科工具\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def _create_coder_agent(self):\n",
    "        \"\"\"创建编码员智能体\"\"\"\n",
    "        tools = [PythonREPLTool()]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def _create_critic_agent(self):\n",
    "        \"\"\"创建评论员智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一位严格的评论家。请评估以下解决方案的质量、正确性和效率：\\\\n{solution}\\\\n请提供详细的改进建议。\",\n",
    "            input_variables=[\"solution\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt, verbose=True)\n",
    "    \n",
    "    def _create_supervisor_agent(self):\n",
    "        \"\"\"创建监督者智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一个团队领导，负责协调其他专家完成任务。你需要将复杂问题分解成子任务，分配给适当的专家，并整合他们的工作。\\\\n\\\\n任务描述: {task}\\\\n\\\\n请制定一个计划，说明如何将这个任务分解并分配给团队成员（研究员、编码员、评论员）。\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def run(self, task: str) -> Dict[str, Any]:\n",
    "        \"\"\"运行团队监督者系统\"\"\"\n",
    "        print(\"\\\\n===== 团队监督者模式 =====\")\n",
    "        print(f\"任务: {task}\")\n",
    "        \n",
    "        # 1. 监督者分配任务\n",
    "        print(\"\\\\n1. 监督者制定计划\")\n",
    "        plan = self.supervisor.run(task=task)\n",
    "        print(f\"\\\\n计划:\\\\n{plan}\")\n",
    "        \n",
    "        # 2. 研究员收集信息\n",
    "        print(\"\\\\n2. 研究员收集信息\")\n",
    "        research_query = f\"请查询关于以下内容的事实性信息: {task}\"\n",
    "        research_result = self.researcher.run(research_query)\n",
    "        print(f\"\\\\n研究结果:\\\\n{research_result}\")\n",
    "        \n",
    "        # 3. 编码员根据研究结果实现解决方案\n",
    "        print(\"\\\\n3. 编码员实现解决方案\")\n",
    "        coding_task = f\"根据以下研究结果，编写Python代码解决问题: {task}\\\\n\\\\n研究信息: {research_result}\"\n",
    "        code_solution = self.coder.run(coding_task)\n",
    "        print(f\"\\\\n代码解决方案:\\\\n{code_solution}\")\n",
    "        \n",
    "        # 4. 评论员评估解决方案\n",
    "        print(\"\\\\n4. 评论员评估解决方案\")\n",
    "        critique = self.critic.run(solution=code_solution)\n",
    "        print(f\"\\\\n评估意见:\\\\n{critique}\")\n",
    "        \n",
    "        # 5. 监督者整合结果\n",
    "        print(\"\\\\n5. 监督者整合最终结果\")\n",
    "        final_prompt = f\"请整合以下信息，提供最终的解决方案和总结：\\\\n\\\\n原始任务: {task}\\\\n\\\\n研究结果: {research_result}\\\\n\\\\n代码解决方案: {code_solution}\\\\n\\\\n评估意见: {critique}\"\n",
    "        final_solution = self.llm.predict(final_prompt)\n",
    "        print(f\"\\\\n最终解决方案:\\\\n{final_solution}\")\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"plan\": plan,\n",
    "            \"research\": research_result,\n",
    "            \"code\": code_solution,\n",
    "            \"critique\": critique,\n",
    "            \"final_solution\": final_solution\n",
    "        }\n",
    "\n",
    "# 2. 计划执行模式 (Plan Executor)\n",
    "class PlanExecutorSystem:\n",
    "    \"\"\"计划执行模式 - 一个智能体制定计划，另一个智能体执行计划\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        \n",
    "        # 创建规划者智能体\n",
    "        self.planner = self._create_planner()\n",
    "        \n",
    "        # 创建执行者智能体\n",
    "        self.executor = self._create_executor()\n",
    "    \n",
    "    def _create_planner(self):\n",
    "        \"\"\"创建规划者智能体\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一位专业的规划者。请为以下任务制定一个详细的、分步骤的计划：\\\\n\\\\n任务: {task}\\\\n\\\\n请提供一个清晰的、有序的计划，每个步骤应该具体且可执行。确保计划涵盖任务的所有方面，并考虑可能的障碍和解决方案。\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def _create_executor(self):\n",
    "        \"\"\"创建执行者智能体\"\"\"\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"维基百科\",\n",
    "                func=WikipediaAPIWrapper().run,\n",
    "                description=\"用于查询信息的工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def run(self, task: str) -> Dict[str, Any]:\n",
    "        \"\"\"运行计划执行系统\"\"\"\n",
    "        print(\"\\\\n===== 计划执行模式 =====\")\n",
    "        print(f\"任务: {task}\")\n",
    "        \n",
    "        # 1. 制定计划\n",
    "        print(\"\\\\n1. 规划者制定计划\")\n",
    "        plan = self.planner.run(task=task)\n",
    "        print(f\"\\\\n计划:\\\\n{plan}\")\n",
    "        \n",
    "        # 2. 执行计划\n",
    "        print(\"\\\\n2. 执行者执行计划\")\n",
    "        execution_task = f\"根据以下计划执行任务：\\\\n\\\\n任务: {task}\\\\n\\\\n计划:\\\\n{plan}\\\\n\\\\n执行每个步骤并报告结果。\"\n",
    "        execution_result = self.executor.run(execution_task)\n",
    "        print(f\"\\\\n执行结果:\\\\n{execution_result}\")\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"plan\": plan,\n",
    "            \"execution_result\": execution_result\n",
    "        }\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain 多智能体编排模式示例 ===\")\n",
    "    \n",
    "    # 选择要演示的编排模式\n",
    "    orchestration_type = \"team_supervisor\"  # 可选: \"team_supervisor\", \"plan_executor\"\n",
    "    \n",
    "    if orchestration_type == \"team_supervisor\":\n",
    "        system = TeamSupervisorSystem()\n",
    "        result = system.run(\"创建一个简单的网站访问计数器应用\")\n",
    "        \n",
    "    elif orchestration_type == \"plan_executor\":\n",
    "        system = PlanExecutorSystem()\n",
    "        result = system.run(\"研究机器学习中的过拟合问题并提供3种解决方法\")\n",
    "\"\"\"\n",
    "    \n",
    "    # Write the file\n",
    "    editor.write(\"langchain_tutorial/code_examples/agent_examples/multi_agent_example.py\", multi_agent_content)\n",
    "    print(\"Created multi-agent examples file\")\n",
    "\n",
    "async def create_rag_agent_file():\n",
    "    \"\"\"Create the RAG+Agent integration example file\"\"\"\n",
    "    rag_agent_content = \"\"\"# LangChain RAG与智能体结合示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "import tempfile\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class RAGAgentExample:\n",
    "    \"\"\"\n",
    "    检索增强生成(RAG)与智能体结合示例\n",
    "    展示如何将RAG系统集成到智能体工作流中\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.documents = []\n",
    "        self.vector_store = None\n",
    "        self.retriever = None\n",
    "    \n",
    "    def load_documents(self, texts: List[str]):\n",
    "        \"\"\"加载文档到系统中\"\"\"\n",
    "        print(\"加载文档...\")\n",
    "        \n",
    "        # 创建临时文件\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        file_paths = []\n",
    "        \n",
    "        # 将文本写入临时文件\n",
    "        for i, text in enumerate(texts):\n",
    "            file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        for file_path in file_paths:\n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个文档\")\n",
    "    \n",
    "    def process_documents(self):\n",
    "        \"\"\"处理文档：分块和创建向量存储\"\"\"\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"请先加载文档\")\n",
    "        \n",
    "        print(\"处理文档：分块和向量化...\")\n",
    "        \n",
    "        # 分块\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "        self.retriever = self.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        print(f\"文档处理完成，共创建 {len(chunks)} 个文本块\")\n",
    "        \n",
    "        return self.retriever\n",
    "    \n",
    "    def create_standalone_rag_chain(self):\n",
    "        \"\"\"创建独立的RAG链\"\"\"\n",
    "        if not self.retriever:\n",
    "            raise ValueError(\"请先处理文档\")\n",
    "        \n",
    "        # 创建RAG提示模板\n",
    "        rag_prompt = PromptTemplate.from_template(\\\"\\\"\\\"\n",
    "        请使用以下检索的信息回答问题。如果检索的信息中没有答案，请说明你不知道。\n",
    "\n",
    "        检索的信息:\n",
    "        {context}\n",
    "\n",
    "        问题: {question}\n",
    "        \\\"\\\"\\\")\n",
    "        \n",
    "        # 定义文档格式化函数\n",
    "        def format_docs(docs):\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建RAG链\n",
    "        rag_chain = (\n",
    "            {\"context\": self.retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | rag_prompt\n",
    "            | self.llm\n",
    "        )\n",
    "        \n",
    "        return rag_chain\n",
    "    \n",
    "    def create_rag_tool(self):\n",
    "        \"\"\"将RAG系统封装为智能体工具\"\"\"\n",
    "        rag_chain = self.create_standalone_rag_chain()\n",
    "        \n",
    "        def query_knowledge_base(query: str) -> str:\n",
    "            \"\"\"查询知识库获取信息\"\"\"\n",
    "            result = rag_chain.invoke(query)\n",
    "            return result.content if hasattr(result, \"content\") else str(result)\n",
    "        \n",
    "        # 创建RAG工具\n",
    "        rag_tool = Tool(\n",
    "            name=\"知识库查询\",\n",
    "            func=query_knowledge_base,\n",
    "            description=\"当你需要查询特定领域知识时使用此工具\"\n",
    "        )\n",
    "        \n",
    "        return rag_tool\n",
    "    \n",
    "    def create_agent_with_rag(self):\n",
    "        \"\"\"创建集成RAG的智能体\"\"\"\n",
    "        # 获取RAG工具\n",
    "        rag_tool = self.create_rag_tool()\n",
    "        \n",
    "        # 添加其他工具\n",
    "        python_tool = PythonREPLTool()\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools=[rag_tool, python_tool],\n",
    "            llm=self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "        \n",
    "        return agent\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain RAG与智能体结合示例 ===\")\n",
    "    \n",
    "    # 1. 运行直接RAG问答示例\n",
    "    print(\"\\\\n===== 直接RAG问答示例 =====\")\n",
    "    \n",
    "    # 创建RAG系统\n",
    "    rag_system = RAGAgentExample()\n",
    "    \n",
    "    # 加载文档\n",
    "    documents = [\n",
    "        \\\"\\\"\\\"\n",
    "        LangChain是一个用于开发由语言模型驱动的应用程序的框架。它的核心组件包括:\n",
    "        \n",
    "        1. 模型I/O (Models): 与各种语言模型提供商的集成接口。\n",
    "        2. 提示管理 (Prompts): 优化和管理提示模板。 \n",
    "        3. 记忆系统 (Memory): 维护对话状态和历史。\n",
    "        4. 索引和检索 (Indexes): 使用向量存储等技术组织和检索信息。\n",
    "        5. 链 (Chains): 将多个组件串联成管道。\n",
    "        6. 智能体 (Agents): 允许LLM决定使用哪些工具来完成任务。\n",
    "        \\\"\\\"\\\",\n",
    "        \\\"\\\"\\\"\n",
    "        LangChain表达式语言(LCEL)是一种声明式语言，用于组合LangChain的组件。它具有以下特性:\n",
    "        \n",
    "        1. 链式API: 使用管道操作符(|)连接组件。\n",
    "        2. 并行执行: 可以同时执行多个操作并合并结果。\n",
    "        3. 错误处理: 内置重试和异常处理机制。\n",
    "        4. 批处理: 一次处理多个输入以提高效率。\n",
    "        5. 流式传输: 支持逐步生成和处理响应。\n",
    "        \n",
    "        示例: chain = prompt | llm | output_parser\n",
    "        \\\"\\\"\\\"\n",
    "    ]\n",
    "    rag_system.load_documents(documents)\n",
    "    rag_system.process_documents()\n",
    "    \n",
    "    # 创建RAG链\n",
    "    rag_chain = rag_system.create_standalone_rag_chain()\n",
    "    \n",
    "    # 查询\n",
    "    queries = [\n",
    "        \"LangChain的核心组件有哪些?\",\n",
    "        \"什么是LCEL，它有什么特点?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\\\n问题: {query}\")\n",
    "        response = rag_chain.invoke(query)\n",
    "        print(f\"回答: {response.content if hasattr(response, 'content') else response}\")\n",
    "    \n",
    "    # 2. 运行智能体与RAG集成示例\n",
    "    print(\"\\\\n===== 智能体与RAG集成示例 =====\")\n",
    "    \n",
    "    # 创建智能体\n",
    "    agent = rag_system.create_agent_with_rag()\n",
    "    \n",
    "    # 查询\n",
    "    agent_queries = [\n",
    "        \"总结LangChain的核心组件并使用Python代码计算它们的总数\",\n",
    "        \"请解释LCEL中的管道操作符是如何工作的\"\n",
    "    ]\n",
    "    \n",
    "    for query in agent_queries:\n",
    "        print(f\"\\\\n智能体查询: {query}\")\n",
    "        response = agent.run(query)\n",
    "        print(f\"智能体回答: {response}\")\n",
    "\"\"\"\n",
    "    \n",
    "    # Write the file\n",
    "    editor.write(\"langchain_tutorial/code_examples/agent_examples/rag_agent_example.py\", rag_agent_content)\n",
    "    print(\"Created RAG agent integration example file\")\n",
    "    \n",
    "    # Create a README file for the examples\n",
    "    readme_content = \"\"\"# LangChain 智能体和多智能体编排示例\n",
    "\n",
    "本目录包含 LangChain 框架中单智能体和多智能体编排的实用示例代码。\n",
    "\n",
    "## 文件说明\n",
    "\n",
    "1. `single_agent_example.py` - 演示不同类型的单智能体实现\n",
    "   - ReAct 智能体：结合推理和行动的智能体\n",
    "   - OpenAI函数调用智能体：基于函数调用能力的智能体\n",
    "   - 自定义工具智能体：使用自定义工具的智能体\n",
    "\n",
    "2. `multi_agent_example.py` - 演示多智能体编排模式\n",
    "   - 团队监督者模式：一个监督者智能体协调多个专家智能体工作\n",
    "   - 计划执行模式：一个智能体制定计划，另一个智能体执行计划\n",
    "\n",
    "3. `rag_agent_example.py` - 演示RAG与智能体结合的实现\n",
    "   - 直接RAG问答：使用检索增强生成直接回答问题\n",
    "   - 智能体与RAG集成：智能体可以主动使用RAG工具获取知识\n",
    "\n",
    "## 使用说明\n",
    "\n",
    "1. 确保设置必要的环境变量：\n",
    "   ```python\n",
    "   os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "   ```\n",
    "\n",
    "2. 安装所需依赖：\n",
    "   ```bash\n",
    "   pip install langchain langchain_community faiss-cpu openai\n",
    "   ```\n",
    "\n",
    "3. 运行示例：\n",
    "   ```bash\n",
    "   python single_agent_example.py\n",
    "   python multi_agent_example.py\n",
    "   python rag_agent_example.py\n",
    "   ```\n",
    "\n",
    "## 注意事项\n",
    "\n",
    "- 这些示例旨在展示核心概念，实际应用时可能需要进一步配置和优化\n",
    "- 代码中的某些功能可能需要特定的API访问权限\n",
    "- RAG示例中使用了临时文件来模拟文档加载，实际应用中可以直接从真实数据源加载\n",
    "\"\"\"\n",
    "    \n",
    "    editor.write(\"langchain_tutorial/code_examples/agent_examples/README.md\", readme_content)\n",
    "    print(\"Created README file\")\n",
    "\n",
    "# Execute the main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "312d04ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:15:29.955505Z",
     "iopub.status.busy": "2025-04-07T04:15:29.955034Z",
     "iopub.status.idle": "2025-04-07T04:15:30.412631Z",
     "shell.execute_reply": "2025-04-07T04:15:30.411992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created single agent examples file\n",
      "Created multi-agent examples file\n",
      "Created RAG agent integration example file\n",
      "Created README file\n",
      "\n",
      "Created example files:\n",
      "\n",
      "langchain_tutorial/code_examples/agent_examples/README.md\n",
      "langchain_tutorial/code_examples/agent_examples/multi_agent_example.py\n",
      "langchain_tutorial/code_examples/agent_examples/rag_agent_example.py\n",
      "langchain_tutorial/code_examples/agent_examples/single_agent_example.py\n",
      "\n",
      "\n",
      "========== Code Examples Creation Complete ==========\n",
      "Created comprehensive examples for:\n",
      "1. Single agent implementation patterns\n",
      "2. Multi-agent orchestration patterns\n",
      "3. RAG integration with agents\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directories for code examples\n",
    "async def main():\n",
    "    # Create directories\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/code_examples/agent_examples\")\n",
    "    \n",
    "    # Create single agent example file\n",
    "    single_agent_content = \"\"\"# LangChain 单智能体模式示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\" \n",
    "\n",
    "# 1. ReAct 智能体示例 - 结合推理和行动的智能体\n",
    "def create_react_agent():\n",
    "    \\\"\\\"\\\"创建基本的ReAct智能体\\\"\\\"\\\"\n",
    "    # 定义工具集\n",
    "    wikipedia = WikipediaAPIWrapper()\n",
    "    python_repl = PythonREPLTool()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"维基百科\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"用于查询维基百科文章的工具\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Python解释器\",\n",
    "            func=python_repl.run,\n",
    "            description=\"用于执行Python代码的工具，可以进行计算或数据分析\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 创建LLM\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    # 创建记忆组件\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    \n",
    "    # 初始化ReAct智能体\n",
    "    agent = initialize_agent(\n",
    "        tools, \n",
    "        llm, \n",
    "        agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 2. OpenAI函数智能体示例 - 专为函数调用设计的智能体\n",
    "def create_openai_functions_agent():\n",
    "    \\\"\\\"\\\"创建基于OpenAI函数调用的智能体\\\"\\\"\\\"\n",
    "    # 定义工具集\n",
    "    wikipedia = WikipediaAPIWrapper()\n",
    "    python_repl = PythonREPLTool()\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Python执行器\",\n",
    "            func=python_repl.run,\n",
    "            description=\"执行Python代码的工具，适合进行计算、数据处理\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"维基百科\",\n",
    "            func=wikipedia.run,\n",
    "            description=\"搜索维基百科文章的工具，适合查询事实性信息\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 创建LLM\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    # 初始化OpenAI函数智能体\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.OPENAI_FUNCTIONS,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 3. 自定义智能体工具示例\n",
    "class WeatherTool(BaseTool):\n",
    "    name = \"天气查询\"\n",
    "    description = \"查询指定城市的天气情况\"\n",
    "    \n",
    "    def _run(self, city: str) -> str:\n",
    "        # 模拟天气API调用\n",
    "        return f\"{city}的天气: 晴朗, 25°C, 湿度50%\"\n",
    "        \n",
    "    async def _arun(self, city: str) -> str:\n",
    "        return self._run(city)\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    name = \"计算器\"\n",
    "    description = \"进行数学计算，输入应为数学表达式\"\n",
    "    \n",
    "    def _run(self, expression: str) -> str:\n",
    "        try:\n",
    "            result = eval(expression)\n",
    "            return f\"计算结果: {result}\"\n",
    "        except Exception as e:\n",
    "            return f\"计算错误: {str(e)}\"\n",
    "            \n",
    "    async def _arun(self, expression: str) -> str:\n",
    "        return self._run(expression)\n",
    "\n",
    "def create_custom_tool_agent():\n",
    "    \\\"\\\"\\\"创建带有自定义工具的智能体\\\"\\\"\\\"\n",
    "    tools = [\n",
    "        WeatherTool(),\n",
    "        CalculatorTool(),\n",
    "        PythonREPLTool()\n",
    "    ]\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    \n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain 单智能体模式示例 ===\")\n",
    "    \n",
    "    # 选择要演示的智能体类型 \n",
    "    agent_type = \"react\"  # 可选: \"react\", \"openai_functions\", \"custom\"\n",
    "    \n",
    "    if agent_type == \"react\":\n",
    "        agent = create_react_agent()\n",
    "        response = agent.run(\n",
    "            \"谁是阿尔伯特·爱因斯坦? 他出生于哪一年? 计算从他出生到现在过了多少年。\"\n",
    "        )\n",
    "    elif agent_type == \"openai_functions\":\n",
    "        agent = create_openai_functions_agent() \n",
    "        response = agent.run(\n",
    "            \"计算 2345 + 5678 的结果，并解释这两个数字的数学特性。\"\n",
    "        )\n",
    "    elif agent_type == \"custom\":\n",
    "        agent = create_custom_tool_agent()\n",
    "        response = agent.run(\n",
    "            \"北京的天气如何？然后计算25乘以4的结果。\"\n",
    "        )\n",
    "        \n",
    "    print(f\"\\\\n最终回答: {response}\")\n",
    "\"\"\"\n",
    "    \n",
    "    # Write the file\n",
    "    editor.write(\"langchain_tutorial/code_examples/agent_examples/single_agent_example.py\", single_agent_content)\n",
    "    print(\"Created single agent examples file\")\n",
    "\n",
    "    # Create the multi-agent examples file\n",
    "    multi_agent_content = \"\"\"# LangChain 多智能体编排模式示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "# 1. 团队监督者模式 (Team Supervisor)\n",
    "class TeamSupervisorSystem:\n",
    "    \\\"\\\"\\\"团队监督者模式 - 一个监督者智能体协调多个专家智能体\\\"\\\"\\\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        \n",
    "        # 创建专家智能体\n",
    "        self.researcher = self._create_researcher_agent()\n",
    "        self.coder = self._create_coder_agent()\n",
    "        self.critic = self._create_critic_agent()\n",
    "        \n",
    "        # 创建监督者\n",
    "        self.supervisor = self._create_supervisor_agent()\n",
    "    \n",
    "    def _create_researcher_agent(self):\n",
    "        \\\"\\\"\\\"创建研究员智能体\\\"\\\"\\\"\n",
    "        wikipedia = WikipediaAPIWrapper()\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"维基百科\",\n",
    "                func=wikipedia.run,\n",
    "                description=\"用于查询事实性信息的维基百科工具\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def _create_coder_agent(self):\n",
    "        \\\"\\\"\\\"创建编码员智能体\\\"\\\"\\\"\n",
    "        tools = [PythonREPLTool()]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def _create_critic_agent(self):\n",
    "        \\\"\\\"\\\"创建评论员智能体\\\"\\\"\\\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一位严格的评论家。请评估以下解决方案的质量、正确性和效率：\\\\n{solution}\\\\n请提供详细的改进建议。\",\n",
    "            input_variables=[\"solution\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt, verbose=True)\n",
    "    \n",
    "    def _create_supervisor_agent(self):\n",
    "        \\\"\\\"\\\"创建监督者智能体\\\"\\\"\\\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一个团队领导，负责协调其他专家完成任务。你需要将复杂问题分解成子任务，分配给适当的专家，并整合他们的工作。\\\\n\\\\n任务描述: {task}\\\\n\\\\n请制定一个计划，说明如何将这个任务分解并分配给团队成员（研究员、编码员、评论员）。\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def run(self, task: str) -> Dict[str, Any]:\n",
    "        \\\"\\\"\\\"运行团队监督者系统\\\"\\\"\\\"\n",
    "        print(\"\\\\n===== 团队监督者模式 =====\")\n",
    "        print(f\"任务: {task}\")\n",
    "        \n",
    "        # 1. 监督者分配任务\n",
    "        print(\"\\\\n1. 监督者制定计划\")\n",
    "        plan = self.supervisor.run(task=task)\n",
    "        print(f\"\\\\n计划:\\\\n{plan}\")\n",
    "        \n",
    "        # 2. 研究员收集信息\n",
    "        print(\"\\\\n2. 研究员收集信息\")\n",
    "        research_query = f\"请查询关于以下内容的事实性信息: {task}\"\n",
    "        research_result = self.researcher.run(research_query)\n",
    "        print(f\"\\\\n研究结果:\\\\n{research_result}\")\n",
    "        \n",
    "        # 3. 编码员根据研究结果实现解决方案\n",
    "        print(\"\\\\n3. 编码员实现解决方案\")\n",
    "        coding_task = f\"根据以下研究结果，编写Python代码解决问题: {task}\\\\n\\\\n研究信息: {research_result}\"\n",
    "        code_solution = self.coder.run(coding_task)\n",
    "        print(f\"\\\\n代码解决方案:\\\\n{code_solution}\")\n",
    "        \n",
    "        # 4. 评论员评估解决方案\n",
    "        print(\"\\\\n4. 评论员评估解决方案\")\n",
    "        critique = self.critic.run(solution=code_solution)\n",
    "        print(f\"\\\\n评估意见:\\\\n{critique}\")\n",
    "        \n",
    "        # 5. 监督者整合结果\n",
    "        print(\"\\\\n5. 监督者整合最终结果\")\n",
    "        final_prompt = f\"请整合以下信息，提供最终的解决方案和总结：\\\\n\\\\n原始任务: {task}\\\\n\\\\n研究结果: {research_result}\\\\n\\\\n代码解决方案: {code_solution}\\\\n\\\\n评估意见: {critique}\"\n",
    "        final_solution = self.llm.predict(final_prompt)\n",
    "        print(f\"\\\\n最终解决方案:\\\\n{final_solution}\")\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"plan\": plan,\n",
    "            \"research\": research_result,\n",
    "            \"code\": code_solution,\n",
    "            \"critique\": critique,\n",
    "            \"final_solution\": final_solution\n",
    "        }\n",
    "\n",
    "# 2. 计划执行模式 (Plan Executor)\n",
    "class PlanExecutorSystem:\n",
    "    \\\"\\\"\\\"计划执行模式 - 一个智能体制定计划，另一个智能体执行计划\\\"\\\"\\\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        \n",
    "        # 创建规划者智能体\n",
    "        self.planner = self._create_planner()\n",
    "        \n",
    "        # 创建执行者智能体\n",
    "        self.executor = self._create_executor()\n",
    "    \n",
    "    def _create_planner(self):\n",
    "        \\\"\\\"\\\"创建规划者智能体\\\"\\\"\\\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"你是一位专业的规划者。请为以下任务制定一个详细的、分步骤的计划：\\\\n\\\\n任务: {task}\\\\n\\\\n请提供一个清晰的、有序的计划，每个步骤应该具体且可执行。确保计划涵盖任务的所有方面，并考虑可能的障碍和解决方案。\",\n",
    "            input_variables=[\"task\"]\n",
    "        )\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=prompt)\n",
    "    \n",
    "    def _create_executor(self):\n",
    "        \\\"\\\"\\\"创建执行者智能体\\\"\\\"\\\"\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"维基百科\",\n",
    "                func=WikipediaAPIWrapper().run,\n",
    "                description=\"用于查询信息的工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        return initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "    \n",
    "    def run(self, task: str) -> Dict[str, Any]:\n",
    "        \\\"\\\"\\\"运行计划执行系统\\\"\\\"\\\"\n",
    "        print(\"\\\\n===== 计划执行模式 =====\")\n",
    "        print(f\"任务: {task}\")\n",
    "        \n",
    "        # 1. 制定计划\n",
    "        print(\"\\\\n1. 规划者制定计划\")\n",
    "        plan = self.planner.run(task=task)\n",
    "        print(f\"\\\\n计划:\\\\n{plan}\")\n",
    "        \n",
    "        # 2. 执行计划\n",
    "        print(\"\\\\n2. 执行者执行计划\")\n",
    "        execution_task = f\"根据以下计划执行任务：\\\\n\\\\n任务: {task}\\\\n\\\\n计划:\\\\n{plan}\\\\n\\\\n执行每个步骤并报告结果。\"\n",
    "        execution_result = self.executor.run(execution_task)\n",
    "        print(f\"\\\\n执行结果:\\\\n{execution_result}\")\n",
    "        \n",
    "        return {\n",
    "            \"task\": task,\n",
    "            \"plan\": plan,\n",
    "            \"execution_result\": execution_result\n",
    "        }\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain 多智能体编排模式示例 ===\")\n",
    "    \n",
    "    # 选择要演示的编排模式\n",
    "    orchestration_type = \"team_supervisor\"  # 可选: \"team_supervisor\", \"plan_executor\"\n",
    "    \n",
    "    if orchestration_type == \"team_supervisor\":\n",
    "        system = TeamSupervisorSystem()\n",
    "        result = system.run(\"创建一个简单的网站访问计数器应用\")\n",
    "        \n",
    "    elif orchestration_type == \"plan_executor\":\n",
    "        system = PlanExecutorSystem()\n",
    "        result = system.run(\"研究机器学习中的过拟合问题并提供3种解决方法\")\n",
    "\"\"\"\n",
    "    \n",
    "    # Write the file\n",
    "    editor.write(\"langchain_tutorial/code_examples/agent_examples/multi_agent_example.py\", multi_agent_content)\n",
    "    print(\"Created multi-agent examples file\")\n",
    "\n",
    "    # Create the RAG+Agent integration example file\n",
    "    rag_agent_content = \"\"\"# LangChain RAG与智能体结合示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "import tempfile\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class RAGAgentExample:\n",
    "    \\\"\\\"\\\"\n",
    "    检索增强生成(RAG)与智能体结合示例\n",
    "    展示如何将RAG系统集成到智能体工作流中\n",
    "    \\\"\\\"\\\"\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.documents = []\n",
    "        self.vector_store = None\n",
    "        self.retriever = None\n",
    "    \n",
    "    def load_documents(self, texts: List[str]):\n",
    "        \\\"\\\"\\\"加载文档到系统中\\\"\\\"\\\"\n",
    "        print(\"加载文档...\")\n",
    "        \n",
    "        # 创建临时文件\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        file_paths = []\n",
    "        \n",
    "        # 将文本写入临时文件\n",
    "        for i, text in enumerate(texts):\n",
    "            file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        for file_path in file_paths:\n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个文档\")\n",
    "    \n",
    "    def process_documents(self):\n",
    "        \\\"\\\"\\\"处理文档：分块和创建向量存储\\\"\\\"\\\"\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"请先加载文档\")\n",
    "        \n",
    "        print(\"处理文档：分块和向量化...\")\n",
    "        \n",
    "        # 分块\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "        self.retriever = self.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        print(f\"文档处理完成，共创建 {len(chunks)} 个文本块\")\n",
    "        \n",
    "        return self.retriever\n",
    "    \n",
    "    def create_standalone_rag_chain(self):\n",
    "        \\\"\\\"\\\"创建独立的RAG链\\\"\\\"\\\"\n",
    "        if not self.retriever:\n",
    "            raise ValueError(\"请先处理文档\")\n",
    "        \n",
    "        # 创建RAG提示模板\n",
    "        rag_prompt = PromptTemplate.from_template(\\\"\\\"\\\"\n",
    "        请使用以下检索的信息回答问题。如果检索的信息中没有答案，请说明你不知道。\n",
    "\n",
    "        检索的信息:\n",
    "        {context}\n",
    "\n",
    "        问题: {question}\n",
    "        \\\"\\\"\\\")\n",
    "        \n",
    "        # 定义文档格式化函数\n",
    "        def format_docs(docs):\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建RAG链\n",
    "        rag_chain = (\n",
    "            {\"context\": self.retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | rag_prompt\n",
    "            | self.llm\n",
    "        )\n",
    "        \n",
    "        return rag_chain\n",
    "    \n",
    "    def create_rag_tool(self):\n",
    "        \\\"\\\"\\\"将RAG系统封装为智能体工具\\\"\\\"\\\"\n",
    "        rag_chain = self.create_standalone_rag_chain()\n",
    "        \n",
    "        def query_knowledge_base(query: str) -> str:\n",
    "            \\\"\\\"\\\"查询知识库获取信息\\\"\\\"\\\"\n",
    "            result = rag_chain.invoke(query)\n",
    "            return result.content if hasattr(result, \"content\") else str(result)\n",
    "        \n",
    "        # 创建RAG工具\n",
    "        rag_tool = Tool(\n",
    "            name=\"知识库查询\",\n",
    "            func=query_knowledge_base,\n",
    "            description=\"当你需要查询特定领域知识时使用此工具\"\n",
    "        )\n",
    "        \n",
    "        return rag_tool\n",
    "    \n",
    "    def create_agent_with_rag(self):\n",
    "        \\\"\\\"\\\"创建集成RAG的智能体\\\"\\\"\\\"\n",
    "        # 获取RAG工具\n",
    "        rag_tool = self.create_rag_tool()\n",
    "        \n",
    "        # 添加其他工具\n",
    "        python_tool = PythonREPLTool()\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools=[rag_tool, python_tool],\n",
    "            llm=self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "        \n",
    "        return agent\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== LangChain RAG与智能体结合示例 ===\")\n",
    "    \n",
    "    # 1. 运行直接RAG问答示例\n",
    "    print(\"\\\\n===== 直接RAG问答示例 =====\")\n",
    "    \n",
    "    # 创建RAG系统\n",
    "    rag_system = RAGAgentExample()\n",
    "    \n",
    "    # 加载文档\n",
    "    documents = [\n",
    "        \\\"\\\"\\\"\n",
    "        LangChain是一个用于开发由语言模型驱动的应用程序的框架。它的核心组件包括:\n",
    "        \n",
    "        1. 模型I/O (Models): 与各种语言模型提供商的集成接口。\n",
    "        2. 提示管理 (Prompts): 优化和管理提示模板。 \n",
    "        3. 记忆系统 (Memory): 维护对话状态和历史。\n",
    "        4. 索引和检索 (Indexes): 使用向量存储等技术组织和检索信息。\n",
    "        5. 链 (Chains): 将多个组件串联成管道。\n",
    "        6. 智能体 (Agents): 允许LLM决定使用哪些工具来完成任务。\n",
    "        \\\"\\\"\\\",\n",
    "        \\\"\\\"\\\"\n",
    "        LangChain表达式语言(LCEL)是一种声明式语言，用于组合LangChain的组件。它具有以下特性:\n",
    "        \n",
    "        1. 链式API: 使用管道操作符(|)连接组件。\n",
    "        2. 并行执行: 可以同时执行多个操作并合并结果。\n",
    "        3. 错误处理: 内置重试和异常处理机制。\n",
    "        4. 批处理: 一次处理多个输入以提高效率。\n",
    "        5. 流式传输: 支持逐步生成和处理响应。\n",
    "        \n",
    "        示例: chain = prompt | llm | output_parser\n",
    "        \\\"\\\"\\\"\n",
    "    ]\n",
    "    rag_system.load_documents(documents)\n",
    "    rag_system.process_documents()\n",
    "    \n",
    "    # 创建RAG链\n",
    "    rag_chain = rag_system.create_standalone_rag_chain()\n",
    "    \n",
    "    # 查询\n",
    "    queries = [\n",
    "        \"LangChain的核心组件有哪些?\",\n",
    "        \"什么是LCEL，它有什么特点?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\\\n问题: {query}\")\n",
    "        response = rag_chain.invoke(query)\n",
    "        print(f\"回答: {response.content if hasattr(response, 'content') else response}\")\n",
    "    \n",
    "    # 2. 运行智能体与RAG集成示例\n",
    "    print(\"\\\\n===== 智能体与RAG集成示例 =====\")\n",
    "    \n",
    "    # 创建智能体\n",
    "    agent = rag_system.create_agent_with_rag()\n",
    "    \n",
    "    # 查询\n",
    "    agent_queries = [\n",
    "        \"总结LangChain的核心组件并使用Python代码计算它们的总数\",\n",
    "        \"请解释LCEL中的管道操作符是如何工作的\"\n",
    "    ]\n",
    "    \n",
    "    for query in agent_queries:\n",
    "        print(f\"\\\\n智能体查询: {query}\")\n",
    "        response = agent.run(query)\n",
    "        print(f\"智能体回答: {response}\")\n",
    "\"\"\"\n",
    "    \n",
    "    # Write the file\n",
    "    editor.write(\"langchain_tutorial/code_examples/agent_examples/rag_agent_example.py\", rag_agent_content)\n",
    "    print(\"Created RAG agent integration example file\")\n",
    "    \n",
    "    # Create a README file for the examples\n",
    "    readme_content = \"\"\"# LangChain 智能体和多智能体编排示例\n",
    "\n",
    "本目录包含 LangChain 框架中单智能体和多智能体编排的实用示例代码。\n",
    "\n",
    "## 文件说明\n",
    "\n",
    "1. `single_agent_example.py` - 演示不同类型的单智能体实现\n",
    "   - ReAct 智能体：结合推理和行动的智能体\n",
    "   - OpenAI函数调用智能体：基于函数调用能力的智能体\n",
    "   - 自定义工具智能体：使用自定义工具的智能体\n",
    "\n",
    "2. `multi_agent_example.py` - 演示多智能体编排模式\n",
    "   - 团队监督者模式：一个监督者智能体协调多个专家智能体工作\n",
    "   - 计划执行模式：一个智能体制定计划，另一个智能体执行计划\n",
    "\n",
    "3. `rag_agent_example.py` - 演示RAG与智能体结合的实现\n",
    "   - 直接RAG问答：使用检索增强生成直接回答问题\n",
    "   - 智能体与RAG集成：智能体可以主动使用RAG工具获取知识\n",
    "\n",
    "## 使用说明\n",
    "\n",
    "1. 确保设置必要的环境变量：\n",
    "   ```python\n",
    "   os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "   ```\n",
    "\n",
    "2. 安装所需依赖：\n",
    "   ```bash\n",
    "   pip install langchain langchain_community faiss-cpu openai\n",
    "   ```\n",
    "\n",
    "3. 运行示例：\n",
    "   ```bash\n",
    "   python single_agent_example.py\n",
    "   python multi_agent_example.py\n",
    "   python rag_agent_example.py\n",
    "   ```\n",
    "\n",
    "## 注意事项\n",
    "\n",
    "- 这些示例旨在展示核心概念，实际应用时可能需要进一步配置和优化\n",
    "- 代码中的某些功能可能需要特定的API访问权限\n",
    "- RAG示例中使用了临时文件来模拟文档加载，实际应用中可以直接从真实数据源加载\n",
    "\"\"\"\n",
    "    \n",
    "    editor.write(\"langchain_tutorial/code_examples/agent_examples/README.md\", readme_content)\n",
    "    print(\"Created README file\")\n",
    "    \n",
    "    # Show the created files\n",
    "    files = await terminal.run(\"find langchain_tutorial/code_examples/agent_examples -type f | sort\")\n",
    "    print(f\"\\nCreated example files:\\n{files}\")\n",
    "    \n",
    "    print(\"\\n========== Code Examples Creation Complete ==========\")\n",
    "    print(\"Created comprehensive examples for:\")\n",
    "    print(\"1. Single agent implementation patterns\")\n",
    "    print(\"2. Multi-agent orchestration patterns\")\n",
    "    print(\"3. RAG integration with agents\")\n",
    "\n",
    "# Execute the main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a882bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:18:54.751327Z",
     "iopub.status.busy": "2025-04-07T04:18:54.750979Z",
     "iopub.status.idle": "2025-04-07T04:18:54.756749Z",
     "shell.execute_reply": "2025-04-07T04:18:54.756139Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2040116023.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[16], line 10\u001B[0;36m\u001B[0m\n\u001B[0;31m    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\u001B[0m\n\u001B[0m                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create a structured summary document that organizes the information\n",
    "# on LangChain's single and multi-agent orchestration patterns\n",
    "summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\n",
    "\n",
    "## 1. 智能体架构概述\n",
    "\n",
    "LangChain的智能体系统是一个强大的框架，允许语言模型（LLMs）通过工具与外部环境交互，从而完成复杂任务。\n",
    "\n",
    "### 1.1 智能体系统的核心组件\n",
    "\n",
    "- **智能体 (Agent)**: 负责决策和推理的语言模型\n",
    "- **工具 (Tools)**: 智能体可以使用的函数或API\n",
    "- **执行器 (Executor)**: 协调智能体与工具之间的交互\n",
    "- **记忆 (Memory)**: 存储对话或执行历史\n",
    "- **观察 (Observation)**: 工具执行的结果反馈\n",
    "\n",
    "## 2. 单智能体实现模式\n",
    "\n",
    "### 2.1 ReAct 智能体\n",
    "\n",
    "ReAct（Reasoning + Acting）智能体结合了推理和行动的能力，是最常用的智能体类型之一。\n",
    "\n",
    "**核心特性:**\n",
    "- 结合推理（思考）和行动的能力\n",
    "- 提供中间推理步骤\n",
    "- 支持\"链式思考\"过程\n",
    "- 适用于需要复杂逻辑和推理的任务\n",
    "\n",
    "**实现代码示例:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2e8ef37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:21:00.320621Z",
     "iopub.status.busy": "2025-04-07T04:21:00.320293Z",
     "iopub.status.idle": "2025-04-07T04:21:00.325023Z",
     "shell.execute_reply": "2025-04-07T04:21:00.324111Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (479763984.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[17], line 10\u001B[0;36m\u001B[0m\n\u001B[0;31m    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\u001B[0m\n\u001B[0m                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create a structured summary document that organizes the information\n",
    "# on LangChain's single and multi-agent orchestration patterns\n",
    "summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\n",
    "\n",
    "## 1. 智能体架构概述\n",
    "\n",
    "LangChain的智能体系统是一个强大的框架，允许语言模型（LLMs）通过工具与外部环境交互，从而完成复杂任务。\n",
    "\n",
    "### 1.1 智能体系统的核心组件\n",
    "\n",
    "- **智能体 (Agent)**: 负责决策和推理的语言模型\n",
    "- **工具 (Tools)**: 智能体可以使用的函数或API\n",
    "- **执行器 (Executor)**: 协调智能体与工具之间的交互\n",
    "- **记忆 (Memory)**: 存储对话或执行历史\n",
    "- **观察 (Observation)**: 工具执行的结果反馈\n",
    "\n",
    "## 2. 单智能体实现模式\n",
    "\n",
    "### 2.1 ReAct 智能体\n",
    "\n",
    "ReAct（Reasoning + Acting）智能体结合了推理和行动的能力，是最常用的智能体类型之一。\n",
    "\n",
    "**核心特性:**\n",
    "- 结合推理（思考）和行动的能力\n",
    "- 提供中间推理步骤\n",
    "- 支持\"链式思考\"过程\n",
    "- 适用于需要复杂逻辑和推理的任务\n",
    "\n",
    "**实现示例:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ce8525c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:23:13.385204Z",
     "iopub.status.busy": "2025-04-07T04:23:13.384709Z",
     "iopub.status.idle": "2025-04-07T04:23:13.390507Z",
     "shell.execute_reply": "2025-04-07T04:23:13.389573Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (980260477.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[18], line 11\u001B[0;36m\u001B[0m\n\u001B[0;31m    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\u001B[0m\n\u001B[0m                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create a structured summary document that organizes the information\n",
    "# on LangChain's single and multi-agent orchestration patterns\n",
    "async def create_langchain_agents_summary():\n",
    "    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\n",
    "\n",
    "## 1. 智能体架构概述\n",
    "\n",
    "LangChain的智能体系统是一个强大的框架，允许语言模型（LLMs）通过工具与外部环境交互，从而完成复杂任务。\n",
    "\n",
    "### 1.1 智能体系统的核心组件\n",
    "\n",
    "- **智能体 (Agent)**: 负责决策和推理的语言模型\n",
    "- **工具 (Tools)**: 智能体可以使用的函数或API\n",
    "- **执行器 (Executor)**: 协调智能体与工具之间的交互\n",
    "- **记忆 (Memory)**: 存储对话或执行历史\n",
    "- **观察 (Observation)**: 工具执行的结果反馈\n",
    "\n",
    "## 2. 单智能体实现模式\n",
    "\n",
    "### 2.1 ReAct 智能体\n",
    "\n",
    "ReAct（Reasoning + Acting）智能体结合了推理和行动的能力，是最常用的智能体类型之一。\n",
    "\n",
    "**核心特性:**\n",
    "- 结合推理（思考）和行动的能力\n",
    "- 提供中间推理步骤\n",
    "- 支持\"链式思考\"过程\n",
    "- 适用于需要复杂逻辑和推理的任务\n",
    "\n",
    "**实现示例:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37026d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:30:28.827919Z",
     "iopub.status.busy": "2025-04-07T04:30:28.827330Z",
     "iopub.status.idle": "2025-04-07T04:30:28.833080Z",
     "shell.execute_reply": "2025-04-07T04:30:28.832219Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (242544012.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[19], line 10\u001B[0;36m\u001B[0m\n\u001B[0;31m    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\u001B[0m\n\u001B[0m                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create a comprehensive structured summary document\n",
    "async def create_langchain_agents_summary():\n",
    "    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\n",
    "\n",
    "## 1. 智能体架构概述\n",
    "\n",
    "LangChain的智能体系统是一个强大的框架，允许语言模型（LLMs）通过工具与外部环境交互，从而完成复杂任务。\n",
    "\n",
    "### 1.1 智能体系统的核心组件\n",
    "\n",
    "- **智能体 (Agent)**: 负责决策和推理的语言模型\n",
    "- **工具 (Tools)**: 智能体可以使用的函数或API\n",
    "- **执行器 (Executor)**: 协调智能体与工具之间的交互\n",
    "- **记忆 (Memory)**: 存储对话或执行历史\n",
    "- **观察 (Observation)**: 工具执行的结果反馈\n",
    "\n",
    "## 2. 单智能体实现模式\n",
    "\n",
    "### 2.1 ReAct 智能体\n",
    "\n",
    "ReAct（Reasoning + Acting）智能体结合了推理和行动的能力，是最常用的智能体类型之一。\n",
    "\n",
    "**核心特性:**\n",
    "- 结合推理（思考）和行动的能力\n",
    "- 提供中间推理步骤\n",
    "- 支持\"链式思考\"过程\n",
    "- 适用于需要复杂逻辑和推理的任务\n",
    "\n",
    "**实现示例:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da7a0f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:31:45.359965Z",
     "iopub.status.busy": "2025-04-07T04:31:45.358965Z",
     "iopub.status.idle": "2025-04-07T04:31:45.364855Z",
     "shell.execute_reply": "2025-04-07T04:31:45.364092Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (242544012.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[20], line 10\u001B[0;36m\u001B[0m\n\u001B[0;31m    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\u001B[0m\n\u001B[0m                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create a comprehensive structured summary document\n",
    "async def create_langchain_agents_summary():\n",
    "    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\n",
    "\n",
    "## 1. 智能体架构概述\n",
    "\n",
    "LangChain的智能体系统是一个强大的框架，允许语言模型（LLMs）通过工具与外部环境交互，从而完成复杂任务。\n",
    "\n",
    "### 1.1 智能体系统的核心组件\n",
    "\n",
    "- **智能体 (Agent)**: 负责决策和推理的语言模型\n",
    "- **工具 (Tools)**: 智能体可以使用的函数或API\n",
    "- **执行器 (Executor)**: 协调智能体与工具之间的交互\n",
    "- **记忆 (Memory)**: 存储对话或执行历史\n",
    "- **观察 (Observation)**: 工具执行的结果反馈\n",
    "\n",
    "## 2. 单智能体实现模式\n",
    "\n",
    "### 2.1 ReAct 智能体\n",
    "\n",
    "ReAct（Reasoning + Acting）智能体结合了推理和行动的能力，是最常用的智能体类型之一。\n",
    "\n",
    "**核心特性:**\n",
    "- 结合推理（思考）和行动的能力\n",
    "- 提供中间推理步骤\n",
    "- 支持\"链式思考\"过程\n",
    "- 适用于需要复杂逻辑和推理的任务\n",
    "\n",
    "**实现示例:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efa98fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:33:11.207577Z",
     "iopub.status.busy": "2025-04-07T04:33:11.206921Z",
     "iopub.status.idle": "2025-04-07T04:33:11.211509Z",
     "shell.execute_reply": "2025-04-07T04:33:11.210864Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1339704324.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[21], line 10\u001B[0;36m\u001B[0m\n\u001B[0;31m    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\u001B[0m\n\u001B[0m                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create a comprehensive structured summary document\n",
    "async def create_langchain_agents_summary():\n",
    "    summary_content = \"\"\"# LangChain 单智能体与多智能体编排模式总结\n",
    "\n",
    "## 1. 智能体架构概述\n",
    "\n",
    "LangChain的智能体系统是一个强大的框架，允许语言模型（LLMs）通过工具与外部环境交互，从而完成复杂任务。\n",
    "\n",
    "### 1.1 智能体系统的核心组件\n",
    "\n",
    "- **智能体 (Agent)**: 负责决策和推理的语言模型\n",
    "- **工具 (Tools)**: 智能体可以使用的函数或API\n",
    "- **执行器 (Executor)**: 协调智能体与工具之间的交互\n",
    "- **记忆 (Memory)**: 存储对话或执行历史\n",
    "- **观察 (Observation)**: 工具执行的结果反馈\n",
    "\n",
    "## 2. 单智能体实现模式\n",
    "\n",
    "### 2.1 ReAct 智能体\n",
    "\n",
    "ReAct（Reasoning + Acting）智能体结合了推理和行动的能力，是最常用的智能体类型之一。\n",
    "\n",
    "**核心特性:**\n",
    "- 结合推理（思考）和行动的能力\n",
    "- 提供中间推理步骤\n",
    "- 支持\"链式思考\"过程\n",
    "- 适用于需要复杂逻辑和推理的任务\n",
    "\n",
    "**实现方式:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cca9308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:38:15.827527Z",
     "iopub.status.busy": "2025-04-07T04:38:15.826805Z",
     "iopub.status.idle": "2025-04-07T04:38:15.840161Z",
     "shell.execute_reply": "2025-04-07T04:38:15.838962Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 499)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m<tokenize>:499\u001B[0;36m\u001B[0m\n\u001B[0;31m    {chat_history}\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.web_scraping import view_page_element_to_scrape\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for search and agent integration\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/docs/search_agent_integration\")\n",
    "\n",
    "# URLs for search and agent integration documentation\n",
    "search_agent_urls = [\n",
    "    (\"search_tools\", \"https://python.langchain.com/docs/modules/agents/tools/\"),\n",
    "    (\"search_toolkit\", \"https://python.langchain.com/docs/modules/agents/toolkits/retrieval\"),\n",
    "    (\"vector_stores\", \"https://python.langchain.com/docs/integrations/vectorstores/\"),\n",
    "    (\"retrievers\", \"https://python.langchain.com/docs/modules/data_connection/retrievers/\"),\n",
    "    (\"agent_with_retrieval_tool\", \"https://python.langchain.com/docs/use_cases/question_answering/how_to/chat_vector_db\")\n",
    "]\n",
    "\n",
    "# Function to extract content\n",
    "async def extract_search_agent_content(name, url):\n",
    "    print(f\"Fetching {name} documentation from: {url}\")\n",
    "    html_content = await view_page_element_to_scrape(\n",
    "        url=url,\n",
    "        requirement=f\"Extract all information about how search/retrieval capabilities can be integrated with agents\",\n",
    "        keep_links=True\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.find('main')\n",
    "    \n",
    "    content = \"\"\n",
    "    if main_content:\n",
    "        title = main_content.find('h1')\n",
    "        if title:\n",
    "            content += f\"# {title.get_text(strip=True)}\\n\\n\"\n",
    "        \n",
    "        for element in main_content.find_all(['h2', 'h3', 'h4', 'p', 'pre', 'ul', 'ol', 'li', 'div']):\n",
    "            if element.name in ['h2', 'h3', 'h4']:\n",
    "                level = int(element.name[1])\n",
    "                content += f\"{'#' * level} {element.get_text(strip=True)}\\n\\n\"\n",
    "            elif element.name == 'p':\n",
    "                content += f\"{element.get_text(strip=True)}\\n\\n\"\n",
    "            elif element.name == 'pre':\n",
    "                code = element.find('code')\n",
    "                if code:\n",
    "                    language = \"python\" if \"python\" in code.get('class', [''])[0] else \"\"\n",
    "                    content += f\"```{language}\\n{code.get_text()}\\n```\\n\\n\"\n",
    "                else:\n",
    "                    content += f\"```\\n{element.get_text()}\\n```\\n\\n\"\n",
    "            elif element.name in ['ul', 'ol']:\n",
    "                for li in element.find_all('li', recursive=False):\n",
    "                    content += f\"- {li.get_text(strip=True)}\\n\"\n",
    "                content += \"\\n\"\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Collect documentation on search and agent integration\n",
    "for name, url in search_agent_urls:\n",
    "    content = await extract_search_agent_content(name, url)\n",
    "    file_path = f\"langchain_tutorial/docs/search_agent_integration/{name}.md\"\n",
    "    editor.write(file_path, content + f\"\\n\\nSource: {url}\")\n",
    "\n",
    "# Create a code example demonstrating search agent integration\n",
    "example_code = \"\"\"# LangChain 搜索与智能体集成示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class SearchAgentIntegration:\n",
    "    \"\"\"搜索与智能体集成的不同方法示例\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "    \n",
    "    def load_sample_documents(self):\n",
    "        \"\"\"加载示例文档\"\"\"\n",
    "        # 创建示例文档\n",
    "        texts = [\n",
    "            \"\"\"\n",
    "            LangChain是一个用于构建基于语言模型的应用程序的框架。\n",
    "            它的核心特点包括:\n",
    "            1. 组件化: 提供模块化的接口和组件\n",
    "            2. 可定制性: 可以灵活组合和调整不同组件\n",
    "            3. 调试能力: 可以轻松追踪应用中的操作\n",
    "            4. 端到端开发: 从原型到生产的完整解决方案\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            LangChain的检索增强生成(RAG)模式是将外部知识与LLM结合的强大方法。\n",
    "            RAG工作流程包括:\n",
    "            1. 索引阶段: 将文档转换为向量表示并存储\n",
    "            2. 检索阶段: 查询相关文档片段\n",
    "            3. 生成阶段: 使用检索到的上下文增强LLM的回答\n",
    "            这种方法减少了幻觉，提高了回答准确性。\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            LangChain的智能体(Agents)系统允许LLM决定使用哪些工具来解决问题。\n",
    "            智能体可以:\n",
    "            1. 拆解复杂问题\n",
    "            2. 选择并使用合适的工具\n",
    "            3. 根据工具输出调整策略\n",
    "            4. 迭代直到达成目标\n",
    "            智能体与工具的结合使LLM能够与现实世界交互。\n",
    "            \"\"\"\n",
    "        ]\n",
    "        \n",
    "        # 加载文档\n",
    "        import tempfile\n",
    "        self.documents = []\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            \n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个示例文档\")\n",
    "    \n",
    "    def process_documents(self):\n",
    "        \"\"\"处理文档并创建向量存储\"\"\"\n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = Chroma.from_documents(splits, embeddings)\n",
    "        self.retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 2}  # 获取最相关的2个文档块\n",
    "        )\n",
    "        \n",
    "        print(f\"文档已处理，共创建 {len(splits)} 个文档块\")\n",
    "    \n",
    "    def method1_retrieval_qa_chain(self, query: str) -> str:\n",
    "        \"\"\"方法1: 使用检索QA链 - 最基本的检索增强问答\"\"\"\n",
    "        print(\"\\n===== 方法1: 使用检索QA链 =====\")\n",
    "        \n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",  # 将所有文档合并到提示中\n",
    "            retriever=self.retriever,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        result = qa_chain({\"query\": query})\n",
    "        return result[\"result\"]\n",
    "    \n",
    "    def method2_retrieval_tool_for_agent(self, query: str) -> str:\n",
    "        \"\"\"方法2: 将检索器作为智能体工具 - 智能体可以主动决定何时搜索信息\"\"\"\n",
    "        print(\"\\n===== 方法2: 将检索器作为智能体工具 =====\")\n",
    "        \n",
    "        # 创建检索工具\n",
    "        def search_docs(query: str) -> str:\n",
    "            docs = self.retriever.get_relevant_documents(query)\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 定义工具\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"文档搜索\",\n",
    "                func=search_docs,\n",
    "                description=\"当你需要查询关于LangChain的信息时使用此工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        result = agent.run(query)\n",
    "        return result\n",
    "    \n",
    "    def method3_contextual_agent(self, query: str) -> str:\n",
    "        \"\"\"方法3: 基于上下文的智能体 - 先检索相关文档，然后让智能体基于上下文回答\"\"\"\n",
    "        print(\"\\n===== 方法3: 基于上下文的智能体 =====\")\n",
    "        \n",
    "        # 首先获取相关文档\n",
    "        docs = self.retriever.get_relevant_documents(query)\n",
    "        context = \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建带上下文的工具\n",
    "        python_tool = PythonREPLTool()\n",
    "        \n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"Python执行器\",\n",
    "                func=python_tool.run,\n",
    "                description=\"执行Python代码，适用于计算、数据处理等\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # 创建基于上下文的提示\n",
    "        contextual_prompt = f\"你有以下参考信息:\\\\n\\\\n{context}\\\\n\\\\n基于这些信息回答问题: {query}\"\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 执行具有上下文的查询\n",
    "        result = agent.run(contextual_prompt)\n",
    "        return result\n",
    "\n",
    "# 主执行函数\n",
    "def main():\n",
    "    print(\"=== LangChain 搜索与智能体集成示例 ===\")\n",
    "    \n",
    "    # 创建示例\n",
    "    example = SearchAgentIntegration()\n",
    "    \n",
    "    # 加载和处理文档\n",
    "    example.load_sample_documents()\n",
    "    example.process_documents()\n",
    "    \n",
    "    # 测试不同的集成方法\n",
    "    queries = [\n",
    "        \"LangChain的核心特点是什么?\",\n",
    "        \"解释RAG模式是如何工作的，并计算它的步骤数量\",\n",
    "        \"智能体如何与外部工具交互?\"\n",
    "    ]\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"\\\\n\\\\n问题 {i+1}: {query}\")\n",
    "        \n",
    "        # 根据问题类型选择不同的方法\n",
    "        if i == 0:\n",
    "            # 简单的事实查询 - 使用基本检索QA\n",
    "            answer = example.method1_retrieval_qa_chain(query)\n",
    "        elif i == 1:\n",
    "            # 需要计算的查询 - 使用检索工具的智能体\n",
    "            answer = example.method2_retrieval_tool_for_agent(query)\n",
    "        else:\n",
    "            # 需要更多上下文的复杂查询 - 使用上下文智能体\n",
    "            answer = example.method3_contextual_agent(query)\n",
    "        \n",
    "        print(f\"\\\\n回答: {answer}\")\n",
    "        print(\"\\\\n\" + \"-\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Write the example code\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/code_examples/search_agent_integration\")\n",
    "editor.write(\"langchain_tutorial/code_examples/search_agent_integration/search_agent_methods.py\", example_code)\n",
    "\n",
    "# Create an advanced hybrid search agent example\n",
    "hybrid_search_agent_code = \"\"\"# LangChain 高级混合检索智能体示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool, AgentExecutor, create_react_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tempfile\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class HybridSearchTool(Tool):\n",
    "    \"\"\"混合搜索工具 - 结合关键词和向量搜索\"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstore, llm):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        # 创建基本检索器\n",
    "        self.basic_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        # 创建上下文压缩检索器\n",
    "        compressor = LLMChainExtractor.from_llm(llm)\n",
    "        self.compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=self.basic_retriever\n",
    "        )\n",
    "        \n",
    "        super().__init__(\n",
    "            name=\"混合知识库搜索\",\n",
    "            func=self.search,\n",
    "            description=\"当你需要查询文档中的特定信息时使用此工具，输入应为明确的问题或信息需求\"\n",
    "        )\n",
    "    \n",
    "    def search(self, query: str) -> str:\n",
    "        \"\"\"执行混合搜索\"\"\"\n",
    "        # 获取向量检索结果\n",
    "        vector_docs = self.basic_retriever.get_relevant_documents(query)\n",
    "        \n",
    "        # 使用LLM提取最相关的信息\n",
    "        compressed_docs = self.compression_retriever.get_relevant_documents(query)\n",
    "        \n",
    "        # 合并并去重结果\n",
    "        all_docs = []\n",
    "        seen_content = set()\n",
    "        \n",
    "        for doc in vector_docs + compressed_docs:\n",
    "            if doc.page_content not in seen_content:\n",
    "                all_docs.append(doc)\n",
    "                seen_content.add(doc.page_content)\n",
    "        \n",
    "        # 格式化结果\n",
    "        if not all_docs:\n",
    "            return \"没有找到相关信息\"\n",
    "        \n",
    "        return \"\\\\n\\\\n\".join([f\"文档 {i+1}:\\\\n{doc.page_content}\" for i, doc in enumerate(all_docs)])\n",
    "\n",
    "\n",
    "class AdvancedSearchAgent:\n",
    "    \"\"\"高级搜索智能体 - 结合多种检索方法并使用对话记忆\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        self.agent_executor = None\n",
    "    \n",
    "    def load_documents(self, file_paths: Optional[List[str]] = None):\n",
    "        \"\"\"加载文档\"\"\"\n",
    "        self.documents = []\n",
    "        \n",
    "        # 如果没有提供文件路径，使用示例文档\n",
    "        if not file_paths:\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            file_paths = []\n",
    "            \n",
    "            # 创建示例文档\n",
    "            example_texts = [\n",
    "                \"\"\"\n",
    "                # 搜索系统与智能体集成的方法\n",
    "                \n",
    "                搜索系统可以通过多种方式与LangChain智能体集成:\n",
    "                \n",
    "                1. **作为工具提供**: 封装为工具API供智能体调用\n",
    "                2. **预检索增强**: 在启动智能体前检索信息\n",
    "                3. **混合架构**: 两种方法的结合，根据需要使用\n",
    "                \n",
    "                每种方法都有其优缺点，适用于不同场景。\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                # 检索增强生成(RAG)架构\n",
    "                \n",
    "                RAG架构是结合检索系统和LLM的有效方法，通常包含以下组件:\n",
    "                \n",
    "                - 文档加载器: 加载各种格式的文档\n",
    "                - 文档转换器: 分割文档为可管理的块\n",
    "                - 文本嵌入模型: 将文本转换为向量表示\n",
    "                - 向量存储: 存储和索引嵌入向量\n",
    "                - 检索器: 检索相关信息\n",
    "                - 生成模型: 基于检索内容生成答案\n",
    "                \n",
    "                RAG过程包括索引、检索和生成三个阶段。\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                # 智能体工具类型\n",
    "                \n",
    "                LangChain提供多种工具类型可以与智能体结合:\n",
    "                \n",
    "                - 检索工具: 从文档中检索信息\n",
    "                - API工具: 与外部服务交互\n",
    "                - Python工具: 执行Python代码\n",
    "                - 人类工具: 获取人类反馈\n",
    "                - Shell工具: 执行系统命令\n",
    "                \n",
    "                智能体可以根据任务需求选择合适的工具。\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                # 上下文压缩技术\n",
    "                \n",
    "                上下文压缩技术可以优化检索结果:\n",
    "                \n",
    "                1. 嵌入过滤: 基于嵌入相似度过滤\n",
    "                2. 语义过滤: 基于语义相关性过滤\n",
    "                3. LLM抽取: 使用LLM提取最相关部分\n",
    "                4. 重排序: 重新排序检索到的文档\n",
    "                \n",
    "                这些技术可以帮助减少噪声，提高检索质量。\n",
    "                \"\"\"\n",
    "            ]\n",
    "            \n",
    "            for i, text in enumerate(example_texts):\n",
    "                file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(text)\n",
    "                file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        for file_path in file_paths:\n",
    "            try:\n",
    "                loader = TextLoader(file_path)\n",
    "                self.documents.extend(loader.load())\n",
    "            except Exception as e:\n",
    "                print(f\"加载文档 {file_path} 时出错: {str(e)}\")\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个文档\")\n",
    "    \n",
    "    def process_documents(self):\n",
    "        \"\"\"处理文档并创建向量存储\"\"\"\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"请先加载文档\")\n",
    "        \n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "        \n",
    "        print(f\"文档已处理，共创建 {len(splits)} 个文档块\")\n",
    "    \n",
    "    def setup_agent(self):\n",
    "        \"\"\"设置智能体\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先处理文档\")\n",
    "        \n",
    "        # 创建混合搜索工具\n",
    "        hybrid_search_tool = HybridSearchTool(self.vectorstore, self.llm)\n",
    "        \n",
    "        # 创建Python工具\n",
    "        python_tool = PythonREPLTool()\n",
    "        \n",
    "        # 创建检索QA链作为独立工具\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vectorstore.as_retriever()\n",
    "        )\n",
    "        \n",
    "        def qa_tool(query: str) -> str:\n",
    "            \"\"\"直接QA问答工具\"\"\"\n",
    "            return qa_chain.run(query)\n",
    "        \n",
    "        # 定义工具集\n",
    "        tools = [\n",
    "            hybrid_search_tool,\n",
    "            Tool(\n",
    "                name=\"Python执行器\",\n",
    "                func=python_tool.run,\n",
    "                description=\"执行Python代码，适用于计算、数据处理等\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"直接问答\",\n",
    "                func=qa_tool,\n",
    "                description=\"当你需要直接回答问题而不进行推理时使用此工具\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # 创建带有记忆的智能体\n",
    "        # 使用React提示创建智能体\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"\"\"你是一个高级搜索智能体，能够访问知识库并执行代码来回答问题。\n",
    "            \n",
    "            {chat_history}\n",
    "            \n",
    "            你可以使用以下工具:\n",
    "            {tools}\n",
    "            \n",
    "            针对人类的问题，先考虑是否需要搜索信息或执行代码，然后使用合适的工具。\n",
    "            如果信息已在聊天历史中，可以直接回答而不需要重新搜索。\n",
    "            \n",
    "            人类问题: {input}\n",
    "            让我们一步步思考:\"\"\"\n",
    "        )\n",
    "        \n",
    "        agent = create_react_agent(self.llm, tools, prompt)\n",
    "        \n",
    "        self.agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "            agent=agent,\n",
    "            tools=tools,\n",
    "            memory=self.memory,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "            max_iterations=5\n",
    "        )\n",
    "    \n",
    "    def ask(self, query: str) -> str:\n",
    "        \"\"\"向智能体提问\"\"\"\n",
    "        if not self.agent_executor:\n",
    "            raise ValueError(\"请先设置智能体\")\n",
    "        \n",
    "        result = self.agent_executor.run(query)\n",
    "        return result\n",
    "\n",
    "\n",
    "# 主执行函数\n",
    "def main():\n",
    "    print(\"=== LangChain 高级混合检索智能体示例 ===\")\n",
    "    \n",
    "    # 创建高级搜索智能体\n",
    "    agent = AdvancedSearchAgent()\n",
    "    \n",
    "    # 加载和处理文档\n",
    "    agent.load_documents()\n",
    "    agent.process_documents()\n",
    "    \n",
    "    # 设置智能体\n",
    "    agent.setup_agent()\n",
    "    \n",
    "    # 测试智能体\n",
    "    questions = [\n",
    "        \"智能体可以通过哪些方式与搜索系统集成?\",\n",
    "        \"什么是RAG架构，它有哪些组件?\",\n",
    "        \"基于之前的问题，计算RAG架构中的组件数量\",\n",
    "        \"什么是上下文压缩技术，它如何改进检索结果?\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(questions):\n",
    "        print(f\"\\\\n\\\\n问题 {i+1}: {question}\")\n",
    "        answer = agent.ask(question)\n",
    "        print(f\"\\\\n回答: {answer}\")\n",
    "        print(\"\\\\n\" + \"-\"*50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Write the advanced hybrid search agent example\n",
    "editor.write(\"langchain_tutorial/code_examples/search_agent_integration/hybrid_search_agent.py\", hybrid_search_agent_code)\n",
    "\n",
    "# Create a comprehensive summary document about search and agent integration\n",
    "summary_content = \"\"\"# LangChain 搜索与智能体集成技术总结\n",
    "\n",
    "## 1. 集成方法概述\n",
    "\n",
    "LangChain 框架提供了多种将搜索/检索功能与智能体集成的方法，主要包括以下几种模式：\n",
    "\n",
    "### 1.1 检索工具模式\n",
    "\n",
    "在这种模式下，检索系统被封装为智能体可以使用的工具。智能体可以根据需要决定何时调用检索工具来获取相关信息。\n",
    "\n",
    "**优势：**\n",
    "- 智能体可以决定何时使用检索功能\n",
    "- 更灵活的交互模式\n",
    "- 可以结合其他工具使用\n",
    "\n",
    "**实现方式：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e55442c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:41:43.059155Z",
     "iopub.status.busy": "2025-04-07T04:41:43.058810Z",
     "iopub.status.idle": "2025-04-07T04:41:43.086676Z",
     "shell.execute_reply": "2025-04-07T04:41:43.085439Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '。' (U+3002) (2485267529.py, line 100)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[24], line 100\u001B[0;36m\u001B[0m\n\u001B[0;31m    LangChain是一个用于构建基于语言模型的应用程序的框架。\u001B[0m\n\u001B[0m                                  ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid character '。' (U+3002)\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.web_scraping import view_page_element_to_scrape\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for search and agent integration\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/docs/search_agent_integration\")\n",
    "\n",
    "# URLs for search and agent integration documentation\n",
    "search_agent_urls = [\n",
    "    (\"search_tools\", \"https://python.langchain.com/docs/modules/agents/tools/\"),\n",
    "    (\"search_toolkit\", \"https://python.langchain.com/docs/modules/agents/toolkits/retrieval\"),\n",
    "    (\"vector_stores\", \"https://python.langchain.com/docs/integrations/vectorstores/\"),\n",
    "    (\"retrievers\", \"https://python.langchain.com/docs/modules/data_connection/retrievers/\"),\n",
    "    (\"agent_with_retrieval_tool\", \"https://python.langchain.com/docs/use_cases/question_answering/how_to/chat_vector_db\")\n",
    "]\n",
    "\n",
    "# Function to extract content\n",
    "async def extract_search_agent_content(name, url):\n",
    "    print(f\"Fetching {name} documentation from: {url}\")\n",
    "    html_content = await view_page_element_to_scrape(\n",
    "        url=url,\n",
    "        requirement=f\"Extract all information about how search/retrieval capabilities can be integrated with agents\",\n",
    "        keep_links=True\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.find('main')\n",
    "    \n",
    "    content = \"\"\n",
    "    if main_content:\n",
    "        title = main_content.find('h1')\n",
    "        if title:\n",
    "            content += f\"# {title.get_text(strip=True)}\\n\\n\"\n",
    "        \n",
    "        for element in main_content.find_all(['h2', 'h3', 'h4', 'p', 'pre', 'ul', 'ol', 'li', 'div']):\n",
    "            if element.name in ['h2', 'h3', 'h4']:\n",
    "                level = int(element.name[1])\n",
    "                content += f\"{'#' * level} {element.get_text(strip=True)}\\n\\n\"\n",
    "            elif element.name == 'p':\n",
    "                content += f\"{element.get_text(strip=True)}\\n\\n\"\n",
    "            elif element.name == 'pre':\n",
    "                code = element.find('code')\n",
    "                if code:\n",
    "                    language = \"python\" if \"python\" in code.get('class', [''])[0] else \"\"\n",
    "                    content += f\"```{language}\\n{code.get_text()}\\n```\\n\\n\"\n",
    "                else:\n",
    "                    content += f\"```\\n{element.get_text()}\\n```\\n\\n\"\n",
    "            elif element.name in ['ul', 'ol']:\n",
    "                for li in element.find_all('li', recursive=False):\n",
    "                    content += f\"- {li.get_text(strip=True)}\\n\"\n",
    "                content += \"\\n\"\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Collect documentation on search and agent integration\n",
    "for name, url in search_agent_urls:\n",
    "    content = await extract_search_agent_content(name, url)\n",
    "    file_path = f\"langchain_tutorial/docs/search_agent_integration/{name}.md\"\n",
    "    editor.write(file_path, content + f\"\\n\\nSource: {url}\")\n",
    "\n",
    "# Create a code example demonstrating search agent integration\n",
    "example_code = \"\"\"# LangChain 搜索与智能体集成示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class SearchAgentIntegration:\n",
    "    \"\"\"搜索与智能体集成的不同方法示例\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "    \n",
    "    def load_sample_documents(self):\n",
    "        \"\"\"加载示例文档\"\"\"\n",
    "        # 创建示例文档\n",
    "        texts = [\n",
    "            \"\"\"\n",
    "            LangChain是一个用于构建基于语言模型的应用程序的框架。\n",
    "            它的核心特点包括:\n",
    "            1. 组件化: 提供模块化的接口和组件\n",
    "            2. 可定制性: 可以灵活组合和调整不同组件\n",
    "            3. 调试能力: 可以轻松追踪应用中的操作\n",
    "            4. 端到端开发: 从原型到生产的完整解决方案\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            LangChain的检索增强生成(RAG)模式是将外部知识与LLM结合的强大方法。\n",
    "            RAG工作流程包括:\n",
    "            1. 索引阶段: 将文档转换为向量表示并存储\n",
    "            2. 检索阶段: 查询相关文档片段\n",
    "            3. 生成阶段: 使用检索到的上下文增强LLM的回答\n",
    "            这种方法减少了幻觉，提高了回答准确性。\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            LangChain的智能体(Agents)系统允许LLM决定使用哪些工具来解决问题。\n",
    "            智能体可以:\n",
    "            1. 拆解复杂问题\n",
    "            2. 选择并使用合适的工具\n",
    "            3. 根据工具输出调整策略\n",
    "            4. 迭代直到达成目标\n",
    "            智能体与工具的结合使LLM能够与现实世界交互。\n",
    "            \"\"\"\n",
    "        ]\n",
    "        \n",
    "        # 加载文档\n",
    "        import tempfile\n",
    "        self.documents = []\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            \n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个示例文档\")\n",
    "    \n",
    "    def process_documents(self):\n",
    "        \"\"\"处理文档并创建向量存储\"\"\"\n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = Chroma.from_documents(splits, embeddings)\n",
    "        self.retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 2}  # 获取最相关的2个文档块\n",
    "        )\n",
    "        \n",
    "        print(f\"文档已处理，共创建 {len(splits)} 个文档块\")\n",
    "    \n",
    "    def method1_retrieval_qa_chain(self, query: str) -> str:\n",
    "        \"\"\"方法1: 使用检索QA链 - 最基本的检索增强问答\"\"\"\n",
    "        print(\"\\\\n===== 方法1: 使用检索QA链 =====\")\n",
    "        \n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",  # 将所有文档合并到提示中\n",
    "            retriever=self.retriever,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        result = qa_chain({\"query\": query})\n",
    "        return result[\"result\"]\n",
    "    \n",
    "    def method2_retrieval_tool_for_agent(self, query: str) -> str:\n",
    "        \"\"\"方法2: 将检索器作为智能体工具 - 智能体可以主动决定何时搜索信息\"\"\"\n",
    "        print(\"\\\\n===== 方法2: 将检索器作为智能体工具 =====\")\n",
    "        \n",
    "        # 创建检索工具\n",
    "        def search_docs(query: str) -> str:\n",
    "            docs = self.retriever.get_relevant_documents(query)\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 定义工具\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"文档搜索\",\n",
    "                func=search_docs,\n",
    "                description=\"当你需要查询关于LangChain的信息时使用此工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        result = agent.run(query)\n",
    "        return result\n",
    "    \n",
    "    def method3_contextual_agent(self, query: str) -> str:\n",
    "        \"\"\"方法3: 基于上下文的智能体 - 先检索相关文档，然后让智能体基于上下文回答\"\"\"\n",
    "        print(\"\\\\n===== 方法3: 基于上下文的智能体 =====\")\n",
    "        \n",
    "        # 首先获取相关文档\n",
    "        docs = self.retriever.get_relevant_documents(query)\n",
    "        context = \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建带上下文的工具\n",
    "        python_tool = PythonREPLTool()\n",
    "        \n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"Python执行器\",\n",
    "                func=python_tool.run,\n",
    "                description=\"执行Python代码，适用于计算、数据处理等\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # 创建基于上下文的提示\n",
    "        contextual_prompt = f\"你有以下参考信息:\\\\n\\\\n{context}\\\\n\\\\n基于这些信息回答问题: {query}\"\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 执行具有上下文的查询\n",
    "        result = agent.run(contextual_prompt)\n",
    "        return result\n",
    "\n",
    "# 主执行函数\n",
    "def main():\n",
    "    print(\"=== LangChain 搜索与智能体集成示例 ===\")\n",
    "    \n",
    "    # 创建示例\n",
    "    example = SearchAgentIntegration()\n",
    "    \n",
    "    # 加载和处理文档\n",
    "    example.load_sample_documents()\n",
    "    example.process_documents()\n",
    "    \n",
    "    # 测试不同的集成方法\n",
    "    queries = [\n",
    "        \"LangChain的核心特点是什么?\",\n",
    "        \"解释RAG模式是如何工作的，并计算它的步骤数量\",\n",
    "        \"智能体如何与外部工具交互?\"\n",
    "    ]\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"\\\\n\\\\n问题 {i+1}: {query}\")\n",
    "        \n",
    "        # 根据问题类型选择不同的方法\n",
    "        if i == 0:\n",
    "            # 简单的事实查询 - 使用基本检索QA\n",
    "            answer = example.method1_retrieval_qa_chain(query)\n",
    "        elif i == 1:\n",
    "            # 需要计算的查询 - 使用检索工具的智能体\n",
    "            answer = example.method2_retrieval_tool_for_agent(query)\n",
    "        else:\n",
    "            # 需要更多上下文的复杂查询 - 使用上下文智能体\n",
    "            answer = example.method3_contextual_agent(query)\n",
    "        \n",
    "        print(f\"\\\\n回答: {answer}\")\n",
    "        print(\"\\\\n\" + \"-\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Write the example code\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/code_examples/search_agent_integration\")\n",
    "editor.write(\"langchain_tutorial/code_examples/search_agent_integration/search_agent_methods.py\", example_code)\n",
    "\n",
    "# Create an advanced hybrid search agent example - Fixed indentation issue in the template string\n",
    "hybrid_search_agent_code = \"\"\"# LangChain 高级混合检索智能体示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool, AgentExecutor, create_react_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tempfile\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class HybridSearchTool(Tool):\n",
    "    \"\"\"混合搜索工具 - 结合关键词和向量搜索\"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstore, llm):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        # 创建基本检索器\n",
    "        self.basic_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        # 创建上下文压缩检索器\n",
    "        compressor = LLMChainExtractor.from_llm(llm)\n",
    "        self.compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=self.basic_retriever\n",
    "        )\n",
    "        \n",
    "        super().__init__(\n",
    "            name=\"混合知识库搜索\",\n",
    "            func=self.search,\n",
    "            description=\"当你需要查询文档中的特定信息时使用此工具，输入应为明确的问题或信息需求\"\n",
    "        )\n",
    "    \n",
    "    def search(self, query: str) -> str:\n",
    "        \"\"\"执行混合搜索\"\"\"\n",
    "        # 获取向量检索结果\n",
    "        vector_docs = self.basic_retriever.get_relevant_documents(query)\n",
    "        \n",
    "        # 使用LLM提取最相关的信息\n",
    "        compressed_docs = self.compression_retriever.get_relevant_documents(query)\n",
    "        \n",
    "        # 合并并去重结果\n",
    "        all_docs = []\n",
    "        seen_content = set()\n",
    "        \n",
    "        for doc in vector_docs + compressed_docs:\n",
    "            if doc.page_content not in seen_content:\n",
    "                all_docs.append(doc)\n",
    "                seen_content.add(doc.page_content)\n",
    "        \n",
    "        # 格式化结果\n",
    "        if not all_docs:\n",
    "            return \"没有找到相关信息\"\n",
    "        \n",
    "        return \"\\\\n\\\\n\".join([f\"文档 {i+1}:\\\\n{doc.page_content}\" for i, doc in enumerate(all_docs)])\n",
    "\n",
    "\n",
    "class AdvancedSearchAgent:\n",
    "    \"\"\"高级搜索智能体 - 结合多种检索方法并使用对话记忆\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        self.agent_executor = None\n",
    "    \n",
    "    def load_documents(self, file_paths: Optional[List[str]] = None):\n",
    "        \"\"\"加载文档\"\"\"\n",
    "        self.documents = []\n",
    "        \n",
    "        # 如果没有提供文件路径，使用示例文档\n",
    "        if not file_paths:\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            file_paths = []\n",
    "            \n",
    "            # 创建示例文档\n",
    "            example_texts = [\n",
    "                \"\"\"\n",
    "                # 搜索系统与智能体集成的方法\n",
    "                \n",
    "                搜索系统可以通过多种方式与LangChain智能体集成:\n",
    "                \n",
    "                1. **作为工具提供**: 封装为工具API供智能体调用\n",
    "                2. **预检索增强**: 在启动智能体前检索信息\n",
    "                3. **混合架构**: 两种方法的结合，根据需要使用\n",
    "                \n",
    "                每种方法都有其优缺点，适用于不同场景。\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                # 检索增强生成(RAG)架构\n",
    "                \n",
    "                RAG架构是结合检索系统和LLM的有效方法，通常包含以下组件:\n",
    "                \n",
    "                - 文档加载器: 加载各种格式的文档\n",
    "                - 文档转换器: 分割文档为可管理的块\n",
    "                - 文本嵌入模型: 将文本转换为向量表示\n",
    "                - 向量存储: 存储和索引嵌入向量\n",
    "                - 检索器: 检索相关信息\n",
    "                - 生成模型: 基于检索内容生成答案\n",
    "                \n",
    "                RAG过程包括索引、检索和生成三个阶段。\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                # 智能体工具类型\n",
    "                \n",
    "                LangChain提供多种工具类型可以与智能体结合:\n",
    "                \n",
    "                - 检索工具: 从文档中检索信息\n",
    "                - API工具: 与外部服务交互\n",
    "                - Python工具: 执行Python代码\n",
    "                - 人类工具: 获取人类反馈\n",
    "                - Shell工具: 执行系统命令\n",
    "                \n",
    "                智能体可以根据任务需求选择合适的工具。\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                # 上下文压缩技术\n",
    "                \n",
    "                上下文压缩技术可以优化检索结果:\n",
    "                \n",
    "                1. 嵌入过滤: 基于嵌入相似度过滤\n",
    "                2. 语义过滤: 基于语义相关性过滤\n",
    "                3. LLM抽取: 使用LLM提取最相关部分\n",
    "                4. 重排序: 重新排序检索到的文档\n",
    "                \n",
    "                这些技术可以帮助减少噪声，提高检索质量。\n",
    "                \"\"\"\n",
    "            ]\n",
    "            \n",
    "            for i, text in enumerate(example_texts):\n",
    "                file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(text)\n",
    "                file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        for file_path in file_paths:\n",
    "            try:\n",
    "                loader = TextLoader(file_path)\n",
    "                self.documents.extend(loader.load())\n",
    "            except Exception as e:\n",
    "                print(f\"加载文档 {file_path} 时出错: {str(e)}\")\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个文档\")\n",
    "    \n",
    "    def process_documents(self):\n",
    "        \"\"\"处理文档并创建向量存储\"\"\"\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"请先加载文档\")\n",
    "        \n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "        \n",
    "        print(f\"文档已处理，共创建 {len(splits)} 个文档块\")\n",
    "    \n",
    "    def setup_agent(self):\n",
    "        \"\"\"设置智能体\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先处理文档\")\n",
    "        \n",
    "        # 创建混合搜索工具\n",
    "        hybrid_search_tool = HybridSearchTool(self.vectorstore, self.llm)\n",
    "        \n",
    "        # 创建Python工具\n",
    "        python_tool = PythonREPLTool()\n",
    "        \n",
    "        # 创建检索QA链作为独立工具\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vectorstore.as_retriever()\n",
    "        )\n",
    "        \n",
    "        def qa_tool(query: str) -> str:\n",
    "            \"\"\"直接QA问答工具\"\"\"\n",
    "            return qa_chain.run(query)\n",
    "        \n",
    "        # 定义工具集\n",
    "        tools = [\n",
    "            hybrid_search_tool,\n",
    "            Tool(\n",
    "                name=\"Python执行器\",\n",
    "                func=python_tool.run,\n",
    "                description=\"执行Python代码，适用于计算、数据处理等\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"直接问答\",\n",
    "                func=qa_tool,\n",
    "                description=\"当你需要直接回答问题而不进行推理时使用此工具\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # 创建带有记忆的智能体\n",
    "        # 使用React提示创建智能体\n",
    "        # Fixed the indentation in the template string by using triple quotes without indentation\n",
    "        prompt_template = \"\"\"你是一个高级搜索智能体，能够访问知识库并执行代码来回答问题。\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "你可以使用以下工具:\n",
    "{tools}\n",
    "\n",
    "针对人类的问题，先考虑是否需要搜索信息或执行代码，然后使用合适的工具。\n",
    "如果信息已在聊天历史中，可以直接回答而不需要重新搜索。\n",
    "\n",
    "人类问题: {input}\n",
    "让我们一步步思考:\"\"\"\n",
    "\n",
    "        prompt = PromptTemplate.from_template(prompt_template)\n",
    "        \n",
    "        agent = create_react_agent(self.llm, tools, prompt)\n",
    "        \n",
    "        self.agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "            agent=agent,\n",
    "            tools=tools,\n",
    "            memory=self.memory,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "            max_iterations=5\n",
    "        )\n",
    "    \n",
    "    def ask(self, query: str) -> str:\n",
    "        \"\"\"向智能体提问\"\"\"\n",
    "        if not self.agent_executor:\n",
    "            raise ValueError(\"请先设置智能体\")\n",
    "        \n",
    "        result = self.agent_executor.run(query)\n",
    "        return result\n",
    "\n",
    "\n",
    "# 主执行函数\n",
    "def main():\n",
    "    print(\"=== LangChain 高级混合检索智能体示例 ===\")\n",
    "    \n",
    "    # 创建高级搜索智能体\n",
    "    agent = AdvancedSearchAgent()\n",
    "    \n",
    "    # 加载和处理文档\n",
    "    agent.load_documents()\n",
    "    agent.process_documents()\n",
    "    \n",
    "    # 设置智能体\n",
    "    agent.setup_agent()\n",
    "    \n",
    "    # 测试智能体\n",
    "    questions = [\n",
    "        \"智能体可以通过哪些方式与搜索系统集成?\",\n",
    "        \"什么是RAG架构，它有哪些组件?\",\n",
    "        \"基于之前的问题，计算RAG架构中的组件数量\",\n",
    "        \"什么是上下文压缩技术，它如何改进检索结果?\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(questions):\n",
    "        print(f\"\\\\n\\\\n问题 {i+1}: {question}\")\n",
    "        answer = agent.ask(question)\n",
    "        print(f\"\\\\n回答: {answer}\")\n",
    "        print(\"\\\\n\" + \"-\"*50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Write the advanced hybrid search agent example\n",
    "editor.write(\"langchain_tutorial/code_examples/search_agent_integration/hybrid_search_agent.py\", hybrid_search_agent_code)\n",
    "\n",
    "# Create a comprehensive summary document about search and agent integration\n",
    "summary_content = \"\"\"# LangChain 搜索与智能体集成技术总结\n",
    "\n",
    "## 1. 集成方法概述\n",
    "\n",
    "LangChain 框架提供了多种将搜索/检索功能与智能体集成的方法，主要包括以下几种模式：\n",
    "\n",
    "### 1.1 检索工具模式\n",
    "\n",
    "在这种模式下，检索系统被封装为智能体可以使用的工具。智能体可以根据需要决定何时调用检索工具来获取相关信息。\n",
    "\n",
    "**优势：**\n",
    "- 智能体可以决定何时使用检索功能\n",
    "- 更灵活的交互模式\n",
    "- 可以结合其他工具使用\n",
    "\n",
    "**实现方式：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8703f55c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:45:17.128497Z",
     "iopub.status.busy": "2025-04-07T04:45:17.127658Z",
     "iopub.status.idle": "2025-04-07T04:45:17.151042Z",
     "shell.execute_reply": "2025-04-07T04:45:17.150040Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (4171685850.py, line 114)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[25], line 114\u001B[0;36m\u001B[0m\n\u001B[0;31m    这种方法减少了幻觉，提高了回答准确性.\u001B[0m\n\u001B[0m             ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.web_scraping import view_page_element_to_scrape\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for search and agent integration\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/docs/search_agent_integration\")\n",
    "\n",
    "# URLs for search and agent integration documentation\n",
    "search_agent_urls = [\n",
    "    (\"search_tools\", \"https://python.langchain.com/docs/modules/agents/tools/\"),\n",
    "    (\"search_toolkit\", \"https://python.langchain.com/docs/modules/agents/toolkits/retrieval\"),\n",
    "    (\"vector_stores\", \"https://python.langchain.com/docs/integrations/vectorstores/\"),\n",
    "    (\"retrievers\", \"https://python.langchain.com/docs/modules/data_connection/retrievers/\"),\n",
    "    (\"agent_with_retrieval_tool\", \"https://python.langchain.com/docs/use_cases/question_answering/how_to/chat_vector_db\")\n",
    "]\n",
    "\n",
    "# Function to extract content\n",
    "async def extract_search_agent_content(name, url):\n",
    "    print(f\"Fetching {name} documentation from: {url}\")\n",
    "    html_content = await view_page_element_to_scrape(\n",
    "        url=url,\n",
    "        requirement=f\"Extract all information about how search/retrieval capabilities can be integrated with agents\",\n",
    "        keep_links=True\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    main_content = soup.find('main')\n",
    "    \n",
    "    content = \"\"\n",
    "    if main_content:\n",
    "        title = main_content.find('h1')\n",
    "        if title:\n",
    "            content += f\"# {title.get_text(strip=True)}\\n\\n\"\n",
    "        \n",
    "        for element in main_content.find_all(['h2', 'h3', 'h4', 'p', 'pre', 'ul', 'ol', 'li', 'div']):\n",
    "            if element.name in ['h2', 'h3', 'h4']:\n",
    "                level = int(element.name[1])\n",
    "                content += f\"{'#' * level} {element.get_text(strip=True)}\\n\\n\"\n",
    "            elif element.name == 'p':\n",
    "                content += f\"{element.get_text(strip=True)}\\n\\n\"\n",
    "            elif element.name == 'pre':\n",
    "                code = element.find('code')\n",
    "                if code:\n",
    "                    language = \"python\" if \"python\" in code.get('class', [''])[0] else \"\"\n",
    "                    content += f\"```{language}\\n{code.get_text()}\\n```\\n\\n\"\n",
    "                else:\n",
    "                    content += f\"```\\n{element.get_text()}\\n```\\n\\n\"\n",
    "            elif element.name in ['ul', 'ol']:\n",
    "                for li in element.find_all('li', recursive=False):\n",
    "                    content += f\"- {li.get_text(strip=True)}\\n\"\n",
    "                content += \"\\n\"\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Collect documentation on search and agent integration\n",
    "for name, url in search_agent_urls:\n",
    "    content = await extract_search_agent_content(name, url)\n",
    "    file_path = f\"langchain_tutorial/docs/search_agent_integration/{name}.md\"\n",
    "    editor.write(file_path, content + f\"\\n\\nSource: {url}\")\n",
    "\n",
    "# Create a code example demonstrating search agent integration\n",
    "# Fix: Replace Chinese periods with ASCII periods in text content\n",
    "example_code = \"\"\"# LangChain 搜索与智能体集成示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class SearchAgentIntegration:\n",
    "    \"\"\"搜索与智能体集成的不同方法示例\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "    \n",
    "    def load_sample_documents(self):\n",
    "        \"\"\"加载示例文档\"\"\"\n",
    "        # 创建示例文档\n",
    "        texts = [\n",
    "            \"\"\"\n",
    "            LangChain是一个用于构建基于语言模型的应用程序的框架.\n",
    "            它的核心特点包括:\n",
    "            1. 组件化: 提供模块化的接口和组件\n",
    "            2. 可定制性: 可以灵活组合和调整不同组件\n",
    "            3. 调试能力: 可以轻松追踪应用中的操作\n",
    "            4. 端到端开发: 从原型到生产的完整解决方案\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            LangChain的检索增强生成(RAG)模式是将外部知识与LLM结合的强大方法.\n",
    "            RAG工作流程包括:\n",
    "            1. 索引阶段: 将文档转换为向量表示并存储\n",
    "            2. 检索阶段: 查询相关文档片段\n",
    "            3. 生成阶段: 使用检索到的上下文增强LLM的回答\n",
    "            这种方法减少了幻觉，提高了回答准确性.\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            LangChain的智能体(Agents)系统允许LLM决定使用哪些工具来解决问题.\n",
    "            智能体可以:\n",
    "            1. 拆解复杂问题\n",
    "            2. 选择并使用合适的工具\n",
    "            3. 根据工具输出调整策略\n",
    "            4. 迭代直到达成目标\n",
    "            智能体与工具的结合使LLM能够与现实世界交互.\n",
    "            \"\"\"\n",
    "        ]\n",
    "        \n",
    "        # 加载文档\n",
    "        import tempfile\n",
    "        self.documents = []\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            \n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个示例文档\")\n",
    "    \n",
    "    def process_documents(self):\n",
    "        \"\"\"处理文档并创建向量存储\"\"\"\n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = Chroma.from_documents(splits, embeddings)\n",
    "        self.retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 2}  # 获取最相关的2个文档块\n",
    "        )\n",
    "        \n",
    "        print(f\"文档已处理，共创建 {len(splits)} 个文档块\")\n",
    "    \n",
    "    def method1_retrieval_qa_chain(self, query: str) -> str:\n",
    "        \"\"\"方法1: 使用检索QA链 - 最基本的检索增强问答\"\"\"\n",
    "        print(\"\\\\n===== 方法1: 使用检索QA链 =====\")\n",
    "        \n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",  # 将所有文档合并到提示中\n",
    "            retriever=self.retriever,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        result = qa_chain({\"query\": query})\n",
    "        return result[\"result\"]\n",
    "    \n",
    "    def method2_retrieval_tool_for_agent(self, query: str) -> str:\n",
    "        \"\"\"方法2: 将检索器作为智能体工具 - 智能体可以主动决定何时搜索信息\"\"\"\n",
    "        print(\"\\\\n===== 方法2: 将检索器作为智能体工具 =====\")\n",
    "        \n",
    "        # 创建检索工具\n",
    "        def search_docs(query: str) -> str:\n",
    "            docs = self.retriever.get_relevant_documents(query)\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 定义工具\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"文档搜索\",\n",
    "                func=search_docs,\n",
    "                description=\"当你需要查询关于LangChain的信息时使用此工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        result = agent.run(query)\n",
    "        return result\n",
    "    \n",
    "    def method3_contextual_agent(self, query: str) -> str:\n",
    "        \"\"\"方法3: 基于上下文的智能体 - 先检索相关文档，然后让智能体基于上下文回答\"\"\"\n",
    "        print(\"\\\\n===== 方法3: 基于上下文的智能体 =====\")\n",
    "        \n",
    "        # 首先获取相关文档\n",
    "        docs = self.retriever.get_relevant_documents(query)\n",
    "        context = \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建带上下文的工具\n",
    "        python_tool = PythonREPLTool()\n",
    "        \n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"Python执行器\",\n",
    "                func=python_tool.run,\n",
    "                description=\"执行Python代码，适用于计算、数据处理等\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # 创建基于上下文的提示\n",
    "        contextual_prompt = f\"你有以下参考信息:\\\\n\\\\n{context}\\\\n\\\\n基于这些信息回答问题: {query}\"\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 执行具有上下文的查询\n",
    "        result = agent.run(contextual_prompt)\n",
    "        return result\n",
    "\n",
    "# 主执行函数\n",
    "def main():\n",
    "    print(\"=== LangChain 搜索与智能体集成示例 ===\")\n",
    "    \n",
    "    # 创建示例\n",
    "    example = SearchAgentIntegration()\n",
    "    \n",
    "    # 加载和处理文档\n",
    "    example.load_sample_documents()\n",
    "    example.process_documents()\n",
    "    \n",
    "    # 测试不同的集成方法\n",
    "    queries = [\n",
    "        \"LangChain的核心特点是什么?\",\n",
    "        \"解释RAG模式是如何工作的，并计算它的步骤数量\",\n",
    "        \"智能体如何与外部工具交互?\"\n",
    "    ]\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"\\\\n\\\\n问题 {i+1}: {query}\")\n",
    "        \n",
    "        # 根据问题类型选择不同的方法\n",
    "        if i == 0:\n",
    "            # 简单的事实查询 - 使用基本检索QA\n",
    "            answer = example.method1_retrieval_qa_chain(query)\n",
    "        elif i == 1:\n",
    "            # 需要计算的查询 - 使用检索工具的智能体\n",
    "            answer = example.method2_retrieval_tool_for_agent(query)\n",
    "        else:\n",
    "            # 需要更多上下文的复杂查询 - 使用上下文智能体\n",
    "            answer = example.method3_contextual_agent(query)\n",
    "        \n",
    "        print(f\"\\\\n回答: {answer}\")\n",
    "        print(\"\\\\n\" + \"-\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Write the example code\n",
    "await terminal.run(\"mkdir -p langchain_tutorial/code_examples/search_agent_integration\")\n",
    "editor.write(\"langchain_tutorial/code_examples/search_agent_integration/search_agent_methods.py\", example_code)\n",
    "\n",
    "# Create an advanced hybrid search agent example - Fixed indentation issue in the template string\n",
    "hybrid_search_agent_code = \"\"\"# LangChain 高级混合检索智能体示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool, AgentExecutor, create_react_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tempfile\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class HybridSearchTool(Tool):\n",
    "    \"\"\"混合搜索工具 - 结合关键词和向量搜索\"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstore, llm):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        # 创建基本检索器\n",
    "        self.basic_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        # 创建上下文压缩检索器\n",
    "        compressor = LLMChainExtractor.from_llm(llm)\n",
    "        self.compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=self.basic_retriever\n",
    "        )\n",
    "        \n",
    "        super().__init__(\n",
    "            name=\"混合知识库搜索\",\n",
    "            func=self.search,\n",
    "            description=\"当你需要查询文档中的特定信息时使用此工具，输入应为明确的问题或信息需求\"\n",
    "        )\n",
    "    \n",
    "    def search(self, query: str) -> str:\n",
    "        \"\"\"执行混合搜索\"\"\"\n",
    "        # 获取向量检索结果\n",
    "        vector_docs = self.basic_retriever.get_relevant_documents(query)\n",
    "        \n",
    "        # 使用LLM提取最相关的信息\n",
    "        compressed_docs = self.compression_retriever.get_relevant_documents(query)\n",
    "        \n",
    "        # 合并并去重结果\n",
    "        all_docs = []\n",
    "        seen_content = set()\n",
    "        \n",
    "        for doc in vector_docs + compressed_docs:\n",
    "            if doc.page_content not in seen_content:\n",
    "                all_docs.append(doc)\n",
    "                seen_content.add(doc.page_content)\n",
    "        \n",
    "        # 格式化结果\n",
    "        if not all_docs:\n",
    "            return \"没有找到相关信息\"\n",
    "        \n",
    "        return \"\\\\n\\\\n\".join([f\"文档 {i+1}:\\\\n{doc.page_content}\" for i, doc in enumerate(all_docs)])\n",
    "\n",
    "\n",
    "class AdvancedSearchAgent:\n",
    "    \"\"\"高级搜索智能体 - 结合多种检索方法并使用对话记忆\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        self.agent_executor = None\n",
    "    \n",
    "    def load_documents(self, file_paths: Optional[List[str]] = None):\n",
    "        \"\"\"加载文档\"\"\"\n",
    "        self.documents = []\n",
    "        \n",
    "        # 如果没有提供文件路径，使用示例文档\n",
    "        if not file_paths:\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            file_paths = []\n",
    "            \n",
    "            # 创建示例文档 - Fix: Replace Chinese punctuation with ASCII\n",
    "            example_texts = [\n",
    "                \"\"\"\n",
    "                # 搜索系统与智能体集成的方法\n",
    "                \n",
    "                搜索系统可以通过多种方式与LangChain智能体集成:\n",
    "                \n",
    "                1. **作为工具提供**: 封装为工具API供智能体调用\n",
    "                2. **预检索增强**: 在启动智能体前检索信息\n",
    "                3. **混合架构**: 两种方法的结合，根据需要使用\n",
    "                \n",
    "                每种方法都有其优缺点，适用于不同场景.\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                # 检索增强生成(RAG)架构\n",
    "                \n",
    "                RAG架构是结合检索系统和LLM的有效方法，通常包含以下组件:\n",
    "                \n",
    "                - 文档加载器: 加载各种格式的文档\n",
    "                - 文档转换器: 分割文档为可管理的块\n",
    "                - 文本嵌入模型: 将文本转换为向量表示\n",
    "                - 向量存储: 存储和索引嵌入向量\n",
    "                - 检索器: 检索相关信息\n",
    "                - 生成模型: 基于检索内容生成答案\n",
    "                \n",
    "                RAG过程包括索引、检索和生成三个阶段.\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                # 智能体工具类型\n",
    "                \n",
    "                LangChain提供多种工具类型可以与智能体结合:\n",
    "                \n",
    "                - 检索工具: 从文档中检索信息\n",
    "                - API工具: 与外部服务交互\n",
    "                - Python工具: 执行Python代码\n",
    "                - 人类工具: 获取人类反馈\n",
    "                - Shell工具: 执行系统命令\n",
    "                \n",
    "                智能体可以根据任务需求选择合适的工具.\n",
    "                \"\"\",\n",
    "                \"\"\"\n",
    "                # 上下文压缩技术\n",
    "                \n",
    "                上下文压缩技术可以优化检索结果:\n",
    "                \n",
    "                1. 嵌入过滤: 基于嵌入相似度过滤\n",
    "                2. 语义过滤: 基于语义相关性过滤\n",
    "                3. LLM抽取: 使用LLM提取最相关部分\n",
    "                4. 重排序: 重新排序检索到的文档\n",
    "                \n",
    "                这些技术可以帮助减少噪声，提高检索质量.\n",
    "                \"\"\"\n",
    "            ]\n",
    "            \n",
    "            for i, text in enumerate(example_texts):\n",
    "                file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(text)\n",
    "                file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        for file_path in file_paths:\n",
    "            try:\n",
    "                loader = TextLoader(file_path)\n",
    "                self.documents.extend(loader.load())\n",
    "            except Exception as e:\n",
    "                print(f\"加载文档 {file_path} 时出错: {str(e)}\")\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个文档\")\n",
    "    \n",
    "    def process_documents(self):\n",
    "        \"\"\"处理文档并创建向量存储\"\"\"\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"请先加载文档\")\n",
    "        \n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "        \n",
    "        print(f\"文档已处理，共创建 {len(splits)} 个文档块\")\n",
    "    \n",
    "    def setup_agent(self):\n",
    "        \"\"\"设置智能体\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先处理文档\")\n",
    "        \n",
    "        # 创建混合搜索工具\n",
    "        hybrid_search_tool = HybridSearchTool(self.vectorstore, self.llm)\n",
    "        \n",
    "        # 创建Python工具\n",
    "        python_tool = PythonREPLTool()\n",
    "        \n",
    "        # 创建检索QA链作为独立工具\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vectorstore.as_retriever()\n",
    "        )\n",
    "        \n",
    "        def qa_tool(query: str) -> str:\n",
    "            \"\"\"直接QA问答工具\"\"\"\n",
    "            return qa_chain.run(query)\n",
    "        \n",
    "        # 定义工具集\n",
    "        tools = [\n",
    "            hybrid_search_tool,\n",
    "            Tool(\n",
    "                name=\"Python执行器\",\n",
    "                func=python_tool.run,\n",
    "                description=\"执行Python代码，适用于计算、数据处理等\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"直接问答\",\n",
    "                func=qa_tool,\n",
    "                description=\"当你需要直接回答问题而不进行推理时使用此工具\"\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # 使用不带缩进的原始字符串来避免缩进问题\n",
    "        prompt_template = \"\"\"你是一个高级搜索智能体，能够访问知识库并执行代码来回答问题。\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "你可以使用以下工具:\n",
    "{tools}\n",
    "\n",
    "针对人类的问题，先考虑是否需要搜索信息或执行代码，然后使用合适的工具。\n",
    "如果信息已在聊天历史中，可以直接回答而不需要重新搜索。\n",
    "\n",
    "人类问题: {input}\n",
    "让我们一步步思考:\"\"\"\n",
    "\n",
    "        prompt = PromptTemplate.from_template(prompt_template)\n",
    "        \n",
    "        agent = create_react_agent(self.llm, tools, prompt)\n",
    "        \n",
    "        self.agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "            agent=agent,\n",
    "            tools=tools,\n",
    "            memory=self.memory,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "            max_iterations=5\n",
    "        )\n",
    "    \n",
    "    def ask(self, query: str) -> str:\n",
    "        \"\"\"向智能体提问\"\"\"\n",
    "        if not self.agent_executor:\n",
    "            raise ValueError(\"请先设置智能体\")\n",
    "        \n",
    "        result = self.agent_executor.run(query)\n",
    "        return result\n",
    "\n",
    "\n",
    "# 主执行函数\n",
    "def main():\n",
    "    print(\"=== LangChain 高级混合检索智能体示例 ===\")\n",
    "    \n",
    "    # 创建高级搜索智能体\n",
    "    agent = AdvancedSearchAgent()\n",
    "    \n",
    "    # 加载和处理文档\n",
    "    agent.load_documents()\n",
    "    agent.process_documents()\n",
    "    \n",
    "    # 设置智能体\n",
    "    agent.setup_agent()\n",
    "    \n",
    "    # 测试智能体\n",
    "    questions = [\n",
    "        \"智能体可以通过哪些方式与搜索系统集成?\",\n",
    "        \"什么是RAG架构，它有哪些组件?\",\n",
    "        \"基于之前的问题，计算RAG架构中的组件数量\",\n",
    "        \"什么是上下文压缩技术，它如何改进检索结果?\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(questions):\n",
    "        print(f\"\\\\n\\\\n问题 {i+1}: {question}\")\n",
    "        answer = agent.ask(question)\n",
    "        print(f\"\\\\n回答: {answer}\")\n",
    "        print(\"\\\\n\" + \"-\"*50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Write the advanced hybrid search agent example\n",
    "editor.write(\"langchain_tutorial/code_examples/search_agent_integration/hybrid_search_agent.py\", hybrid_search_agent_code)\n",
    "\n",
    "# Create a comprehensive summary document about search and agent integration\n",
    "summary_content = \"\"\"# LangChain 搜索与智能体集成技术总结\n",
    "\n",
    "## 1. 集成方法概述\n",
    "\n",
    "LangChain 框架提供了多种将搜索/检索功能与智能体集成的方法，主要包括以下几种模式:\n",
    "\n",
    "### 1.1 检索工具模式\n",
    "\n",
    "在这种模式下，检索系统被封装为智能体可以使用的工具。智能体可以根据需要决定何时调用检索工具来获取相关信息。\n",
    "\n",
    "**优势:**\n",
    "- 智能体可以决定何时使用检索功能\n",
    "- 更灵活的交互模式\n",
    "- 可以结合其他工具使用\n",
    "\n",
    "**实现方式:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce26456e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:50:53.176932Z",
     "iopub.status.busy": "2025-04-07T04:50:53.176604Z",
     "iopub.status.idle": "2025-04-07T04:50:53.185437Z",
     "shell.execute_reply": "2025-04-07T04:50:53.184430Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 413)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m<tokenize>:413\u001B[0;36m\u001B[0m\n\u001B[0;31m    agent = initialize_agent(\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "I need to fix the encoding issues in our previous code examples and create additional examples for search-enhanced agents with LangChain. Let me focus on creating a new example that demonstrates different ways to integrate search capabilities with agents.\n",
    "\n",
    "```python\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "\n",
    "# Set up tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for search-enhanced agent examples\n",
    "async def create_search_agent_examples():\n",
    "    print(\"Creating search-enhanced agent examples...\")\n",
    "    \n",
    "    # Make sure directory exists\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/code_examples/search_agent_integration\")\n",
    "    \n",
    "    # Create a comprehensive example demonstrating different ways to integrate search with agents\n",
    "    search_enhanced_agent_code = \"\"\"# LangChain 搜索与智能体结合综合示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class SearchEnhancedAgent:\n",
    "    \"\"\"搜索增强智能体 - 展示搜索与智能体结合的不同方式\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.vectorstore = None\n",
    "        self.documents = []\n",
    "        self.memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "    \n",
    "    def load_sample_documents(self):\n",
    "        \"\"\"加载示例文档\"\"\"\n",
    "        print(\"正在加载示例文档...\")\n",
    "        \n",
    "        # 创建示例文本\n",
    "        documents_text = [\n",
    "            \"\"\"\n",
    "            # LangChain搜索集成\n",
    "            \n",
    "            LangChain提供多种将搜索功能集成到智能体的方法:\n",
    "            \n",
    "            1. 检索工具（Retrieval Tools）: 将检索器包装为工具供智能体使用\n",
    "            2. 上下文增强（Contextual Augmentation）: 在智能体处理前添加相关上下文\n",
    "            3. 检索增强生成（RAG）: 结合检索和生成能力来提供更准确的回答\n",
    "            4. 自主检索（Self-querying）: 让智能体自己决定如何查询知识库\n",
    "            \n",
    "            这些方法可以根据具体需求组合使用。\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            # 向量检索优化\n",
    "            \n",
    "            向量检索可以通过以下技术优化:\n",
    "            \n",
    "            1. 查询修改: 重写或扩展用户查询以提高检索质量\n",
    "            2. 过滤: 使用元数据过滤相关文档\n",
    "            3. 重排序: 使用额外标准对检索结果重新排序\n",
    "            4. 压缩: 提取最相关的内容片段\n",
    "            5. 混合检索: 结合语义和关键词搜索\n",
    "            \n",
    "            优化后的检索系统能够显著提高智能体的响应质量。\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            # 智能体工具选择\n",
    "            \n",
    "            智能体需要智能地选择合适的工具:\n",
    "            \n",
    "            1. 基于查询分析选择搜索或计算工具\n",
    "            2. 考虑任务的信息需求和复杂度\n",
    "            3. 在多个信息源之间平衡权衡\n",
    "            4. 评估工具执行结果并决定后续行动\n",
    "            \n",
    "            有效的工具选择使智能体能够更高效地完成任务。\n",
    "            \"\"\"\n",
    "        ]\n",
    "        \n",
    "        # 使用临时文件存储文档\n",
    "        import tempfile\n",
    "        self.documents = []\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        \n",
    "        # 写入和加载文档\n",
    "        for i, text in enumerate(documents_text):\n",
    "            file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            \n",
    "            # 加载文档\n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个示例文档\")\n",
    "    \n",
    "    def create_vectorstore(self):\n",
    "        \"\"\"处理文档并创建向量存储\"\"\"\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"请先加载文档\")\n",
    "        \n",
    "        print(\"正在创建向量存储...\")\n",
    "        \n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = Chroma.from_documents(splits, embeddings)\n",
    "        \n",
    "        print(f\"向量存储已创建，共 {len(splits)} 个文本块\")\n",
    "        return self.vectorstore\n",
    "    \n",
    "    def method1_retrieval_qa_chain(self):\n",
    "        \"\"\"方法1: 基础检索QA - 使用检索QA链直接回答问题\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\n=== 方法1: 基础检索QA ===\")\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 2}\n",
    "        )\n",
    "        \n",
    "        # 创建检索QA链\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        query = \"LangChain提供哪些方法将搜索功能集成到智能体中?\"\n",
    "        result = qa_chain.invoke({\"query\": query})\n",
    "        print(f\"\\n问题: {query}\")\n",
    "        print(f\"回答: {result['result']}\")\n",
    "        \n",
    "        return qa_chain\n",
    "    \n",
    "    def method2_retrieval_tool(self):\n",
    "        \"\"\"方法2: 检索工具 - 将检索器包装为智能体工具\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\n=== 方法2: 检索工具 ===\")\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 2}\n",
    "        )\n",
    "        \n",
    "        # 创建检索工具\n",
    "        def search_docs(query: str) -> str:\n",
    "            docs = retriever.get_relevant_documents(query)\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建工具列表\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"文档搜索\",\n",
    "                func=search_docs,\n",
    "                description=\"当需要查询有关LangChain搜索集成或向量检索技术的信息时使用\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        query = \"向量检索可以通过哪些技术优化? 列出这些技术，并计算总数。\"\n",
    "        result = agent.invoke(query)\n",
    "        print(f\"\\n问题: {query}\")\n",
    "        print(f\"回答: {result}\")\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def method3_context_augmented_agent(self):\n",
    "        \"\"\"方法3: 上下文增强智能体 - 先检索相关文档作为上下文，再使用智能体处理\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\n=== 方法3: 上下文增强智能体 ===\")\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "        \n",
    "        # 创建工具\n",
    "        tools = [\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            memory=self.memory,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        query = \"智能体如何选择合适的工具?\"\n",
    "        \n",
    "        # 先检索相关文档\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        context = \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 添加上下文后处理\n",
    "        augmented_query = f\"基于以下信息回答问题。如果信息不足，可以使用自己的知识。\\\\n\\\\n信息: {context}\\\\n\\\\n问题: {query}\"\n",
    "        \n",
    "        result = agent.invoke(augmented_query)\n",
    "        print(f\"\\n问题: {query}\")\n",
    "        print(f\"回答: {result}\")\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def method4_advanced_rag(self):\n",
    "        \"\"\"方法4: 高级RAG - 使用上下文压缩和混合检索增强智能体\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\n=== 方法4: 高级RAG ===\")\n",
    "        \n",
    "        # 创建基本检索器\n",
    "        base_retriever = self.vectorstore.as_retriever()\n",
    "        \n",
    "        # 创建压缩器\n",
    "        compressor = LLMChainExtractor.from_llm(self.llm)\n",
    "        \n",
    "        # 创建压缩检索器\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=base_retriever\n",
    "        )\n",
    "        \n",
    "        # 创建RAG提示模板\n",
    "        rag_prompt = PromptTemplate.from_template(\\\"\\\"\\\"\n",
    "        你是一个专业助手，请根据以下检索到的信息回答问题。\n",
    "        如果检索的信息不足以回答问题，请说明信息不足，并尝试基于你的知识提供相关见解。\n",
    "        \n",
    "        检索到的信息:\n",
    "        {context}\n",
    "        \n",
    "        问题: {question}\n",
    "        \n",
    "        请提供详细且结构化的回答:\n",
    "        \\\"\\\"\\\")\n",
    "        \n",
    "        # 构建RAG链\n",
    "        def format_docs(docs):\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        rag_chain = (\n",
    "            {\"context\": compression_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | rag_prompt\n",
    "            | self.llm\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        query = \"比较不同搜索集成方法的优缺点\"\n",
    "        result = rag_chain.invoke(query)\n",
    "        print(f\"\\n问题: {query}\")\n",
    "        print(f\"回答: {result.content if hasattr(result, 'content') else result}\")\n",
    "        \n",
    "        return rag_chain\n",
    "    \n",
    "    def method5_query_transformation(self):\n",
    "        \"\"\"方法5: 查询转换 - 使用LLM改进查询后再检索\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\n=== 方法5: 查询转换 ===\")\n",
    "        \n",
    "        # 创建查询改写链\n",
    "        query_transformer_prompt = PromptTemplate.from_template(\\\"\\\"\\\"\n",
    "        给定以下原始查询，请将其重写为更有效的向量数据库检索查询。\n",
    "        添加可能相关的关键词，使查询更完整，但保持简洁。\n",
    "        \n",
    "        原始查询: {query}\n",
    "        \n",
    "        重写的查询:\n",
    "        \\\"\\\"\\\")\n",
    "        \n",
    "        query_transformer_chain = query_transformer_prompt | self.llm\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "        \n",
    "        # 执行查询\n",
    "        original_query = \"智能体使用工具的最佳实践\"\n",
    "        \n",
    "        # 1. 改写查询\n",
    "        transformed_query_result = query_transformer_chain.invoke({\"query\": original_query})\n",
    "        transformed_query = transformed_query_result.content if hasattr(transformed_query_result, 'content') else str(transformed_query_result)\n",
    "        \n",
    "        print(f\"\\n原始查询: {original_query}\")\n",
    "        print(f\"改写后查询: {transformed_query}\")\n",
    "        \n",
    "        # 2. 使用改写后的查询进行检索\n",
    "        docs = retriever.get_relevant_documents(transformed_query)\n",
    "        context = \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 3. 使用LLM生成最终答案\n",
    "        final_prompt = f\"基于以下信息回答问题: '{original_query}'\\\\n\\\\n检索到的信息:\\\\n{context}\"\n",
    "        final_result = self.llm.invoke(final_prompt)\n",
    "        \n",
    "        print(f\"回答: {final_result.content if hasattr(final_result, 'content') else final_result}\")\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": original_query,\n",
    "            \"transformed_query\": transformed_query,\n",
    "            \"retrieved_context\": context,\n",
    "            \"final_result\": final_result\n",
    "        }\n",
    "    \n",
    "    def run_all_methods(self):\n",
    "        \"\"\"运行所有方法进行演示\"\"\"\n",
    "        # 准备数据\n",
    "        self.load_sample_documents()\n",
    "        self.create_vectorstore()\n",
    "        \n",
    "        # 运行各种方法\n",
    "        self.method1_retrieval_qa_chain()\n",
    "        self.method2_retrieval_tool()\n",
    "        self.method3_context_augmented_agent()\n",
    "        self.method4_advanced_rag()\n",
    "        self.method5_query_transformation()\n",
    "        \n",
    "        print(\"\\n所有方法演示完成！\")\n",
    "\n",
    "\n",
    "# 多步骤搜索智能体示例\n",
    "class MultiStepSearchAgent:\n",
    "    \"\"\"多步骤搜索智能体 - 实现迭代搜索和信息整合\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "        self.vectorstore = None\n",
    "    \n",
    "    def setup_from_existing(self, vectorstore):\n",
    "        \"\"\"使用现有向量存储设置智能体\"\"\"\n",
    "        self.vectorstore = vectorstore\n",
    "    \n",
    "    def create_search_planning_agent(self):\n",
    "        \"\"\"创建搜索规划智能体\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先设置向量存储\")\n",
    "        \n",
    "        # 创建检索工具\n",
    "        retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "        \n",
    "        def search_docs(query: str) -> str:\n",
    "            docs = retriever.get_relevant_documents(query)\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建工具列表\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"文档搜索\",\n",
    "                func=search_docs,\n",
    "                description=\"当需要查询与任务相关的信息时使用此工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 使用自定义提示创建智能体\n",
    "        planning_prompt = \\\"\\\"\\\"你是一个专业的研究助手，可以通过分解复杂问题并使用搜索工具找到相关信息来解决问题。\n",
    "        \n",
    "        对于复杂问题，请先思考如何将其分解为多个子问题，然后逐一解决这些子问题。\n",
    "        检索到的信息可能不完整，需要进行多次搜索并整合信息。\n",
    "        始终以结构化的方式整理你的思考过程和发现。\n",
    "        \n",
    "        当前可用工具：\n",
    "        {tools}\n",
    "        \n",
    "        任务: {input}\n",
    "        {agent_scratchpad}\n",
    "        \"\"\"\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            memory=self.memory,\n",
    "            handle_parsing_errors=True,\n",
    "            max_iterations=8\n",
    "        )\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def process_complex_query(self, query: str):\n",
    "        \"\"\"处理需要多步骤搜索的复杂查询\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先设置向量存储\")\n",
    "        \n",
    "        print(f\"\\n=== 处理复杂查询: {query} ===\")\n",
    "        \n",
    "        # 创建搜索规划智能体\n",
    "        agent = self.create_search_planning_agent()\n",
    "        \n",
    "        # 执行多步骤搜索\n",
    "        result = agent.invoke(f\"请通过多步骤搜索解决以下问题，确保全面回答所有相关方面: {query}\")\n",
    "        \n",
    "        print(f\"\\n最终回答: {result}\")\n",
    "        return result\n",
    "\n",
    "\n",
    "# 运行示例\n",
    "def main():\n",
    "    print(\"=== LangChain 搜索与智能体结合综合示例 ===\")\n",
    "    \n",
    "    # 创建并运行基本搜索增强智能体\n",
    "    print(\"\\n1. 运行基本搜索增强智能体示例\")\n",
    "    search_agent = SearchEnhancedAgent()\n",
    "    search_agent.load_sample_documents()\n",
    "    search_agent.create_vectorstore()\n",
    "    \n",
    "    # 运行各类方法\n",
    "    search_agent.method1_retrieval_qa_chain()\n",
    "    search_agent.method2_retrieval_tool()\n",
    "    search_agent.method3_context_augmented_agent()\n",
    "    search_agent.method4_advanced_rag()\n",
    "    \n",
    "    # 创建并运行多步骤搜索智能体\n",
    "    print(\"\\n2. 运行多步骤搜索智能体示例\")\n",
    "    multi_step_agent = MultiStepSearchAgent()\n",
    "    multi_step_agent.setup_from_existing(search_agent.vectorstore)\n",
    "    \n",
    "    # 执行复杂查询\n",
    "    complex_query = \"比较不同搜索集成方法的优缺点，并推荐适合不同应用场景的最佳选择\"\n",
    "    multi_step_agent.process_complex_query(complex_query)\n",
    "    \n",
    "    print(\"\\n=== 示例运行完成 ===\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "    \n",
    "    # Create a real-world example of search-enhanced agent integration\n",
    "    application_example_code = \"\"\"# LangChain 搜索增强智能体实际应用示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool, AgentExecutor\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
    "from langchain.schema import SystemMessage\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class ProductSupport:\n",
    "    \"\"\"产品支持智能体 - 结合知识库搜索的技术支持助手\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0.2)\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.agent = None\n",
    "    \n",
    "    def setup_knowledge_base(self):\n",
    "        \"\"\"设置示例产品知识库\"\"\"\n",
    "        print(\"设置产品知识库...\")\n",
    "        \n",
    "        # 创建示例知识库文档\n",
    "        product_docs = [\n",
    "            {\n",
    "                \"title\": \"产品概述\",\n",
    "                \"content\": \"\"\"\n",
    "                智能家居控制系统 v2.0\n",
    "                \n",
    "                我们的智能家居控制系统允许用户通过移动应用、语音或自动化规则控制家中的所有联网设备。\n",
    "                系统支持灯光、恒温器、安全摄像头、门锁、窗帘和家电等设备。\n",
    "                主要功能包括:\n",
    "                - 远程控制: 从任何地方控制家中设备\n",
    "                - 语音控制: 通过Alexa、Google Assistant集成\n",
    "                - 自动化: 基于时间、位置或传感器触发的规则\n",
    "                - 能源监控: 跟踪能源使用并提供优化建议\n",
    "                - 安全警报: 异常活动通知\n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"安装指南\",\n",
    "                \"content\": \"\"\"\n",
    "                智能家居控制系统安装指南\n",
    "                \n",
    "                1. 硬件要求:\n",
    "                   - 中央控制枢纽(包含在包装中)\n",
    "                   - WiFi网络(推荐5GHz)\n",
    "                   - 兼容的智能设备\n",
    "                   - iOS或Android手机(用于移动应用)\n",
    "                \n",
    "                2. 初始设置:\n",
    "                   a. 将中央控制枢纽连接到电源\n",
    "                   b. 将枢纽连接到您的WiFi网络\n",
    "                   c. 在手机上下载并安装\"智能家居\"应用\n",
    "                   d. 创建账户并按照应用中的指导进行操作\n",
    "                \n",
    "                3. 设备配对:\n",
    "                   a. 在应用中点击\"添加设备\"\n",
    "                   b. 选择设备类型\n",
    "                   c. 将设备设置为配对模式(参考设备说明)\n",
    "                   d. 按照应用中的特定说明完成配对\n",
    "                \n",
    "                常见问题:\n",
    "                - 如果枢纽无法连接WiFi，请确保路由器固件已更新\n",
    "                - 蓝灯闪烁表示配对模式，红灯表示连接错误\n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"故障排除\",\n",
    "                \"content\": \"\"\"\n",
    "                智能家居系统故障排除指南\n",
    "                \n",
    "                1. 设备离线:\n",
    "                   - 检查设备电源\n",
    "                   - 确认WiFi连接正常\n",
    "                   - 重启设备(断电10秒后重新连接)\n",
    "                   - 重启中央控制枢纽\n",
    "                   - 确保设备在WiFi范围内\n",
    "                \n",
    "                2. 应用程序无法连接:\n",
    "                   - 检查手机网络连接\n",
    "                   - 确认使用正确的账户凭据\n",
    "                   - 清除应用缓存并重新启动\n",
    "                   - 检查应用是否需要更新\n",
    "                \n",
    "                3. 自动化规则失效:\n",
    "                   - 验证触发条件是否满足\n",
    "                   - 检查所有相关设备是否在线\n",
    "                   - 查看规则设置中的时区设置\n",
    "                   - 删除并重新创建规则\n",
    "                \n",
    "                4. 系统响应缓慢:\n",
    "                   - 检查internet连接速度\n",
    "                   - 减少连接到枢纽的设备数量\n",
    "                   - 重启中央控制枢纽\n",
    "                   - 检查固件更新\n",
    "                \n",
    "                5. 错误代码:\n",
    "                   - E01: 网络连接错误\n",
    "                   - E02: 设备认证失败\n",
    "                   - E03: 固件更新失败\n",
    "                   - E04: 存储空间不足\n",
    "                   - E05: 系统过载\n",
    "                \"\"\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # 创建临时文件存储文档\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        file_paths = []\n",
    "        \n",
    "        for doc in product_docs:\n",
    "            file_path = os.path.join(temp_dir, f\"{doc['title'].replace(' ', '_')}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"# {doc['title']}\\\\n\\\\n{doc['content']}\")\n",
    "            file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        for file_path in file_paths:\n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        # 处理文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "        \n",
    "        print(f\"知识库设置完成，包含 {len(splits)} 个文本块\")\n",
    "    \n",
    "    def setup_agent(self):\n",
    "        \"\"\"设置产品支持智能体\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先设置知识库\")\n",
    "        \n",
    "        print(\"设置产品支持智能体...\")\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "        \n",
    "        # 创建上下文压缩检索器\n",
    "        compressor = LLMChainExtractor.from_llm(self.llm)\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=retriever\n",
    "        )\n",
    "        \n",
    "        # 创建检索工具\n",
    "        def search_product_knowledge(query: str) -> str:\n",
    "            \"\"\"搜索产品知识库\"\"\"\n",
    "            docs = compression_retriever.get_relevant_documents(query)\n",
    "            if not docs:\n",
    "                return \"知识库中没有找到相关信息。\"\n",
    "            return \"\\\\n\\\\n\".join([f\"来源: {doc.metadata.get('source', '未知')}\\\\n内容: {doc.page_content}\" for doc in docs])\n",
    "        \n",
    "        # 创建故障诊断工具\n",
    "        def diagnose_problem(description: str) -> str:\n",
    "            \"\"\"诊断产品问题\"\"\"\n",
    "            # 创建诊断链\n",
    "            diagnosis_prompt = PromptTemplate(\n",
    "                template=\"你是智能家居系统专家。请分析以下问题描述并提供可能的原因和解决步骤：\\\\n\\\\n{problem_description}\",\n",
    "                input_variables=[\"problem_description\"]\n",
    "            )\n",
    "            diagnosis_chain = LLMChain(llm=self.llm, prompt=diagnosis_prompt)\n",
    "            \n",
    "            # 执行诊断\n",
    "            result = diagnosis_chain.run(description)\n",
    "            return result\n",
    "        \n",
    "        # 定义工具\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"产品知识库\",\n",
    "                func=search_product_knowledge,\n",
    "                description=\"当需要查询产品信息、安装指南或常见问题时使用\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"故障诊断\",\n",
    "                func=diagnose_problem,\n",
    "                description=\"当用户描述具体问题需要诊断时使用\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建产品支持智能体\n",
    "        system_message = SystemMessage(\n",
    "            content=\\\"\\\"\\\"你是智能家居控制系统的客户支持专家。你的任务是帮助用户解决与产品相关的问题。\n",
    "            \n",
    "            遵循以下指南:\n",
    "            1. 首先理解用户的问题\n",
    "            2. 使用产品知识库工具查询相关信息\n",
    "            3. 如果是具体的技术问题，使用故障诊断工具\n",
    "            4. 以友好、专业的方式回应用户\n",
    "            5. 给出清晰、分步骤的解决方案\n",
    "            6. 如果知识库中没有相关信息，承认这一点并提供一般性建议\n",
    "            \n",
    "            确保回答准确、实用且易于理解。\n",
    "            \\\"\\\"\\\"\n",
    "        )\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            system_message,\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ])\n",
    "        \n",
    "        self.agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            memory=self.memory,\n",
    "            handle_parsing_errors=True,\n",
    "            agent_kwargs={\"system_message\": system_message}\n",
    "        )\n",
    "        \n",
    "        print(\"产品支持智能体设置完成\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6189d4a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:54:29.745347Z",
     "iopub.status.busy": "2025-04-07T04:54:29.745014Z",
     "iopub.status.idle": "2025-04-07T04:54:29.770050Z",
     "shell.execute_reply": "2025-04-07T04:54:29.768891Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (2088735988.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[28], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    In my previous implementation, I was trying to create a code example that demonstrates different ways to integrate search capabilities with LangChain agents. The error is an indentation error at line 413, specifically at the `agent = initialize_agent(` line in the `ProductSupport.setup_agent` method. This indicates that there's an inconsistent indentation level in the code.\u001B[0m\n\u001B[0m                                                                                                                                                                                                                                                                                                                                           ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "[reflection on previous impl]\n",
    "In my previous implementation, I was trying to create a code example that demonstrates different ways to integrate search capabilities with LangChain agents. The error is an indentation error at line 413, specifically at the `agent = initialize_agent(` line in the `ProductSupport.setup_agent` method. This indicates that there's an inconsistent indentation level in the code.\n",
    "\n",
    "Looking more carefully at the code structure, I see that the indentation for the `setup_agent` method is inconsistent with the rest of the class methods. This is especially problematic in Python where indentation is significant for code structure.\n",
    "\n",
    "Additionally, the code is quite long and was cut off in the middle of the `ProductSupport` class implementation, without showing the complete methods and their corresponding indentation levels. I need to ensure consistent indentation throughout the class and complete any unfinished methods.\n",
    "\n",
    "[improved impl]:\n",
    "```python\n",
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Set up tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "# Create directory for search-enhanced agent examples\n",
    "async def create_search_agent_examples():\n",
    "    print(\"Creating search-enhanced agent examples...\")\n",
    "    \n",
    "    # Make sure directory exists\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/code_examples/search_agent_integration\")\n",
    "    \n",
    "    # Create a comprehensive example demonstrating different ways to integrate search with agents\n",
    "    search_enhanced_agent_code = \"\"\"# LangChain 搜索与智能体结合综合示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class SearchEnhancedAgent:\n",
    "    \\\"\\\"\\\"搜索增强智能体 - 展示搜索与智能体结合的不同方式\\\"\\\"\\\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.vectorstore = None\n",
    "        self.documents = []\n",
    "        self.memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "    \n",
    "    def load_sample_documents(self):\n",
    "        \\\"\\\"\\\"加载示例文档\\\"\\\"\\\"\n",
    "        print(\"正在加载示例文档...\")\n",
    "        \n",
    "        # 创建示例文本\n",
    "        documents_text = [\n",
    "            \\\"\\\"\\\"\n",
    "            # LangChain搜索集成\n",
    "            \n",
    "            LangChain提供多种将搜索功能集成到智能体的方法:\n",
    "            \n",
    "            1. 检索工具（Retrieval Tools）: 将检索器包装为工具供智能体使用\n",
    "            2. 上下文增强（Contextual Augmentation）: 在智能体处理前添加相关上下文\n",
    "            3. 检索增强生成（RAG）: 结合检索和生成能力来提供更准确的回答\n",
    "            4. 自主检索（Self-querying）: 让智能体自己决定如何查询知识库\n",
    "            \n",
    "            这些方法可以根据具体需求组合使用。\n",
    "            \\\"\\\"\\\",\n",
    "            \\\"\\\"\\\"\n",
    "            # 向量检索优化\n",
    "            \n",
    "            向量检索可以通过以下技术优化:\n",
    "            \n",
    "            1. 查询修改: 重写或扩展用户查询以提高检索质量\n",
    "            2. 过滤: 使用元数据过滤相关文档\n",
    "            3. 重排序: 使用额外标准对检索结果重新排序\n",
    "            4. 压缩: 提取最相关的内容片段\n",
    "            5. 混合检索: 结合语义和关键词搜索\n",
    "            \n",
    "            优化后的检索系统能够显著提高智能体的响应质量。\n",
    "            \\\"\\\"\\\",\n",
    "            \\\"\\\"\\\"\n",
    "            # 智能体工具选择\n",
    "            \n",
    "            智能体需要智能地选择合适的工具:\n",
    "            \n",
    "            1. 基于查询分析选择搜索或计算工具\n",
    "            2. 考虑任务的信息需求和复杂度\n",
    "            3. 在多个信息源之间平衡权衡\n",
    "            4. 评估工具执行结果并决定后续行动\n",
    "            \n",
    "            有效的工具选择使智能体能够更高效地完成任务。\n",
    "            \\\"\\\"\\\"\n",
    "        ]\n",
    "        \n",
    "        # 使用临时文件存储文档\n",
    "        import tempfile\n",
    "        self.documents = []\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        \n",
    "        # 写入和加载文档\n",
    "        for i, text in enumerate(documents_text):\n",
    "            file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "            \n",
    "            # 加载文档\n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        print(f\"已加载 {len(self.documents)} 个示例文档\")\n",
    "    \n",
    "    def create_vectorstore(self):\n",
    "        \\\"\\\"\\\"处理文档并创建向量存储\\\"\\\"\\\"\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"请先加载文档\")\n",
    "        \n",
    "        print(\"正在创建向量存储...\")\n",
    "        \n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = Chroma.from_documents(splits, embeddings)\n",
    "        \n",
    "        print(f\"向量存储已创建，共 {len(splits)} 个文本块\")\n",
    "        return self.vectorstore\n",
    "    \n",
    "    def method1_retrieval_qa_chain(self):\n",
    "        \\\"\\\"\\\"方法1: 基础检索QA - 使用检索QA链直接回答问题\\\"\\\"\\\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\\\n=== 方法1: 基础检索QA ===\")\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 2}\n",
    "        )\n",
    "        \n",
    "        # 创建检索QA链\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        query = \"LangChain提供哪些方法将搜索功能集成到智能体中?\"\n",
    "        result = qa_chain.invoke({\"query\": query})\n",
    "        print(f\"\\\\n问题: {query}\")\n",
    "        print(f\"回答: {result['result']}\")\n",
    "        \n",
    "        return qa_chain\n",
    "    \n",
    "    def method2_retrieval_tool(self):\n",
    "        \\\"\\\"\\\"方法2: 检索工具 - 将检索器包装为智能体工具\\\"\\\"\\\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\\\n=== 方法2: 检索工具 ===\")\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 2}\n",
    "        )\n",
    "        \n",
    "        # 创建检索工具\n",
    "        def search_docs(query: str) -> str:\n",
    "            docs = retriever.get_relevant_documents(query)\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建工具列表\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"文档搜索\",\n",
    "                func=search_docs,\n",
    "                description=\"当需要查询有关LangChain搜索集成或向量检索技术的信息时使用\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        query = \"向量检索可以通过哪些技术优化? 列出这些技术，并计算总数。\"\n",
    "        result = agent.invoke(query)\n",
    "        print(f\"\\\\n问题: {query}\")\n",
    "        print(f\"回答: {result}\")\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def method3_context_augmented_agent(self):\n",
    "        \\\"\\\"\\\"方法3: 上下文增强智能体 - 先检索相关文档作为上下文，再使用智能体处理\\\"\\\"\\\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\\\n=== 方法3: 上下文增强智能体 ===\")\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "        \n",
    "        # 创建工具\n",
    "        tools = [\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            memory=self.memory,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        query = \"智能体如何选择合适的工具?\"\n",
    "        \n",
    "        # 先检索相关文档\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        context = \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 添加上下文后处理\n",
    "        augmented_query = f\"基于以下信息回答问题。如果信息不足，可以使用自己的知识。\\\\n\\\\n信息: {context}\\\\n\\\\n问题: {query}\"\n",
    "        \n",
    "        result = agent.invoke(augmented_query)\n",
    "        print(f\"\\\\n问题: {query}\")\n",
    "        print(f\"回答: {result}\")\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def method4_advanced_rag(self):\n",
    "        \\\"\\\"\\\"方法4: 高级RAG - 使用上下文压缩和混合检索增强智能体\\\"\\\"\\\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\\\n=== 方法4: 高级RAG ===\")\n",
    "        \n",
    "        # 创建基本检索器\n",
    "        base_retriever = self.vectorstore.as_retriever()\n",
    "        \n",
    "        # 创建压缩器\n",
    "        compressor = LLMChainExtractor.from_llm(self.llm)\n",
    "        \n",
    "        # 创建压缩检索器\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=base_retriever\n",
    "        )\n",
    "        \n",
    "        # 创建RAG提示模板\n",
    "        rag_prompt = PromptTemplate.from_template(\\\"\\\"\\\"\n",
    "        你是一个专业助手，请根据以下检索到的信息回答问题。\n",
    "        如果检索的信息不足以回答问题，请说明信息不足，并尝试基于你的知识提供相关见解。\n",
    "        \n",
    "        检索到的信息:\n",
    "        {context}\n",
    "        \n",
    "        问题: {question}\n",
    "        \n",
    "        请提供详细且结构化的回答:\n",
    "        \\\"\\\"\\\")\n",
    "        \n",
    "        # 构建RAG链\n",
    "        def format_docs(docs):\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        rag_chain = (\n",
    "            {\"context\": compression_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | rag_prompt\n",
    "            | self.llm\n",
    "        )\n",
    "        \n",
    "        # 执行查询\n",
    "        query = \"比较不同搜索集成方法的优缺点\"\n",
    "        result = rag_chain.invoke(query)\n",
    "        print(f\"\\\\n问题: {query}\")\n",
    "        print(f\"回答: {result.content if hasattr(result, 'content') else result}\")\n",
    "        \n",
    "        return rag_chain\n",
    "    \n",
    "    def method5_query_transformation(self):\n",
    "        \\\"\\\"\\\"方法5: 查询转换 - 使用LLM改进查询后再检索\\\"\\\"\\\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先创建向量存储\")\n",
    "        \n",
    "        print(\"\\\\n=== 方法5: 查询转换 ===\")\n",
    "        \n",
    "        # 创建查询改写链\n",
    "        query_transformer_prompt = PromptTemplate.from_template(\\\"\\\"\\\"\n",
    "        给定以下原始查询，请将其重写为更有效的向量数据库检索查询。\n",
    "        添加可能相关的关键词，使查询更完整，但保持简洁。\n",
    "        \n",
    "        原始查询: {query}\n",
    "        \n",
    "        重写的查询:\n",
    "        \\\"\\\"\\\")\n",
    "        \n",
    "        query_transformer_chain = query_transformer_prompt | self.llm\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "        \n",
    "        # 执行查询\n",
    "        original_query = \"智能体使用工具的最佳实践\"\n",
    "        \n",
    "        # 1. 改写查询\n",
    "        transformed_query_result = query_transformer_chain.invoke({\"query\": original_query})\n",
    "        transformed_query = transformed_query_result.content if hasattr(transformed_query_result, 'content') else str(transformed_query_result)\n",
    "        \n",
    "        print(f\"\\\\n原始查询: {original_query}\")\n",
    "        print(f\"改写后查询: {transformed_query}\")\n",
    "        \n",
    "        # 2. 使用改写后的查询进行检索\n",
    "        docs = retriever.get_relevant_documents(transformed_query)\n",
    "        context = \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 3. 使用LLM生成最终答案\n",
    "        final_prompt = f\"基于以下信息回答问题: '{original_query}'\\\\n\\\\n检索到的信息:\\\\n{context}\"\n",
    "        final_result = self.llm.invoke(final_prompt)\n",
    "        \n",
    "        print(f\"回答: {final_result.content if hasattr(final_result, 'content') else final_result}\")\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": original_query,\n",
    "            \"transformed_query\": transformed_query,\n",
    "            \"retrieved_context\": context,\n",
    "            \"final_result\": final_result\n",
    "        }\n",
    "    \n",
    "    def run_all_methods(self):\n",
    "        \\\"\\\"\\\"运行所有方法进行演示\\\"\\\"\\\"\n",
    "        # 准备数据\n",
    "        self.load_sample_documents()\n",
    "        self.create_vectorstore()\n",
    "        \n",
    "        # 运行各种方法\n",
    "        self.method1_retrieval_qa_chain()\n",
    "        self.method2_retrieval_tool()\n",
    "        self.method3_context_augmented_agent()\n",
    "        self.method4_advanced_rag()\n",
    "        self.method5_query_transformation()\n",
    "        \n",
    "        print(\"\\\\n所有方法演示完成！\")\n",
    "\n",
    "\n",
    "# 多步骤搜索智能体示例\n",
    "class MultiStepSearchAgent:\n",
    "    \\\"\\\"\\\"多步骤搜索智能体 - 实现迭代搜索和信息整合\\\"\\\"\\\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "        self.vectorstore = None\n",
    "    \n",
    "    def setup_from_existing(self, vectorstore):\n",
    "        \\\"\\\"\\\"使用现有向量存储设置智能体\\\"\\\"\\\"\n",
    "        self.vectorstore = vectorstore\n",
    "    \n",
    "    def create_search_planning_agent(self):\n",
    "        \\\"\\\"\\\"创建搜索规划智能体\\\"\\\"\\\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先设置向量存储\")\n",
    "        \n",
    "        # 创建检索工具\n",
    "        retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "        \n",
    "        def search_docs(query: str) -> str:\n",
    "            docs = retriever.get_relevant_documents(query)\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建工具列表\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"文档搜索\",\n",
    "                func=search_docs,\n",
    "                description=\"当需要查询与任务相关的信息时使用此工具\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            memory=self.memory,\n",
    "            handle_parsing_errors=True,\n",
    "            max_iterations=8\n",
    "        )\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def process_complex_query(self, query: str):\n",
    "        \\\"\\\"\\\"处理需要多步骤搜索的复杂查询\\\"\\\"\\\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先设置向量存储\")\n",
    "        \n",
    "        print(f\"\\\\n=== 处理复杂查询: {query} ===\")\n",
    "        \n",
    "        # 创建搜索规划智能体\n",
    "        agent = self.create_search_planning_agent()\n",
    "        \n",
    "        # 执行多步骤搜索\n",
    "        result = agent.invoke(f\"请通过多步骤搜索解决以下问题，确保全面回答所有相关方面: {query}\")\n",
    "        \n",
    "        print(f\"\\\\n最终回答: {result}\")\n",
    "        return result\n",
    "\n",
    "\n",
    "# 运行示例\n",
    "def main():\n",
    "    print(\"=== LangChain 搜索与智能体结合综合示例 ===\")\n",
    "    \n",
    "    # 创建并运行基本搜索增强智能体\n",
    "    print(\"\\\\n1. 运行基本搜索增强智能体示例\")\n",
    "    search_agent = SearchEnhancedAgent()\n",
    "    search_agent.load_sample_documents()\n",
    "    search_agent.create_vectorstore()\n",
    "    \n",
    "    # 运行各类方法\n",
    "    search_agent.method1_retrieval_qa_chain()\n",
    "    search_agent.method2_retrieval_tool()\n",
    "    search_agent.method3_context_augmented_agent()\n",
    "    search_agent.method4_advanced_rag()\n",
    "    \n",
    "    # 创建并运行多步骤搜索智能体\n",
    "    print(\"\\\\n2. 运行多步骤搜索智能体示例\")\n",
    "    multi_step_agent = MultiStepSearchAgent()\n",
    "    multi_step_agent.setup_from_existing(search_agent.vectorstore)\n",
    "    \n",
    "    # 执行复杂查询\n",
    "    complex_query = \"比较不同搜索集成方法的优缺点，并推荐适合不同应用场景的最佳选择\"\n",
    "    multi_step_agent.process_complex_query(complex_query)\n",
    "    \n",
    "    print(\"\\\\n=== 示例运行完成 ===\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "    \n",
    "    # Create a real-world example of search-enhanced agent integration\n",
    "    application_example_code = \"\"\"# LangChain 搜索增强智能体实际应用示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool, AgentExecutor\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
    "from langchain.schema import SystemMessage\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class ProductSupport:\n",
    "    \\\"\\\"\\\"产品支持智能体 - 结合知识库搜索的技术支持助手\\\"\\\"\\\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0.2)\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.agent = None\n",
    "    \n",
    "    def setup_knowledge_base(self):\n",
    "        \\\"\\\"\\\"设置示例产品知识库\\\"\\\"\\\"\n",
    "        print(\"设置产品知识库...\")\n",
    "        \n",
    "        # 创建示例知识库文档\n",
    "        product_docs = [\n",
    "            {\n",
    "                \"title\": \"产品概述\",\n",
    "                \"content\": \\\"\\\"\\\"\n",
    "                智能家居控制系统 v2.0\n",
    "                \n",
    "                我们的智能家居控制系统允许用户通过移动应用、语音或自动化规则控制家中的所有联网设备。\n",
    "                系统支持灯光、恒温器、安全摄像头、门锁、窗帘和家电等设备。\n",
    "                主要功能包括:\n",
    "                - 远程控制: 从任何地方控制家中设备\n",
    "                - 语音控制: 通过Alexa、Google Assistant集成\n",
    "                - 自动化: 基于时间、位置或传感器触发的规则\n",
    "                - 能源监控: 跟踪能源使用并提供优化建议\n",
    "                - 安全警报: 异常活动通知\n",
    "                \\\"\\\"\\\"\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"安装指南\",\n",
    "                \"content\": \\\"\\\"\\\"\n",
    "                智能家居控制系统安装指南\n",
    "                \n",
    "                1. 硬件要求:\n",
    "                   - 中央控制枢纽(包含在包装中)\n",
    "                   - WiFi网络(推荐5GHz)\n",
    "                   - 兼容的智能设备\n",
    "                   - iOS或Android手机(用于移动应用)\n",
    "                \n",
    "                2. 初始设置:\n",
    "                   a. 将中央控制枢纽连接到电源\n",
    "                   b. 将枢纽连接到您的WiFi网络\n",
    "                   c. 在手机上下载并安装\"智能家居\"应用\n",
    "                   d. 创建账户并按照应用中的指导进行操作\n",
    "                \n",
    "                3. 设备配对:\n",
    "                   a. 在应用中点击\"添加设备\"\n",
    "                   b. 选择设备类型\n",
    "                   c. 将设备设置为配对模式(参考设备说明)\n",
    "                   d. 按照应用中的特定说明完成配对\n",
    "                \n",
    "                常见问题:\n",
    "                - 如果枢纽无法连接WiFi，请确保路由器固件已更新\n",
    "                - 蓝灯闪烁表示配对模式，红灯表示连接错误\n",
    "                \\\"\\\"\\\"\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"故障排除\",\n",
    "                \"content\": \\\"\\\"\\\"\n",
    "                智能家居系统故障排除指南\n",
    "                \n",
    "                1. 设备离线:\n",
    "                   - 检查设备电源\n",
    "                   - 确认WiFi连接正常\n",
    "                   - 重启设备(断电10秒后重新连接)\n",
    "                   - 重启中央控制枢纽\n",
    "                   - 确保设备在WiFi范围内\n",
    "                \n",
    "                2. 应用程序无法连接:\n",
    "                   - 检查手机网络连接\n",
    "                   - 确认使用正确的账户凭据\n",
    "                   - 清除应用缓存并重新启动\n",
    "                   - 检查应用是否需要更新\n",
    "                \n",
    "                3. 自动化规则失效:\n",
    "                   - 验证触发条件是否满足\n",
    "                   - 检查所有相关设备是否在线\n",
    "                   - 查看规则设置中的时区设置\n",
    "                   - 删除并重新创建规则\n",
    "                \n",
    "                4. 系统响应缓慢:\n",
    "                   - 检查internet连接速度\n",
    "                   - 减少连接到枢纽的设备数量\n",
    "                   - 重启中央控制枢纽\n",
    "                   - 检查固件更新\n",
    "                \n",
    "                5. 错误代码:\n",
    "                   - E01: 网络连接错误\n",
    "                   - E02: 设备认证失败\n",
    "                   - E03: 固件更新失败\n",
    "                   - E04: 存储空间不足\n",
    "                   - E05: 系统过载\n",
    "                \\\"\\\"\\\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # 创建临时文件存储文档\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        file_paths = []\n",
    "        \n",
    "        for doc in product_docs:\n",
    "            file_path = os.path.join(temp_dir, f\"{doc['title'].replace(' ', '_')}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"# {doc['title']}\\\\n\\\\n{doc['content']}\")\n",
    "            file_paths.append(file_path)\n",
    "        \n",
    "        # 加载文档\n",
    "        for file_path in file_paths:\n",
    "            loader = TextLoader(file_path)\n",
    "            self.documents.extend(loader.load())\n",
    "        \n",
    "        # 处理文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        splits = text_splitter.split_documents(self.documents)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "        \n",
    "        print(f\"知识库设置完成，包含 {len(splits)} 个文本块\")\n",
    "    \n",
    "    def setup_agent(self):\n",
    "        \\\"\\\"\\\"设置产品支持智能体\\\"\\\"\\\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先设置知识库\")\n",
    "        \n",
    "        print(\"设置产品支持智能体...\")\n",
    "        \n",
    "        # 创建检索器\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "        \n",
    "        # 创建上下文压缩检索器\n",
    "        compressor = LLMChainExtractor.from_llm(self.llm)\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=retriever\n",
    "        )\n",
    "        \n",
    "        # 创建检索工具\n",
    "        def search_product_knowledge(query: str) -> str:\n",
    "            \\\"\\\"\\\"搜索产品知识库\\\"\\\"\\\"\n",
    "            docs = compression_retriever.get_relevant_documents(query)\n",
    "            if not docs:\n",
    "                return \"知识库中没有找到相关信息。\"\n",
    "            return \"\\\\n\\\\n\".join([f\"来源: {doc.metadata.get('source', '未知')}\\\\n内容: {doc.page_content}\" for doc in docs])\n",
    "        \n",
    "        # 创建故障诊断工具\n",
    "        def diagnose_problem(description: str) -> str:\n",
    "            \\\"\\\"\\\"诊断产品问题\\\"\\\"\\\"\n",
    "            # 创建诊断链\n",
    "            diagnosis_prompt = PromptTemplate(\n",
    "                template=\"你是智能家居系统专家。请分析以下问题描述并提供可能的原因和解决步骤：\\\\n\\\\n{problem_description}\",\n",
    "                input_variables=[\"problem_description\"]\n",
    "            )\n",
    "            diagnosis_chain = LLMChain(llm=self.llm, prompt=diagnosis_prompt)\n",
    "            \n",
    "            # 执行诊断\n",
    "            result = diagnosis_chain.run(description)\n",
    "            return result\n",
    "        \n",
    "        # 定义工具\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"产品知识库\",\n",
    "                func=search_product_knowledge,\n",
    "                description=\"当需要查询产品信息、安装指南或常见问题时使用\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name=\"故障诊断\",\n",
    "                func=diagnose_problem,\n",
    "                description=\"当用户描述具体问题需要诊断时使用\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        # 创建产品支持智能体\n",
    "        system_message = SystemMessage(\n",
    "            content=\\\"\\\"\\\"你是智能家居控制系统的客户支持专家。你的任务是帮助用户解决与产品相关的问题。\n",
    "            \n",
    "            遵循以下指南:\n",
    "            1. 首先理解用户的问题\n",
    "            2. 使用产品知识库工具查询相关信息\n",
    "            3. 如果是具体的技术问题，使用故障诊断工具\n",
    "            4. 以友好、专业的方式回应用户\n",
    "            5. 给出清晰、分步骤的解决方案\n",
    "            6. 如果知识库中没有相关信息，承认这一点并提供一般性建议\n",
    "            \n",
    "            确保回答准确、实用且易于理解。\n",
    "            \\\"\\\"\\\"\n",
    "        )\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            system_message,\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ])\n",
    "        \n",
    "        # 创建智能体\n",
    "        self.agent = initialize_agent(\n",
    "            tools,\n",
    "            self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "087c705b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:57:26.123282Z",
     "iopub.status.busy": "2025-04-07T04:57:26.122692Z",
     "iopub.status.idle": "2025-04-07T04:57:26.133141Z",
     "shell.execute_reply": "2025-04-07T04:57:26.131690Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 486)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m<tokenize>:486\u001B[0;36m\u001B[0m\n\u001B[0;31m    editor.write(\"langchain_tutorial/code_examples/search_agent_integration/basic_search_agent.py\", basic_search_agent)\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "\n",
    "# Setup tools\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "async def create_search_agent_examples():\n",
    "    \"\"\"Create search-agent integration examples for LangChain\"\"\"\n",
    "    \n",
    "    # Create directory for examples\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/code_examples/search_agent_integration\")\n",
    "    \n",
    "    # Create basic search agent example\n",
    "    basic_search_agent = \"\"\"# LangChain 搜索与智能体集成基础示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import tempfile\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "def create_demo_knowledge_base():\n",
    "    \"\"\"创建示例知识库\"\"\"\n",
    "    print(\"创建示例知识库...\")\n",
    "    \n",
    "    # 创建临时目录存储示例文档\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    # 示例文档内容\n",
    "    documents = [\n",
    "        {\n",
    "            \"title\": \"搜索与智能体集成方法\",\n",
    "            \"content\": \"\"\"\n",
    "            LangChain提供多种将搜索功能集成到智能体的方法:\n",
    "            \n",
    "            1. 检索工具（Retrieval Tools）: 将检索器包装为工具供智能体使用\n",
    "            2. 上下文增强（Contextual Augmentation）: 在智能体处理前添加相关上下文\n",
    "            3. 检索增强生成（RAG）: 结合检索和生成能力来提供更准确的回答\n",
    "            4. 自主检索（Self-querying）: 让智能体自己决定如何查询知识库\n",
    "            \n",
    "            这些方法可以根据具体需求组合使用。\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"向量检索优化\",\n",
    "            \"content\": \"\"\"\n",
    "            向量检索可以通过以下技术优化:\n",
    "            \n",
    "            1. 查询修改: 重写或扩展用户查询以提高检索质量\n",
    "            2. 过滤: 使用元数据过滤相关文档\n",
    "            3. 重排序: 使用额外标准对检索结果重新排序\n",
    "            4. 压缩: 提取最相关的内容片段\n",
    "            5. 混合检索: 结合语义和关键词搜索\n",
    "            \n",
    "            优化后的检索系统能够显著提高智能体的响应质量。\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"智能体工具选择\",\n",
    "            \"content\": \"\"\"\n",
    "            智能体需要智能地选择合适的工具:\n",
    "            \n",
    "            1. 基于查询分析选择搜索或计算工具\n",
    "            2. 考虑任务的信息需求和复杂度\n",
    "            3. 在多个信息源之间平衡权衡\n",
    "            4. 评估工具执行结果并决定后续行动\n",
    "            \n",
    "            有效的工具选择使智能体能够更高效地完成任务。\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # 写入文档到临时文件并加载\n",
    "    all_docs = []\n",
    "    for i, doc in enumerate(documents):\n",
    "        file_path = os.path.join(temp_dir, f\"{i}_{doc['title'].replace(' ', '_')}.txt\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"# {doc['title']}\\\\n\\\\n{doc['content']}\")\n",
    "        \n",
    "        # 加载文档\n",
    "        loader = TextLoader(file_path)\n",
    "        all_docs.extend(loader.load())\n",
    "    \n",
    "    # 分割文档\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    splits = text_splitter.split_documents(all_docs)\n",
    "    \n",
    "    # 创建向量存储\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "    \n",
    "    print(f\"知识库创建完成，包含 {len(splits)} 个文本块\")\n",
    "    return vectorstore\n",
    "\n",
    "def method1_retrieval_qa_direct():\n",
    "    \"\"\"方法1: 直接检索 - 使用检索QA链直接回答问题\"\"\"\n",
    "    print(\"\\\\n=== 方法1: 直接检索 ===\")\n",
    "    \n",
    "    # 创建知识库\n",
    "    vectorstore = create_demo_knowledge_base()\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    # 创建检索QA链\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=ChatOpenAI(),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 执行查询\n",
    "    query = \"LangChain中的搜索集成方法有哪些?\"\n",
    "    result = qa_chain.invoke({\"query\": query})\n",
    "    print(f\"\\\\n问题: {query}\")\n",
    "    print(f\"回答: {result['result']}\")\n",
    "    \n",
    "    return vectorstore, qa_chain\n",
    "\n",
    "def method2_agent_with_retrieval_tool(vectorstore):\n",
    "    \"\"\"方法2: 检索工具 - 将检索器封装为智能体工具\"\"\"\n",
    "    print(\"\\\\n=== 方法2: 检索工具 ===\")\n",
    "    \n",
    "    # 创建检索工具\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "    \n",
    "    def search_knowledge_base(query: str) -> str:\n",
    "        \"\"\"搜索知识库工具\"\"\"\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    # 创建工具列表\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"知识库搜索\",\n",
    "            func=search_knowledge_base,\n",
    "            description=\"当需要查询关于LangChain搜索方法或向量检索技术的信息时使用\"\n",
    "        ),\n",
    "        PythonREPLTool()\n",
    "    ]\n",
    "    \n",
    "    # 创建智能体\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        ChatOpenAI(temperature=0),\n",
    "        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    \n",
    "    # 执行查询\n",
    "    query = \"向量检索有哪些优化技术? 计算它们的数量。\"\n",
    "    result = agent.invoke(query)\n",
    "    print(f\"\\\\n问题: {query}\")\n",
    "    print(f\"回答: {result}\")\n",
    "    \n",
    "    return agent\n",
    "\n",
    "def method3_context_enhanced_agent(vectorstore):\n",
    "    \"\"\"方法3: 上下文增强 - 在处理前检索相关信息并增强上下文\"\"\"\n",
    "    print(\"\\\\n=== 方法3: 上下文增强 ===\")\n",
    "    \n",
    "    # 创建检索器\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "    \n",
    "    # 创建智能体工具\n",
    "    tools = [PythonREPLTool()]\n",
    "    \n",
    "    # 创建智能体\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        ChatOpenAI(temperature=0),\n",
    "        agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "        memory=memory,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    \n",
    "    # 先检索相关文档\n",
    "    query = \"智能体如何选择合适的工具?\"\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    # 增强查询\n",
    "    enhanced_query = f\"基于以下信息回答问题，如果需要可以使用Python代码演示：\\\\n\\\\n信息：{context}\\\\n\\\\n问题：{query}\"\n",
    "    \n",
    "    # 执行查询\n",
    "    result = agent.invoke(enhanced_query)\n",
    "    print(f\"\\\\n问题: {query}\")\n",
    "    print(f\"回答: {result}\")\n",
    "    \n",
    "    return agent\n",
    "\n",
    "def main():\n",
    "    print(\"=== LangChain 搜索与智能体集成示例 ===\")\n",
    "    \n",
    "    # 方法1: 直接检索QA\n",
    "    vectorstore, qa_chain = method1_retrieval_qa_direct()\n",
    "    \n",
    "    # 方法2: 检索作为智能体工具\n",
    "    agent_with_tool = method2_agent_with_retrieval_tool(vectorstore)\n",
    "    \n",
    "    # 方法3: 上下文增强智能体\n",
    "    contextual_agent = method3_context_enhanced_agent(vectorstore)\n",
    "    \n",
    "    print(\"\\\\n=== 所有示例执行完成 ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "    \n",
    "    # Create advanced search agent example\n",
    "    advanced_search_agent = \"\"\"# LangChain 高级搜索智能体示例\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents import AgentType, initialize_agent, Tool, create_react_agent, AgentExecutor\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema import SystemMessage\n",
    "import tempfile\n",
    "\n",
    "# 确保设置环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "class AdvancedSearchAgent:\n",
    "    \"\"\"高级搜索智能体 - 结合多种搜索增强技术的智能体\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0)\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        self.vectorstore = None\n",
    "        self.agent = None\n",
    "    \n",
    "    def setup_knowledge_base(self):\n",
    "        \"\"\"设置示例知识库\"\"\"\n",
    "        print(\"设置知识库...\")\n",
    "        \n",
    "        # 创建临时目录存储示例文档\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        \n",
    "        # 示例文档内容\n",
    "        documents = [\n",
    "            {\n",
    "                \"title\": \"搜索集成架构\",\n",
    "                \"content\": \"\"\"\n",
    "                搜索与智能体集成的三种主要架构:\n",
    "                \n",
    "                1. 工具型集成: 将搜索/检索系统作为工具提供给智能体使用\n",
    "                   - 智能体可以决定何时使用搜索\n",
    "                   - 更灵活但可能需要更多提示工程\n",
    "                   - 适合复杂任务和开放域问答\n",
    "                \n",
    "                2. 预检索增强: 在智能体处理前先进行检索并作为上下文提供\n",
    "                   - 智能体始终能看到相关信息\n",
    "                   - 减少不必要的API调用\n",
    "                   - 适合知识密集型任务\n",
    "                \n",
    "                3. 混合架构: 结合以上两种方法\n",
    "                   - 提供基础上下文，同时允许主动搜索\n",
    "                   - 更全面但复杂度更高\n",
    "                   - 适合多轮对话和复杂推理任务\n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"高级检索技术\",\n",
    "                \"content\": \"\"\"\n",
    "                提高检索质量的高级技术:\n",
    "                \n",
    "                1. 查询重构与扩展\n",
    "                   - 使用LLM重写用户查询\n",
    "                   - 添加相关关键词扩展查询\n",
    "                   - 分解复杂查询为多个简单查询\n",
    "                \n",
    "                2. 上下文压缩\n",
    "                   - 提取检索文档中最相关的部分\n",
    "                   - 减少上下文长度，集中于关键信息\n",
    "                   - 使用LLM或启发式方法进行筛选\n",
    "                \n",
    "                3. 混合检索\n",
    "                   - 结合多种检索策略(语义、关键词等)\n",
    "                   - 整合多个数据源的结果\n",
    "                   - 使用加权方法排序最终结果\n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"title\": \"行业应用场景\",\n",
    "                \"content\": \"\"\"\n",
    "                搜索增强智能体的行业应用:\n",
    "                \n",
    "                1. 客户支持\n",
    "                   - 检索产品文档回答用户问题\n",
    "                   - 访问内部知识库解决技术问题\n",
    "                   - 提供个性化的故障排除建议\n",
    "                \n",
    "                2. 法律研究\n",
    "                   - 搜索相关法规和判例\n",
    "                   - 分析法律文件并提供见解\n",
    "                   - 辅助起草法律文档\n",
    "                \n",
    "                3. 医疗咨询\n",
    "                   - 检索医学文献和临床指南\n",
    "                   - 提供基于证据的治疗建议\n",
    "                   - 支持医生的诊断决策\n",
    "                \n",
    "                4. 教育辅助\n",
    "                   - 个性化学习材料推荐\n",
    "                   - 回答学生的专业领域问题\n",
    "                   - 生成定制的练习和测试\n",
    "                \"\"\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # 写入文档到临时文件并加载\n",
    "        all_docs = []\n",
    "        for i, doc in enumerate(documents):\n",
    "            file_path = os.path.join(temp_dir, f\"{i}_{doc['title'].replace(' ', '_')}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"# {doc['title']}\\\\n\\\\n{doc['content']}\")\n",
    "            \n",
    "            # 加载文档\n",
    "            loader = TextLoader(file_path)\n",
    "            all_docs.extend(loader.load())\n",
    "        \n",
    "        # 分割文档\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        splits = text_splitter.split_documents(all_docs)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "        \n",
    "        print(f\"知识库设置完成，包含 {len(splits)} 个文本块\")\n",
    "    \n",
    "    def setup_advanced_search_tools(self):\n",
    "        \"\"\"设置高级搜索工具\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"请先设置知识库\")\n",
    "        \n",
    "        # 基本检索器\n",
    "        base_retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "        \n",
    "        # 1. 创建上下文压缩检索器\n",
    "        compressor = LLMChainExtractor.from_llm(self.llm)\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=base_retriever\n",
    "        )\n",
    "        \n",
    "        # 2. 创建查询转换器\n",
    "        def transform_query(query: str) -> str:\n",
    "            \"\"\"使用LLM改写查询以提高检索效果\"\"\"\n",
    "            transform_prompt = PromptTemplate.from_template(\n",
    "                \"请将以下用户查询改写成更适合向量数据库检索的形式，添加可能相关的关键词，但保持简洁。\\\\n\\\\n用户查询: {query}\\\\n\\\\n改写后的查询:\"\n",
    "            )\n",
    "            chain = transform_prompt | self.llm\n",
    "            result = chain.invoke({\"query\": query})\n",
    "            return result.content if hasattr(result, \"content\") else str(result)\n",
    "        \n",
    "        # 3. 定义搜索函数\n",
    "        def enhanced_search(query: str) -> str:\n",
    "            \"\"\"增强搜索函数，包括查询转换和上下文压缩\"\"\"\n",
    "            # 转换查询\n",
    "            transformed_query = transform_query(query)\n",
    "            print(f\"原始查询: {query}\")\n",
    "            print(f\"改写查询: {transformed_query}\")\n",
    "            \n",
    "            # 使用压缩检索器获取结果\n",
    "            docs = compression_retriever.get_relevant_documents(transformed_query)\n",
    "            return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "        \n",
    "        # 创建工具集\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"增强知识搜索\",\n",
    "                func=enhanced_search,\n",
    "                description=\"当需要查询关于搜索技术、智能体集成方法或应用场景的信息时使用\"\n",
    "            ),\n",
    "            PythonREPLTool()\n",
    "        ]\n",
    "        \n",
    "        return tools\n",
    "    \n",
    "    def setup_agent(self):\n",
    "        \"\"\"设置高级搜索智能体\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            self.setup_knowledge_base()\n",
    "        \n",
    "        # 获取高级搜索工具\n",
    "        tools = self.setup_advanced_search_tools()\n",
    "        \n",
    "        # 创建系统提示\n",
    "        system_message = SystemMessage(\n",
    "            content=\"\"\"你是一个先进的搜索增强智能体，专门回答关于搜索技术与智能体集成的问题。\n",
    "\n",
    "遵循以下步骤:\n",
    "1. 理解用户的查询意图\n",
    "2. 使用增强知识搜索工具获取相关信息\n",
    "3. 基于检索到的信息提供全面的回答\n",
    "4. 如果需要进行计算或示例，使用Python工具\n",
    "5. 以清晰、结构化的方式组织你的回答\n",
    "\n",
    "如果检索的信息不完整，可以基于你的知识进行补充，但要明确区分来源。\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        # 创建提示模板\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            system_message,\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ])\n",
    "        \n",
    "        # 创建智能体\n",
    "        agent = create_react_agent(self.llm, tools, prompt)\n",
    "        \n",
    "        # 创建执行器\n",
    "        self.agent = AgentExecutor.from_agent_and_tools(\n",
    "            agent=agent,\n",
    "            tools=tools,\n",
    "            memory=self.memory,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "            max_iterations=5\n",
    "        )\n",
    "        \n",
    "        return self.agent\n",
    "    \n",
    "    def run_query(self, query: str) -> str:\n",
    "        \"\"\"执行查询\"\"\"\n",
    "        if not self.agent:\n",
    "            self.setup_agent()\n",
    "        \n",
    "        print(f\"\\\\n执行查询: {query}\")\n",
    "        result = self.agent.invoke(query)\n",
    "        return result\n",
    "\n",
    "def main():\n",
    "    print(\"=== LangChain 高级搜索智能体示例 ===\")\n",
    "    \n",
    "    # 创建高级搜索智能体\n",
    "    agent = AdvancedSearchAgent()\n",
    "    agent.setup_knowledge_base()\n",
    "    agent.setup_agent()\n",
    "    \n",
    "    # 执行多个查询示例\n",
    "    queries = [\n",
    "        \"比较不同搜索与智能体集成架构的优缺点\",\n",
    "        \"有哪些高级检索技术可以提高搜索质量?\",\n",
    "        \"搜索增强智能体在哪些行业有应用，并计算行业数量\"\n",
    "    ]\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"\\\\n--- 查询 {i+1} ---\")\n",
    "        result = agent.run_query(query)\n",
    "        print(f\"\\\\n最终回答: {result}\")\n",
    "    \n",
    "    print(\"\\\\n=== 示例执行完成 ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "    # Write the examples to files\n",
    "    editor.write(\"langchain_tutorial/code_examples/search_agent_integration/basic_search_agent.py\", basic_search_agent)\n",
    "    print(\"Created basic search agent example file\")\n",
    "    \n",
    "    editor.write(\"langchain_tutorial/code_examples/search_agent_integration/advanced_search_agent.py\", advanced_search_agent)\n",
    "    print(\"Created advanced search agent example file\")\n",
    "    \n",
    "    # Create README file\n",
    "    readme_content = \"\"\"# LangChain 搜索与智能体集成示例\n",
    "\n",
    "本目录包含展示LangChain框架中搜索功能与智能体集成的各种实现方式的代码示例。\n",
    "\n",
    "## 文件说明\n",
    "\n",
    "1. `basic_search_agent.py` - 基础搜索智能体示例\n",
    "   - 演示三种基本的搜索-智能体集成模式：\n",
    "     - 直接检索QA链\n",
    "     - 检索作为智能体工具\n",
    "     - 上下文增强智能体\n",
    "\n",
    "2. `advanced_search_agent.py` - 高级搜索智能体示例\n",
    "   - 演示更复杂的搜索增强技术：\n",
    "     - 查询转换/重写\n",
    "     - 上下文压缩\n",
    "     - 多轮对话记忆\n",
    "\n",
    "## 集成方法概述\n",
    "\n",
    "1. **直接检索模式**\n",
    "   - 使用检索QA链直接查询向量存储\n",
    "   - 最简单的实现方式\n",
    "   - 适用于单轮、直接的问答场景\n",
    "\n",
    "2. **检索工具模式**\n",
    "   - 将检索器包装为智能体工具\n",
    "   - 让智能体决定何时搜索信息\n",
    "   - 适用于复杂任务和开放域问答\n",
    "\n",
    "3. **上下文增强模式**\n",
    "   - 在处理前检索相关信息\n",
    "   - 作为上下文提供给智能体\n",
    "   - 适用于知识密集型任务\n",
    "\n",
    "## 使用说明\n",
    "\n",
    "1. 确保安装所需依赖：\n",
    "   ```bash\n",
    "   pip install langchain langchain_community faiss-cpu openai\n",
    "   ```\n",
    "\n",
    "2. 设置OpenAI API密钥：\n",
    "   ```python\n",
    "   import os\n",
    "   os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "   ```\n",
    "\n",
    "3. 运行示例：\n",
    "   ```bash\n",
    "   python basic_search_agent.py\n",
    "   python advanced_search_agent.py\n",
    "   ```\n",
    "\"\"\"\n",
    "    \n",
    "    editor.write(\"langchain_tutorial/code_examples/search_agent_integration/README.md\", readme_content)\n",
    "    print(\"Created README file\")\n",
    "    \n",
    "    # List files\n",
    "    files = await terminal.run(\"find langchain_tutorial/code_examples/search_agent_integration -type f | sort\")\n",
    "    print(f\"\\nCreated files in search agent integration directory:\\n{files}\")\n",
    "    \n",
    "    print(\"\\n=== Search Agent Example Creation Complete ===\")\n",
    "    print(\"Created comprehensive examples for:\")\n",
    "    print(\"1. Basic search-agent integration patterns\")\n",
    "    print(\"2. Advanced search techniques with LangChain agents\")\n",
    "    print(\"3. Documentation and usage instructions\")\n",
    "\n",
    "# Run the main function\n",
    "await create_search_agent_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a76dae5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T05:04:50.780391Z",
     "iopub.status.busy": "2025-04-07T05:04:50.780095Z",
     "iopub.status.idle": "2025-04-07T05:04:50.786609Z",
     "shell.execute_reply": "2025-04-07T05:04:50.785514Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2884206134.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[31], line 13\u001B[0;36m\u001B[0m\n\u001B[0;31m    comprehensive_guide = \"\"\"# LangChain 框架全面指南\u001B[0m\n\u001B[0m                          ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "async def create_comprehensive_langchain_guide():\n",
    "    # Create directory for documentation\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "    \n",
    "    # Compile the comprehensive guide integrating all collected information\n",
    "    comprehensive_guide = \"\"\"# LangChain 框架全面指南\n",
    "\n",
    "## 1. LangChain 框架概述\n",
    "\n",
    "LangChain 是一个用于开发由大型语言模型（LLMs）驱动的应用程序的框架，它提供了一系列组件和工具，使开发者能够创建复杂的、交互式的、基于语言模型的应用。\n",
    "\n",
    "### 1.1 框架核心理念\n",
    "\n",
    "LangChain 的设计理念围绕以下几个核心原则：\n",
    "\n",
    "- **组件化设计**：提供模块化的组件，可以独立使用或组合成复杂的系统\n",
    "- **与语言模型的无缝集成**：优化与各种语言模型的交互方式\n",
    "- **链式处理**：允许将多个组件组合成处理管道\n",
    "- **状态管理**：提供记忆组件以维护对话历史和状态\n",
    "- **工具集成**：允许语言模型与外部工具和系统交互\n",
    "\n",
    "### 1.2 LangChain 表达式语言 (LCEL)\n",
    "\n",
    "LangChain 表达式语言是一种声明式语言，用于组合 LangChain 的各种组件，具有以下特点：\n",
    "\n",
    "- 使用管道操作符 (`|`) 连接组件\n",
    "- 支持同步和异步操作\n",
    "- 内置错误处理和重试机制\n",
    "- 支持流式传输和批处理\n",
    "- 简化复杂链的构建过程\n",
    "\n",
    "示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5279be5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T05:07:56.495288Z",
     "iopub.status.busy": "2025-04-07T05:07:56.494923Z",
     "iopub.status.idle": "2025-04-07T05:07:56.501596Z",
     "shell.execute_reply": "2025-04-07T05:07:56.500508Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2884206134.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[32], line 13\u001B[0;36m\u001B[0m\n\u001B[0;31m    comprehensive_guide = \"\"\"# LangChain 框架全面指南\u001B[0m\n\u001B[0m                          ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "async def create_comprehensive_langchain_guide():\n",
    "    # Create directory for documentation\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "    \n",
    "    # Compile the comprehensive guide integrating all collected information\n",
    "    comprehensive_guide = \"\"\"# LangChain 框架全面指南\n",
    "\n",
    "## 1. LangChain 框架概述\n",
    "\n",
    "LangChain 是一个用于开发由大型语言模型（LLMs）驱动的应用程序的框架，它提供了一系列组件和工具，使开发者能够创建复杂的、交互式的、基于语言模型的应用。\n",
    "\n",
    "### 1.1 框架核心理念\n",
    "\n",
    "LangChain 的设计理念围绕以下几个核心原则：\n",
    "\n",
    "- **组件化设计**：提供模块化的组件，可以独立使用或组合成复杂的系统\n",
    "- **与语言模型的无缝集成**：优化与各种语言模型的交互方式\n",
    "- **链式处理**：允许将多个组件组合成处理管道\n",
    "- **状态管理**：提供记忆组件以维护对话历史和状态\n",
    "- **工具集成**：允许语言模型与外部工具和系统交互\n",
    "\n",
    "### 1.2 LangChain 表达式语言 (LCEL)\n",
    "\n",
    "LangChain 表达式语言是一种声明式语言，用于组合 LangChain 的各种组件，具有以下特点：\n",
    "\n",
    "- 使用管道操作符 (`|`) 连接组件\n",
    "- 支持同步和异步操作\n",
    "- 内置错误处理和重试机制\n",
    "- 支持流式传输和批处理\n",
    "- 简化复杂链的构建过程\n",
    "\n",
    "示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3552662e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T05:10:34.110809Z",
     "iopub.status.busy": "2025-04-07T05:10:34.110515Z",
     "iopub.status.idle": "2025-04-07T05:10:34.115573Z",
     "shell.execute_reply": "2025-04-07T05:10:34.115021Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2884206134.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[33], line 13\u001B[0;36m\u001B[0m\n\u001B[0;31m    comprehensive_guide = \"\"\"# LangChain 框架全面指南\u001B[0m\n\u001B[0m                          ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "async def create_comprehensive_langchain_guide():\n",
    "    # Create directory for documentation\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "    \n",
    "    # Compile the comprehensive guide integrating all collected information\n",
    "    comprehensive_guide = \"\"\"# LangChain 框架全面指南\n",
    "\n",
    "## 1. LangChain 框架概述\n",
    "\n",
    "LangChain 是一个用于开发由大型语言模型（LLMs）驱动的应用程序的框架，它提供了一系列组件和工具，使开发者能够创建复杂的、交互式的、基于语言模型的应用。\n",
    "\n",
    "### 1.1 框架核心理念\n",
    "\n",
    "LangChain 的设计理念围绕以下几个核心原则：\n",
    "\n",
    "- **组件化设计**：提供模块化的组件，可以独立使用或组合成复杂的系统\n",
    "- **与语言模型的无缝集成**：优化与各种语言模型的交互方式\n",
    "- **链式处理**：允许将多个组件组合成处理管道\n",
    "- **状态管理**：提供记忆组件以维护对话历史和状态\n",
    "- **工具集成**：允许语言模型与外部工具和系统交互\n",
    "\n",
    "### 1.2 LangChain 表达式语言 (LCEL)\n",
    "\n",
    "LangChain 表达式语言是一种声明式语言，用于组合 LangChain 的各种组件，具有以下特点：\n",
    "\n",
    "- 使用管道操作符 (`|`) 连接组件\n",
    "- 支持同步和异步操作\n",
    "- 内置错误处理和重试机制\n",
    "- 支持流式传输和批处理\n",
    "- 简化复杂链的构建过程\n",
    "\n",
    "示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5859f641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T05:22:54.861781Z",
     "iopub.status.busy": "2025-04-07T05:22:54.861507Z",
     "iopub.status.idle": "2025-04-07T05:22:55.613438Z",
     "shell.execute_reply": "2025-04-07T05:22:55.612853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined comprehensive guide created successfully\n",
      "Created index document successfully\n",
      "Cleaned up temporary files\n",
      "\n",
      "Final documentation files:\n",
      "\n",
      "langchain_tutorial/documentation/index.md\n",
      "langchain_tutorial/documentation/langchain_complete_guide.md\n",
      "langchain_tutorial/documentation/langchain_comprehensive_guide.md\n",
      "\n",
      "Created project README file\n",
      "\n",
      "=== Document Organization Complete ===\n",
      "Successfully created:\n",
      "1. Combined comprehensive guide\n",
      "2. Structured index document with links to all resources\n",
      "3. Project README file\n",
      "\n",
      "All information has been organized into a coherent structure.\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "from metagpt.tools.libs.editor import Editor\n",
    "import os\n",
    "\n",
    "terminal = Terminal()\n",
    "editor = Editor()\n",
    "\n",
    "async def create_final_document_structure():\n",
    "    # Create directory for final documentation\n",
    "    await terminal.run(\"mkdir -p langchain_tutorial/documentation\")\n",
    "    \n",
    "    # Read the two parts of the comprehensive guide\n",
    "    part1_path = \"langchain_tutorial/documentation/langchain_comprehensive_guide.md\"\n",
    "    part2_path = \"langchain_tutorial/documentation/langchain_comprehensive_guide_part2.md\"\n",
    "    \n",
    "    part1_content = await editor.read(part1_path)\n",
    "    part2_content = await editor.read(part2_path)\n",
    "    \n",
    "    # Combine them into a single document\n",
    "    combined_content = part1_content.content + \"\\n\\n\" + part2_content.content\n",
    "    \n",
    "    # Write the combined guide\n",
    "    editor.write(\"langchain_tutorial/documentation/langchain_complete_guide.md\", combined_content)\n",
    "    print(\"Combined comprehensive guide created successfully\")\n",
    "    \n",
    "    # Create the final index document that links to all resources\n",
    "    index_content = \"\"\"# LangChain 框架学习资源索引\n",
    "\n",
    "## 项目概述\n",
    "\n",
    "本项目收集并整理了 LangChain 框架的相关资源，包括框架组件说明、智能体实现方法、搜索集成和多智能体工作流的设计与实现。所有资料基于 LangChain 官方文档（[https://python.langchain.com/docs/introduction/](https://python.langchain.com/docs/introduction/)）整理而成。\n",
    "\n",
    "## 综合指南\n",
    "\n",
    "- [LangChain 框架完整指南](langchain_complete_guide.md) - 全面介绍 LangChain 的架构、组件和使用方法\n",
    "\n",
    "## 文档结构\n",
    "\n",
    "### 基础文档\n",
    "\n",
    "- [文档结构](../docs/document_structure.md) - LangChain 文档的整体结构\n",
    "- [框架组件](../docs/components.md) - LangChain 的核心组件概述\n",
    "- [智能体](../docs/agents.md) - 智能体系统概览\n",
    "- [框架总览](../docs/overview.md) - LangChain 框架的总体架构\n",
    "\n",
    "### LangChain 表达式语言 (LCEL)\n",
    "\n",
    "- [LCEL 介绍](../docs/lcel_intro.md) - LangChain 表达式语言基础\n",
    "- [LCEL 接口](../docs/lcel_interface.md) - LCEL 接口说明\n",
    "- [LCEL 食谱](../docs/lcel_cookbook.md) - LCEL 使用示例\n",
    "\n",
    "### 组件详解\n",
    "\n",
    "- [模型输入输出](../docs/components/model_io.md) - 语言模型接口\n",
    "- [记忆系统](../docs/components/memory.md) - 对话历史管理\n",
    "- [提示模板](../docs/components/prompt_templates.md) - 提示工程\n",
    "- [输出解析器](../docs/components/output_parsers.md) - 结构化输出处理\n",
    "- [链](../docs/components/chains.md) - 组件组合\n",
    "- [检索系统](../docs/components/retrieval.md) - 数据连接和检索\n",
    "\n",
    "### 单智能体实现\n",
    "\n",
    "- [智能体执行器](../docs/single_agent/agent_executor.md) - 智能体执行管理\n",
    "- [ReAct 智能体](../docs/single_agent/react_agent.md) - 结合推理和行动的智能体\n",
    "- [OpenAI 函数智能体](../docs/single_agent/openai_functions.md) - 基于函数调用的智能体\n",
    "- [结构化聊天智能体](../docs/single_agent/structured_chat.md) - 结构化对话智能体\n",
    "- [计划执行智能体](../docs/single_agent/plan_execute.md) - 规划与执行智能体\n",
    "\n",
    "### 多智能体编排\n",
    "\n",
    "- [智能体监督](../docs/multi_agent/agent_supervision.md) - 多智能体监督框架\n",
    "- [团队监督者模式](../docs/multi_agent/team_supervisor.md) - 团队协作模式\n",
    "- [经理-工人模式](../docs/multi_agent/manager_worker.md) - 层级协作模式\n",
    "- [计划执行模式](../docs/multi_agent/plan_executor.md) - 规划与执行分离模式\n",
    "- [CrewAI 集成](../docs/multi_agent/crewai_integration.md) - CrewAI 多智能体框架集成\n",
    "\n",
    "### 搜索与智能体集成\n",
    "\n",
    "- [搜索与智能体集成总结](../docs/search_agent_integration/search_agent_summary.md) - 综合概述\n",
    "- [搜索工具](../docs/search_agent_integration/search_tools.md) - 智能体可用的搜索工具\n",
    "- [搜索工具包](../docs/search_agent_integration/search_toolkit.md) - 搜索工具集成包\n",
    "- [向量存储](../docs/search_agent_integration/vector_stores.md) - 向量数据库集成\n",
    "- [检索器](../docs/search_agent_integration/retrievers.md) - 检索增强系统\n",
    "- [向量数据库聊天](../docs/search_agent_integration/agent_with_retrieval_tool.md) - 集成检索工具的聊天智能体\n",
    "\n",
    "### 智能体编排指南\n",
    "\n",
    "- [智能体编排模式](../docs/agent_patterns_summary.md) - 单智能体和多智能体编排模式总结\n",
    "- [智能体编排指南](../docs/agent_orchestration_guide.md) - 智能体协作系统设计指南\n",
    "\n",
    "## 代码示例\n",
    "\n",
    "### 智能体示例\n",
    "\n",
    "- [单智能体示例](../code_examples/agent_examples/single_agent_example.py) - 不同类型单智能体实现\n",
    "- [多智能体示例](../code_examples/agent_examples/multi_agent_example.py) - 多智能体协作模式实现\n",
    "- [RAG 智能体示例](../code_examples/agent_examples/rag_agent_example.py) - 检索增强智能体实现\n",
    "- [README](../code_examples/agent_examples/README.md) - 示例代码使用说明\n",
    "\n",
    "### 搜索智能体集成示例\n",
    "\n",
    "- [基础搜索智能体](../code_examples/search_agent_integration/basic_search_agent.py) - 基本搜索集成模式\n",
    "- [高级搜索智能体](../code_examples/search_agent_integration/advanced_search_agent.py) - 高级搜索技术\n",
    "- [README](../code_examples/search_agent_integration/README.md) - 搜索集成示例使用说明\n",
    "\n",
    "### 多智能体工作流示例\n",
    "\n",
    "- [多智能体工作流](../code_examples/multi_agent_demo/multi_agent_workflow.py) - 完整多智能体系统示例\n",
    "- [专家智能体](../code_examples/multi_agent_demo/agents/specialist_agents.py) - 专业领域智能体实现\n",
    "- [自定义工具](../code_examples/multi_agent_demo/tools/custom_tools.py) - 智能体工具扩展\n",
    "- [LCEL 示例](../code_examples/multi_agent_demo/lcel_example.py) - LangChain 表达式语言示例\n",
    "- [README](../code_examples/multi_agent_demo/README.md) - 多智能体演示使用说明\n",
    "\n",
    "## 资源来源\n",
    "\n",
    "所有资料基于 LangChain 官方文档：[https://python.langchain.com/docs/introduction/](https://python.langchain.com/docs/introduction/)\n",
    "\"\"\"\n",
    "    \n",
    "    # Write the index file\n",
    "    editor.write(\"langchain_tutorial/documentation/index.md\", index_content)\n",
    "    print(\"Created index document successfully\")\n",
    "    \n",
    "    # Clean up - delete the separate parts since we have combined them\n",
    "    await terminal.run(\"rm langchain_tutorial/documentation/langchain_comprehensive_guide_part2.md\")\n",
    "    print(\"Cleaned up temporary files\")\n",
    "    \n",
    "    # List all documentation files\n",
    "    doc_files = await terminal.run(\"find langchain_tutorial/documentation -type f | sort\")\n",
    "    print(\"\\nFinal documentation files:\")\n",
    "    print(doc_files)\n",
    "    \n",
    "    # Create a simple README for the project root\n",
    "    project_readme = \"\"\"# LangChain 框架学习项目\n",
    "\n",
    "## 项目简介\n",
    "\n",
    "本项目收集并整理了 LangChain 框架的核心组件、智能体系统、搜索集成和多智能体工作流设计的相关资料和代码示例，旨在帮助开发者快速上手和深入理解 LangChain 框架。\n",
    "\n",
    "## 资源导航\n",
    "\n",
    "请查看 [资源索引](documentation/index.md) 获取完整的资源列表和导航。\n",
    "\n",
    "## 主要内容\n",
    "\n",
    "- **文档资料**：框架组件解析、智能体系统详解、搜索集成方法、多智能体工作流设计\n",
    "- **代码示例**：单智能体实现、多智能体编排、RAG系统集成、LCEL表达式语言使用\n",
    "\n",
    "## 数据来源\n",
    "\n",
    "所有资料基于 LangChain 官方文档（[https://python.langchain.com/docs/introduction/](https://python.langchain.com/docs/introduction/)）整理而成。\n",
    "\n",
    "## 使用方法\n",
    "\n",
    "1. 浏览 [完整指南](documentation/langchain_complete_guide.md) 获取 LangChain 框架的全面介绍\n",
    "2. 参考 [代码示例](code_examples/) 了解实际实现方法\n",
    "3. 查阅特定主题的详细文档深入学习\n",
    "\"\"\"\n",
    "    \n",
    "    editor.write(\"langchain_tutorial/README.md\", project_readme)\n",
    "    print(\"Created project README file\")\n",
    "    \n",
    "    print(\"\\n=== Document Organization Complete ===\")\n",
    "    print(\"Successfully created:\")\n",
    "    print(\"1. Combined comprehensive guide\")\n",
    "    print(\"2. Structured index document with links to all resources\")\n",
    "    print(\"3. Project README file\")\n",
    "    print(\"\\nAll information has been organized into a coherent structure.\")\n",
    "\n",
    "# Execute the function to create the final document structure\n",
    "await create_final_document_structure()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}