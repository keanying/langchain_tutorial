"""
LangSmithåŸºæœ¬è¿½è¸ªç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨LangSmithè·Ÿè¸ªLangChainåº”ç”¨ç¨‹åºçš„æ‰§è¡Œè¿‡ç¨‹ï¼Œ
åŒ…æ‹¬åŸºæœ¬è®¾ç½®ã€è‡ªå®šä¹‰è·Ÿè¸ªå’ŒæŸ¥è¯¢è¿½è¸ªæ•°æ®ã€‚
"""

import os
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain.callbacks.tracers import LangSmithTracer
from langsmith import Client

# è®¾ç½®LangSmithç¯å¢ƒå˜é‡
os.environ["LANGCHAIN_API_KEY"] = "your-langsmith-api-key"  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„LangSmith APIå¯†é’¥
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "langsmith-demo"

def basic_tracing_example():
    """åŸºæœ¬è¿½è¸ªç¤ºä¾‹ï¼šæ— éœ€é¢å¤–ä»£ç ï¼Œè‡ªåŠ¨è·Ÿè¸ªLangChainç»„ä»¶"""
    print("ğŸ” æ‰§è¡ŒåŸºæœ¬è¿½è¸ªç¤ºä¾‹...")
    
    # åˆ›å»ºLLMå®ä¾‹
    llm = ChatOpenAI(temperature=0.7)
    
    # åˆ›å»ºæç¤ºæ¨¡æ¿
    template = "ä½ æ˜¯ä¸€ä½{role}ä¸“å®¶ã€‚è¯·ç®€è¦å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{question}"
    prompt = ChatPromptTemplate.from_template(template)
    
    # åˆ›å»ºé“¾
    chain = LLMChain(llm=llm, prompt=prompt)
    
    # æ‰§è¡Œé“¾ - ä¼šè‡ªåŠ¨è¿½è¸ª
    response = chain.invoke({
        "role": "äººå·¥æ™ºèƒ½",
        "question": "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
    })
    
    print(f"å›ç­”: {response['text']}")
    print("âœ… è¿è¡Œå·²è‡ªåŠ¨è¿½è¸ªåˆ°LangSmithã€‚è¯·ç™»å½•LangSmithæ§åˆ¶å°æŸ¥çœ‹è¯¦æƒ…ã€‚")
    
    return response

def custom_tracing_example():
    """è‡ªå®šä¹‰è¿½è¸ªç¤ºä¾‹ï¼šä½¿ç”¨è‡ªå®šä¹‰æ ‡ç­¾å’Œå…ƒæ•°æ®"""
    print("\nğŸ” æ‰§è¡Œè‡ªå®šä¹‰è¿½è¸ªç¤ºä¾‹...")
    
    # åˆ›å»ºLLMå®ä¾‹
    llm = ChatOpenAI(temperature=0.7)
    
    # åˆ›å»ºæç¤ºæ¨¡æ¿
    template = "ä½œä¸º{domain}æ–¹é¢çš„ä¸“å®¶ï¼Œè¯·è¯¦ç»†è§£é‡Š{topic}æ¦‚å¿µï¼Œå¹¶æä¾›ä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‚"
    prompt = ChatPromptTemplate.from_template(template)
    
    # åˆ›å»ºé“¾
    chain = LLMChain(llm=llm, prompt=prompt)
    
    # åˆ›å»ºè‡ªå®šä¹‰è·Ÿè¸ªå™¨
    tracer = LangSmithTracer(
        project_name="custom-traces",
        tags=["æ•™è‚²å†…å®¹", "æŠ€æœ¯è§£é‡Š"],
        metadata={
            "user_id": "user-123",
            "session_id": "session-456",
            "request_source": "tutorial_demo",
            "complexity_level": "intermediate"
        }
    )
    
    # æ‰§è¡Œé“¾ - ä½¿ç”¨è‡ªå®šä¹‰è·Ÿè¸ªå™¨
    response = chain.invoke(
        {
            "domain": "è®¡ç®—æœºç§‘å­¦",
            "topic": "é€’å½’ç®—æ³•"
        },
        config={"callbacks": [tracer]}
    )
    
    print(f"å›ç­”: {response['text'][:100]}...")
    print("âœ… è¿è¡Œå·²ä½¿ç”¨è‡ªå®šä¹‰å…ƒæ•°æ®è¿½è¸ªåˆ°LangSmithã€‚")
    
    return response

def manual_tracing_example():
    """æ‰‹åŠ¨è¿½è¸ªç¤ºä¾‹ï¼šè¿½è¸ªéLangChainç»„ä»¶æˆ–è‡ªå®šä¹‰å¤„ç†æ­¥éª¤"""
    print("\nğŸ” æ‰§è¡Œæ‰‹åŠ¨è¿½è¸ªç¤ºä¾‹...")
    
    # åˆ›å»ºLangSmithå®¢æˆ·ç«¯
    client = Client()
    
    # æ¨¡æ‹Ÿä¸€ä¸ªè‡ªå®šä¹‰å¤„ç†å‡½æ•°
    def process_data(input_text):
        # æ‰‹åŠ¨åˆ›å»ºæ ¹è·Ÿè¸ªé¡¹
        with client.trace(
            name="è‡ªå®šä¹‰æ•°æ®å¤„ç†æµç¨‹",
            run_type="chain",
            project_name="manual-traces",
            tags=["data-processing"],
            metadata={"input_length": len(input_text)}
        ) as run:
            try:
                # è®°å½•æ¥æ”¶åˆ°çš„æ•°æ®
                run.add_inputs({"raw_input": input_text})
                
                # æ¨¡æ‹Ÿç¬¬ä¸€ä¸ªå¤„ç†æ­¥éª¤
                with run.trace("æ­¥éª¤1ï¼šåˆ†è¯", run_type="tool") as step1:
                    # æ¨¡æ‹Ÿä¸€äº›å¤„ç†é€»è¾‘
                    tokens = input_text.split()
                    step1.add_outputs({"tokens": tokens, "token_count": len(tokens)})
                
                # æ¨¡æ‹Ÿç¬¬äºŒä¸ªå¤„ç†æ­¥éª¤
                with run.trace("æ­¥éª¤2ï¼šè¿‡æ»¤åœç”¨è¯", run_type="tool") as step2:
                    # æ¨¡æ‹Ÿä¸€äº›å¤„ç†é€»è¾‘
                    stopwords = ["çš„", "äº†", "æ˜¯"]
                    filtered_tokens = [token for token in tokens if token not in stopwords]
                    step2.add_outputs({"filtered_tokens": filtered_tokens})
                
                # æ¨¡æ‹Ÿæœ€ç»ˆç»“æœ
                result = " ".join(filtered_tokens)
                run.add_outputs({"processed_result": result})
                
                return result
                
            except Exception as e:
                # è®°å½•é”™è¯¯
                run.add_outputs({"error": str(e)})
                run.end(error=str(e))
                raise
    
    # è°ƒç”¨è‡ªå®šä¹‰å¤„ç†å‡½æ•°
    result = process_data("è¿™æ˜¯ä¸€ä¸ªç”¨äºæ¼”ç¤ºæ‰‹åŠ¨è¿½è¸ªåŠŸèƒ½çš„ç¤ºä¾‹æ–‡æœ¬ï¼Œå®ƒå°†è¢«å¤„ç†å¹¶è®°å½•åˆ°LangSmithä¸­ã€‚")
    
    print(f"å¤„ç†ç»“æœ: {result}")
    print("âœ… è‡ªå®šä¹‰å¤„ç†æ­¥éª¤å·²æ‰‹åŠ¨è¿½è¸ªåˆ°LangSmithã€‚")
    
    return result

def query_runs_example():
    """æŸ¥è¯¢è¿½è¸ªæ•°æ®ç¤ºä¾‹ï¼šè·å–å’Œåˆ†æå…ˆå‰çš„è¿è¡Œè®°å½•"""
    print("\nğŸ” æ‰§è¡Œè¿½è¸ªæ•°æ®æŸ¥è¯¢ç¤ºä¾‹...")
    
    try:
        # åˆ›å»ºLangSmithå®¢æˆ·ç«¯
        client = Client()
        
        # æŸ¥è¯¢æœ€è¿‘çš„è¿è¡Œè®°å½•
        runs = list(client.list_runs(
            project_name="langsmith-demo",
            execution_order=1,  # æŒ‰æ‰§è¡Œæ—¶é—´æ’åº
            limit=5  # é™åˆ¶è¿”å›æ•°é‡
        ))
        
        if not runs:
            print("æœªæ‰¾åˆ°è¿è¡Œè®°å½•ã€‚è¯·å…ˆè¿è¡Œå…¶ä»–ç¤ºä¾‹ä»¥ç”Ÿæˆä¸€äº›è·Ÿè¸ªæ•°æ®ã€‚")
            return
        
        print(f"æ‰¾åˆ° {len(runs)} æ¡æœ€è¿‘çš„è¿è¡Œè®°å½•:")
        
        for i, run in enumerate(runs):
            print(f"\nè¿è¡Œ {i+1}:")
            print(f"  ID: {run.id}")
            print(f"  åç§°: {run.name}")
            print(f"  çŠ¶æ€: {run.status}")
            print(f"  è¿è¡Œæ—¶é—´: {run.latency_ms if run.latency_ms else 'N/A'} æ¯«ç§’")
            print(f"  è¾“å…¥: {list(run.inputs.keys()) if run.inputs else 'N/A'}")
            print(f"  è¾“å‡º: {list(run.outputs.keys()) if run.outputs else 'N/A'}")
            if run.error:
                print(f"  é”™è¯¯: {run.error}")
        
        # è®¡ç®—å¹³å‡å»¶è¿Ÿ
        latencies = [run.latency_ms for run in runs if run.latency_ms]
        if latencies:
            avg_latency = sum(latencies) / len(latencies)
            print(f"\nå¹³å‡å»¶è¿Ÿ: {avg_latency:.2f} æ¯«ç§’")
        
        print("âœ… æˆåŠŸæŸ¥è¯¢å¹¶åˆ†æäº†LangSmithä¸­çš„è¿è¡Œè®°å½•ã€‚")
        
        return runs
        
    except Exception as e:
        print(f"æŸ¥è¯¢è¿è¡Œè®°å½•æ—¶å‡ºé”™: {str(e)}")
        return None

def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("===== LangSmith åŸºæœ¬è¿½è¸ªç¤ºä¾‹ =====\n")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if os.environ.get("LANGCHAIN_API_KEY") == "your-langsmith-api-key":
        print("âš ï¸ è­¦å‘Š: è¯·å°†ä»£ç ä¸­çš„'your-langsmith-api-key'æ›¿æ¢ä¸ºæ‚¨çš„å®é™…LangSmith APIå¯†é’¥")
        print("ç”³è¯·APIå¯†é’¥: https://smith.langchain.com/\n")
    
    # è¿è¡Œç¤ºä¾‹
    basic_tracing_example()
    custom_tracing_example()
    manual_tracing_example()
    query_runs_example()
    
    print("\n===== æ‰€æœ‰ç¤ºä¾‹å®Œæˆ =====")
    print("ç™»å½• https://smith.langchain.com/ æŸ¥çœ‹è¯¦ç»†çš„è¿½è¸ªç»“æœ")

if __name__ == "__main__":
    main()